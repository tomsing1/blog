{
  "hash": "b406cc2a8a464863fc1811837f28f981",
  "result": {
    "markdown": "---\ntitle: \"Querying parquet files with duckdb\"\nauthor: \"Thomas Sandmann\"\ndate: \"2023-05-06\"\nfreeze: true\ncategories: [SQL, AWS, TIL]\neditor:\n  markdown:\n    wrap: 72\nformat:\n  html:\n    toc: true\n    toc-depth: 4\n    code-tools:\n      source: true\n      toggle: false\n      caption: none\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n## tl;dr\n\nToday I learned how to access and query CSV and parquet files with \n[duckdb](https://duckdb.org/), using either the `duckdb` command line \ninterface or the eponymous\n[R package](https://cran.r-project.org/package=duckdb)\n\n### Motivation\n\n[duckdb](https://duckdb.org/) is a relational (table-oriented) database \nmanagement system (RDMS) contained in a single executable. It excels at\nprocessing tabular datasets, e.g. from CSV or Parquet files, from local\nfile systems or remote sources.\n\n[Apache Parquet](https://parquet.apache.org/) is\n> an open source, column-oriented data file format designed for efficient data storage and retrieval.\n\nHere, I am highlighting how to use `duckdb` to query remote parquet\nfiles without the need for retrieving the full dataset first. And \nthat's just one of the many functionalities offered by `duckdb`, truly\na swiss army knife in the data science toolkit!\n\n<p align=\"center\">\n<a title=\"D-M Commons, CC BY-SA 3.0 &lt;https://creativecommons.org/licenses/by-sa/3.0&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Wenger_EvoGrip_S17.JPG\"><img width=\"300\" alt=\"Wenger EvoGrip S17\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Wenger_EvoGrip_S17.JPG/512px-Wenger_EvoGrip_S17.JPG\"></a>\n<br>\n<a href=\"https://commons.wikimedia.org/wiki/File:Wenger_EvoGrip_S17.JPG\">D-M Commons</a>, <a href=\"https://creativecommons.org/licenses/by-sa/3.0\">CC BY-SA 3.0</a>, via Wikimedia Commons\n</p>\n\n### Prequisites\n\nI installed the duckdb executable on my Mac OS system with homebrew:\n\n```bash\nbrew install duckdb\nduckdb --version\n```\n\n### Getting started\n\nBy default, `duckdb` will create database in memory. Like other RMDS, it\nsupports a \n[core set of SQL statements](https://duckdb.org/docs/sql/introduction)\nand expressions. In addition, \n[extensions](https://duckdb.org/docs/extensions/overview) provide additional\nfunctionality, e.g.\n[connecting to Postgres databases](https://duckdb.org/docs/extensions/postgres_scanner)\nor\n[supporting JSON data](https://duckdb.org/docs/extensions/json).\n\nCommands can either be entered interactively, provided via the `-c` argument\nor in a text file. To access remote files, we first need to  install the \n[httpsfs` extension](https://duckdb.org/docs/extensions/httpfs)\nthat allows reading remote/writing remote files [^1].\n\n```bash\nduckdb -c \"INSTALL httpfs\"\n```\n\nTo get started, we read a small dataset from a CSV file hosted publicly on a\nwebserver. For brevity, we store this URL in the environmental variable\n`REMOTE_FILE`:\n\n```bash\nREMOTE_FILE=https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv\n```\n\n[^1]: Additional options to parse / import CSV files is available in duckdb's [documentation](https://duckdb.org/docs/data/csv/overview.html#parameters)\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nduckdb -c \"SELECT species, island, sex, bill_length_mm, bill_depth_mm \\\n           FROM '$REMOTE_FILE' LIMIT 5;\" \n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n┌─────────┬───────────┬─────────┬────────────────┬───────────────┐\n│ species │  island   │   sex   │ bill_length_mm │ bill_depth_mm │\n│ varchar │  varchar  │ varchar │     double     │    double     │\n├─────────┼───────────┼─────────┼────────────────┼───────────────┤\n│ Adelie  │ Torgersen │ MALE    │           39.1 │          18.7 │\n│ Adelie  │ Torgersen │ FEMALE  │           39.5 │          17.4 │\n│ Adelie  │ Torgersen │ FEMALE  │           40.3 │          18.0 │\n│ Adelie  │ Torgersen │         │                │               │\n│ Adelie  │ Torgersen │ FEMALE  │           36.7 │          19.3 │\n└─────────┴───────────┴─────────┴────────────────┴───────────────┘\n```\n:::\n:::\n\n\nBy default, `duckdb` will use a temporary, in-memory database. \nTo open or create a persistent database, simply include a path as a command\nline argument, e.g. `duckdb path/to/my_database.duckdb`\n\nFor example, the following command will download the remote CSV file and \nimport it into a duckdb database and store it in the `penguins.duckdb` file.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nduckdb \\\n  -c \"CREATE TABLE penguins AS SELECT * FROM '${REMOTE_FILE}';\" \\\n  penguins.duckdb \n```\n:::\n\n\nNow, we can query the local file with `duckdb` or explore it interactive with\nthe\n[tad viewer](https://duckdb.org/docs/guides/data_viewers/tad) [^2]\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nduckdb \\\n  -c \"SELECT * from penguins WHERE sex = 'MALE' LIMIT 5;\" \\\n  penguins.duckdb\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n┌─────────┬───────────┬────────────────┬───────────────┬───────────────────┬─────────────┬─────────┐\n│ species │  island   │ bill_length_mm │ bill_depth_mm │ flipper_length_mm │ body_mass_g │   sex   │\n│ varchar │  varchar  │     double     │    double     │       int64       │    int64    │ varchar │\n├─────────┼───────────┼────────────────┼───────────────┼───────────────────┼─────────────┼─────────┤\n│ Adelie  │ Torgersen │           39.1 │          18.7 │               181 │        3750 │ MALE    │\n│ Adelie  │ Torgersen │           39.3 │          20.6 │               190 │        3650 │ MALE    │\n│ Adelie  │ Torgersen │           39.2 │          19.6 │               195 │        4675 │ MALE    │\n│ Adelie  │ Torgersen │           38.6 │          21.2 │               191 │        3800 │ MALE    │\n│ Adelie  │ Torgersen │           34.6 │          21.1 │               198 │        4400 │ MALE    │\n└─────────┴───────────┴────────────────┴───────────────┴───────────────────┴─────────────┴─────────┘\n```\n:::\n:::\n\n\n[^2]: The [tad viewer](https://www.tadviewer.com/) is a free tool to view \nCSV, Parquet, and SQLite and DuckDb database files\n\n### Querying remote parquet files\n\nThe \n[NYC Taxi & Limousine Commission](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)\nhas collected data on public NYC taxi and for-hire vehicle (Uber, Lyft)\ntrips, going all the way back to 2009. The data is shared in the form\nof parquet files, and one parquet file is created for each month of \ndata.\n\nHere, I will use the Yellow Taxi Trip records from January and February\n2023 as examples. Let's store the URLs pointing to the respective\nparquet files in environmental variables.\n\n```bash\nPARQUET_FILE1=\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\"\nPARQUET_FILE2=\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet\"\n```\n\n\n::: {.cell}\n\n:::\n\n\nEach parquet file stores a single table of data. To get an overview of\nthe available information, we ask `duckdb` to DESCRIBE it:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nduckdb -c \"DESCRIBE SELECT * FROM '$PARQUET_FILE1'\";\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n┌───────────────────────┬─────────────┬─────────┬─────────┬─────────┬─────────┐\n│      column_name      │ column_type │  null   │   key   │ default │  extra  │\n│        varchar        │   varchar   │ varchar │ varchar │ varchar │ varchar │\n├───────────────────────┼─────────────┼─────────┼─────────┼─────────┼─────────┤\n│ VendorID              │ BIGINT      │ YES     │         │         │         │\n│ tpep_pickup_datetime  │ TIMESTAMP   │ YES     │         │         │         │\n│ tpep_dropoff_datetime │ TIMESTAMP   │ YES     │         │         │         │\n│ passenger_count       │ DOUBLE      │ YES     │         │         │         │\n│ trip_distance         │ DOUBLE      │ YES     │         │         │         │\n│ RatecodeID            │ DOUBLE      │ YES     │         │         │         │\n│ store_and_fwd_flag    │ VARCHAR     │ YES     │         │         │         │\n│ PULocationID          │ BIGINT      │ YES     │         │         │         │\n│ DOLocationID          │ BIGINT      │ YES     │         │         │         │\n│ payment_type          │ BIGINT      │ YES     │         │         │         │\n│ fare_amount           │ DOUBLE      │ YES     │         │         │         │\n│ extra                 │ DOUBLE      │ YES     │         │         │         │\n│ mta_tax               │ DOUBLE      │ YES     │         │         │         │\n│ tip_amount            │ DOUBLE      │ YES     │         │         │         │\n│ tolls_amount          │ DOUBLE      │ YES     │         │         │         │\n│ improvement_surcharge │ DOUBLE      │ YES     │         │         │         │\n│ total_amount          │ DOUBLE      │ YES     │         │         │         │\n│ congestion_surcharge  │ DOUBLE      │ YES     │         │         │         │\n│ airport_fee           │ DOUBLE      │ YES     │         │         │         │\n├───────────────────────┴─────────────┴─────────┴─────────┴─────────┴─────────┤\n│ 19 rows                                                           6 columns │\n└─────────────────────────────────────────────────────────────────────────────┘\n```\n:::\n:::\n\n\nA detailed description of the columns and their values is available\nin the \n[metadata dictionary](https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf). For example, the `payment_type`\nfield contains \"A numeric code signifying how the passenger paid for the trip.\" with the following encoding:\n\n- 1: Credit card\n- 2: Cash\n- 3: No charge\n- 4: Dispute\n- 5: Unknown\n- 6: Voided trip\n\nIn January, more than three million trips were recorded, but a\nquery to return the total number of records executes almost \ninstantaneously - because we don't need to download the (very large)\nfile first:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nduckdb -c \"SELECT count(*) FROM '$PARQUET_FILE1'\";\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n┌──────────────┐\n│ count_star() │\n│    int64     │\n├──────────────┤\n│      3066766 │\n└──────────────┘\n```\n:::\n:::\n\n\nThe vast majority of trips was paid for by credit card (payment type 1),\nand a small subset of trips was performed free of charge \n(payment type 3).\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nduckdb -c \"SELECT payment_type, count(payment_type) \\\n           FROM '$PARQUET_FILE1' \\\n           GROUP BY payment_type LIMIT 5\";\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n┌──────────────┬─────────────────────┐\n│ payment_type │ count(payment_type) │\n│    int64     │        int64        │\n├──────────────┼─────────────────────┤\n│            0 │               71743 │\n│            1 │             2411462 │\n│            2 │              532241 │\n│            3 │               18023 │\n│            4 │               33297 │\n└──────────────┴─────────────────────┘\n```\n:::\n:::\n\n\nWe can also query across multiple parquet files, e.g. retrieving the total number of trips for both January and February 2023:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nduckdb -c \"SELECT count(*) FROM \\\n           read_parquet(['$PARQUET_FILE1', '$PARQUET_FILE2'])\";\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n┌──────────────┐\n│ count_star() │\n│    int64     │\n├──────────────┤\n│      5980721 │\n└──────────────┘\n```\n:::\n:::\n\n\nWe can also copy the output of a query into a new, local parquet file.\nFor example, the following query will copy records for 100 trips that\nwere performed free of charge into a new `free_trips.parquet` parquet\nfile in the current working directory:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nduckdb -c \\\n  \"COPY (SELECT * FROM '$PARQUET_FILE1' \\\n         WHERE payment_type = 3 LIMIT 100) TO 'free_trips.parquet' \\\n  (FORMAT 'parquet');\"\n```\n:::\n\n\nWe can now query the local parquet file to drill deeper into this\ndata slice:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nduckdb -c \"SELECT payment_type, count(payment_type) \\\n           FROM 'free_trips.parquet' \\\n           GROUP BY payment_type\";\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n┌──────────────┬─────────────────────┐\n│ payment_type │ count(payment_type) │\n│    int64     │        int64        │\n├──────────────┼─────────────────────┤\n│            3 │                 100 │\n└──────────────┴─────────────────────┘\n```\n:::\n:::\n\n\n### APIs\n\nIn addition to using the `duckdb` command line interface (CLI), you can\nalso use a library for your favorite programming language. For example,\nthe\n[duckdb R package](https://cran.r-project.org/package=duckdb)\nprovides a \n[DBI interface](https://duckdb.org/docs/api/r) \nthat enables queries from within an R session.\n(The \n[duckdb python module](https://duckdb.org/docs/api/python/overview)\nprovides similar functionality.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!requireNamespace(\"duckdb\", quietly = TRUE)) {\n  install.packages(\"duckdb\")\n}\nsuppressPackageStartupMessages(library(\"duckdb\"))\nsuppressPackageStartupMessages(library(\"DBI\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncon <- dbConnect(duckdb::duckdb(), dbdir = \":memory:\")\ndbExecute(conn = con, \"INSTALL httpfs\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\nFor example, we can use an in-memory duckdb instance to query the\none (or more) of the remote parquet files we examined above:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nPARQUET_FILE1 = paste0(\"https://d37ci6vzurychx.cloudfront.net/\",\n                       \"trip-data/yellow_tripdata_2023-01.parquet\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsql <- \"SELECT payment_type, count(payment_type) \\\n        FROM read_parquet([?]) \\\n        GROUP BY payment_type LIMIT 5\";\ndbGetQuery(con, sql, list(PARQUET_FILE1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  payment_type count(payment_type)\n1            0               71743\n2            1             2411462\n3            2              532241\n4            3               18023\n5            4               33297\n```\n:::\n:::\n\n\nAlternatively, we can also access data (including CSV and parquet files)\nusing \n[dbplyr](https://cran.r-project.org/package=dbplyr) \nand\n[dplyr](https://cran.r-project.org/package=dplyr)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressPackageStartupMessages(library(dbplyr))\nsuppressPackageStartupMessages(library(dplyr))\n\ntbl(con, PARQUET_FILE1) |>\n  group_by(payment_type) |>\n  count() |>\n  collect()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 2\n# Groups:   payment_type [5]\n  payment_type       n\n         <dbl>   <dbl>\n1            0   71743\n2            1 2411462\n3            2  532241\n4            3   18023\n5            4   33297\n```\n:::\n:::\n\n\nDon't forget to disconnect from your duckdb database at the end of your\nR session!\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbDisconnect(con, shutdown=TRUE)\n```\n:::\n\n::: {.cell}\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}