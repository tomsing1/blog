{
  "hash": "017390fae4b510513a64ac98cf58900d",
  "result": {
    "markdown": "---\ntitle: \"Adventures with parquet II: Implementing the parquetArray S4 class\"\nauthor: \"Thomas Sandmann\"\ndate: \"2023-09-05\"\nfreeze: true\ncategories: [R, TIL, parquet, Bioconductor]\neditor:\n  markdown:\n    wrap: 72\nformat:\n  html:\n    toc: true\n    toc-depth: 4\n    code-tools:\n      source: true\n      toggle: false\n      caption: none\neditor_options: \n  chunk_output_type: console\n---\n\n\n## tl;dr\n\n[Previously](../parquet/), \nI learned how to export gene expression data from Bioconductor/R\nobjects as parquet files. Today, I am exploring Hervé Pagès's awesome\n[DelayedArray Bioconductor package](https://bioconductor.org/packages/release/bioc/html/DelayedArray.html)\nto represent data stored in parquet files as R matrices - retrieving only those\nsubsets needed for downstream analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressPackageStartupMessages({\n  library(\"arrow\")\n  library(\"dplyr\")\n  library(\"duckdb\")\n  library(\"edgeR\")\n  library(\"glue\")\n  library(\"rnaseqExamples\")\n  library(\"tibble\")\n  library(\"tidyr\")\n  library(\"DelayedArray\")\n  library(\"DESeq2\")\n  library(\"Mus.musculus\")\n})\n```\n:::\n\n\n## Exporting gene expression data to parquet files\n\nTo get some example RNA-seq data, I am loading two `SummarizedExperiments`\n(`tau` and `sarm1`)with bulk RNA-seq data from my\n[rnaseqExamples R package](https://github.com/tomsing1/rnaseq-examples). \n\nFirst, I extract the raw counts into data.frames with a short `tidy()` \nhelper function. Afterward, I store this data in parquet files in a temporary\ndirectory.\n\n::: {.callout-note collapse=\"true\"}\n\nNote that I am not including sample annotations in the parquet files, as I\nfound it useful to keep this (relatively small) set of metadata in a\nseparate object, file or (e.g. SQLite) database.\n\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Coerce a DGEList or a SummarizedExperiment into a tibble\ntidy <- function(x) {\n  # extract raw counts\n  edgeR::calcNormFactors(x)$counts %>%\n    as.data.frame() %>%\n    tibble::rownames_to_column(\"feature_id\") %>%\n    tidyr::pivot_longer(cols = colnames(x), names_to = \"sample_id\", \n                        values_to = \"count\")\n}\n\n# Store gene expression data for two mouse RNA-seq studies as parquet files\"\nout_dir <- file.path(tempdir(), \"parquet\")\ndir.create(out_dir, showWarnings = FALSE)\nfor (dataset in c(\"tau\", \"sarm1\")) {\n  df <- tidy(get(dataset))\n  df$study <- dataset  # add a columns with the name of the experiment\n  arrow::write_parquet(\n    x = df,\n    sink = file.path(out_dir, paste0(dataset, \".parquet\"))\n  )\n}\ndir(out_dir)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"sarm1.parquet\" \"tau.parquet\"  \n```\n:::\n:::\n\n\n## Creating the `ParquetArraySeed` S4 class\n\nNow, with the two parquet files in place, I am ready to follow \n[Hervé's excellent instructions](https://bioconductor.org/packages/release/bioc/vignettes/DelayedArray/inst/doc/02-Implementing_a_backend.html)\nto define my very own `ParquetArraySeed` S4 class, which can then be passed\ninto the `DelayedArray()` constructor function (see below).\n\nTo keep things simple, my `ParquetArraySeed` class will only store a single\nattribute: the path to the directory containing the parquet files.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsetClass(\"ParquetArraySeed\",\n    contains = \"Array\",\n    slots = c(\n        filepath = \"character\"\n    )\n)\n```\n:::\n\n\nTo simplify the instantiation of new objects, I also define a constructor\nfunction, which also ensures that the absolute file path is stored.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#' @importFrom tools file_path_as_absolute\nParquetArraySeed <- function(filepath) {\n  filepath <- tools::file_path_as_absolute(filepath)\n  new(\"ParquetArraySeed\", filepath = filepath)\n}\n```\n:::\n\n\n## Essential methods\n\nTo power a `DelayedArray` object, I need to define at least three different\nS4 methods for my new class:\n\n- `dim()` - returning an integer vector with the dimensions\n- `dimnames()` - returning a list of character vectors with the dimension names\n  (if any), e.g. the row and column names of a matrix.\n- `extract_array()` - returning an _ordinary array_ for a set of indices (see\n  below), e.g. a subset of the dataset to realize in memory.\n\n### `dim` and `dimnames` methods\n\nTo query the set of parquet files, I am using \n[duckdb](https://duckdb.org/docs/api/r.html)\nto retrieve the unique sample and feature identifiers. In case this information\nis useful later, I am caching the return values with \n[memoise](https://memoise.r-lib.org/). \nThat's handy because I can simply return the lengths of the dimensions names via\nthe `dim()` method - without accessing the same files again.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n.unique_values <- function(x, column, con = NULL, suffix = \".parquet\") {\n  if (is.null(con)) {\n    con <- duckdb::dbConnect(duckdb::duckdb())\n    on.exit(duckdb::dbDisconnect(con, shutdown=TRUE))\n  }\n  data_dir <- file.path(x@filepath, paste0(\"*\", suffix))\n  dbGetQuery(\n    con = con,\n    glue_sql(\n      \"SELECT DISTINCT {`column`} \n       FROM read_parquet({data_dir}) \n       ORDER BY {`column`}\", \n     .con = con)\n  )[, 1]\n}\nunique_values <- memoise::memoise(.unique_values)\n\nsetMethod(\"dimnames\", \"ParquetArraySeed\", function(x) {\n  samples <- unique_values(x, column = \"sample_id\")\n  features <- unique_values(x, column = \"feature_id\")\n  list(features, samples)\n})\n\nsetMethod(\"dim\", \"ParquetArraySeed\", function(x) {\n  lengths(dimnames(x))\n})\n```\n:::\n\n\n### The `extract_array` method\n\nI also use `duckdb()` to retrieve the actual data for a subset of \nfeatures, a subset of samples - or both. In case users only specify one _or_\nthe other, e.g. by passing an index with `NULL` values, I explicitely define\nfour different SQL queries returning:\n\n1. The full dataset (when `index = list(NULL, NULL)`),\n2. All features for a subset of samples,\n3. Selected features for all samples, or\n4. Selected features for selected samples.\n\nFinally, I pivot the data into a feature x sample matrix.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n.get_data <- function(x, index, con = NULL, suffix = \".parquet\") {\n  if (is.null(con)) {\n    con <- duckdb::dbConnect(duckdb::duckdb())\n    on.exit(duckdb::dbDisconnect(con, shutdown=TRUE))\n  }\n  data_dir <- file.path(x@filepath, paste0(\"*\", suffix))\n  \n  # match indices to feature and sample identifiers\n  dims <- dimnames(x)\n  keep_features <- dims[[1]][index[[1]]]\n  \n  # no indices => return the full dataset\n  if (is.null(index[[1]]) & is.null(index[[2]])) {\n   dataset <- dbGetQuery(\n      con = con,\n      glue_sql(\n        \"SELECT feature_id, sample_id, count\n       FROM read_parquet({data_dir})\", \n       .con = con)\n   )\n   keep_features <- unique(dataset$feature_id)\n   keep_samples <- unique(dataset$sample_id)\n   # no sample index => return all samples\n  } else if (!is.null(index[[1]]) && is.null(index[[2]])) {\n    keep_features <- dims[[1]][index[[1]]]\n    dataset <- dbGetQuery(\n      con = con,\n      glue_sql(\n        \"SELECT feature_id, sample_id, count\n       FROM read_parquet({data_dir}) \n       WHERE feature_id IN ({keep_features*})\", \n       .con = con)\n    )\n    keep_samples <- unique(dataset$sample_id)\n    # no feature index => return all features\n  } else if (is.null(index[[1]]) && !is.null(index[[2]])) {\n    keep_samples <- dims[[2]][index[[2]]]\n    dataset <- dbGetQuery(\n      con = con,\n      glue_sql(\n        \"SELECT feature_id, sample_id, count\n       FROM read_parquet({data_dir}) \n       WHERE sample_id IN ({keep_samples*})\", \n       .con = con)\n    )\n    keep_features <- unique(dataset$feature_id)\n  } else {\n    keep_features <- dims[[1]][index[[1]]]\n    keep_samples <- dims[[2]][index[[2]]]\n    dataset <- dbGetQuery(\n      con = con,\n      glue_sql(\n        \"SELECT feature_id, sample_id, count\n       FROM read_parquet({data_dir}) \n       WHERE feature_id IN ({keep_features*})AND sample_id IN ({keep_samples*})\n       ORDER BY sample_id, feature_id\", \n       .con = con)\n    ) \n  }\n  # pivot the count data into a regular matrix\n  m <- matrix(\n    data = NA_integer_, \n    nrow = length(keep_features),\n    ncol = length(keep_samples),\n    dimnames = list(keep_features, keep_samples))\n  matrix_index <- cbind(\n    match(dataset$feature_id, row.names(m)), \n    match(dataset$sample_id, colnames(m))\n  )\n  m[matrix_index] <- dataset$count\n  return(m)\n}\n\n.extract_array_from_ParquetArraySeed <- function(x, index) {\n  .get_data(x = x, index = index)\n}\n\nsetMethod(\"extract_array\", \"ParquetArraySeed\", \n          .extract_array_from_ParquetArraySeed)\n```\n:::\n\n\n## Creating a first `ParquetArraySeed` object\n\nWith these three methods in place, I can instantiate my first `ParquetArraySeed`\nobject, which is suitable as input to the `DelayedArray` constructor from\nthe eponymous R package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseed <- ParquetArraySeed(out_dir)\nda <- DelayedArray(seed)\nda\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<53801 x 48> DelayedMatrix object of type \"integer\":\n                   DRN-10415 DRN-10418 DRN-10421 ... DRN-16866 DRN-16867\nENSMUSG00000000001      2754      2764      2907   .      1214      1002\nENSMUSG00000000003         0         0         0   .         0         0\nENSMUSG00000000028        54        61        66   .        39        57\nENSMUSG00000000031         0         0         3   .        16        17\nENSMUSG00000000037         9        50        26   .        58        78\n               ...         .         .         .   .         .         .\nENSMUSG00000116519         0         0         0   .         0         0\nENSMUSG00000116520         0         0         0   .         0         0\nENSMUSG00000116521         0         0         0   .         0         0\nENSMUSG00000116525         3         1         2   .        65        44\nENSMUSG00000116528         0         0         0   .         0         0\n                   DRN-16868\nENSMUSG00000000001       921\nENSMUSG00000000003         0\nENSMUSG00000000028        38\nENSMUSG00000000031        22\nENSMUSG00000000037        33\n               ...         .\nENSMUSG00000116519         0\nENSMUSG00000116520         0\nENSMUSG00000116521         0\nENSMUSG00000116525        45\nENSMUSG00000116528         0\n```\n:::\n:::\n\n\nWhen the object is printed, we are presented with the first couple of rows\nand columns, but most of the data remains on disk (e.g. has not been retrieved\nfrom the parquet files).\n\nSubsetting the `DelayedArray` works as expected, e.g. to retain only samples\nfrom the `tau` study:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# subset to one dataset - using gene and sample identifiers\nda[row.names(tau), colnames(tau)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<53801 x 32> DelayedMatrix object of type \"integer\":\n                   DRN-10415 DRN-10418 DRN-10421 ... DRN-10502 DRN-10505\nENSMUSG00000000001      2754      2764      2907   .      2260      3273\nENSMUSG00000000003         0         0         0   .         0         0\nENSMUSG00000000028        54        61        66   .        16        82\nENSMUSG00000000031         0         0         3   .         0         0\nENSMUSG00000000037         9        50        26   .        11        11\n               ...         .         .         .   .         .         .\nENSMUSG00000116519         0         0         0   .         0         0\nENSMUSG00000116520         0         0         0   .         0         0\nENSMUSG00000116521         0         0         0   .         0         0\nENSMUSG00000116525         3         1         2   .         1         3\nENSMUSG00000116528         0         0         0   .         0         0\n                   DRN-10508\nENSMUSG00000000001      2758\nENSMUSG00000000003         0\nENSMUSG00000000028        47\nENSMUSG00000000031         0\nENSMUSG00000000037         6\n               ...         .\nENSMUSG00000116519         0\nENSMUSG00000116520         0\nENSMUSG00000116521         0\nENSMUSG00000116525         1\nENSMUSG00000116528         0\n```\n:::\n:::\n\n\n## Creating a parquet-backed SummarizedExperiment\n\nFor downstream analyses, it is useful to combine sample- and feature-annotations\nwith the gene expression counts in a single `SummarizedExperiment`.\n\nLet's extract the sample metadata from the original data objects and add a\n`study` column.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npdata <- lapply(c(\"tau\", \"sarm1\"), \\(x) {\n  col_data <- colData(get(x))\n  col_data$study <- x\n  return(col_data)\n  })\npdata <- Reduce(rbind, pdata)\n```\n:::\n\n\nThe original datasets only provide ensembl gene identifiers, so let's retrieve\nthe corresponding gene symbols and entrez identifiers from the\n[Mus.musculus Bioconductor annotation package](https://bioconductor.org/packages/release/data/annotation/html/Mus.musculus.html).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# add Entrez identifiers and gene symbols for both human and mouse genes\nfdata <- DataFrame(\n    ensembl = row.names(da),\n    entrez = mapIds(Mus.musculus, \n                    row.names(da), \n                    column = \"ENTREZID\", \n                    keytype = \"ENSEMBL\", \n                    multiVals = \"first\"),\n    symbol = mapIds(Mus.musculus, \n                    row.names(da), \n                    column = \"SYMBOL\", \n                    keytype = \"ENSEMBL\", \n                    multiVals = \"first\"),\n    row.names = row.names(da)\n)\n```\n:::\n\n\nNow we are ready to compose meta- and gene expression data into a single\nobject:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nse <- SummarizedExperiment(\n  assays = list(counts = da), \n  rowData = fdata[row.names(da), ],\n  colData = pdata[colnames(da),,drop=FALSE ]\n)\nse\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nclass: SummarizedExperiment \ndim: 53801 48 \nmetadata(0):\nassays(1): counts\nrownames(53801): ENSMUSG00000000001 ENSMUSG00000000003 ...\n  ENSMUSG00000116525 ENSMUSG00000116528\nrowData names(3): ensembl entrez symbol\ncolnames(48): DRN-10415 DRN-10418 ... DRN-16867 DRN-16868\ncolData names(2): group study\n```\n:::\n\n```{.r .cell-code}\ntable(se$study)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nsarm1   tau \n   16    32 \n```\n:::\n:::\n\n\nAt this point, we still haven't retrieved the actual counts from the parquet\nfiles, e.g. they information is still on disk. It will automatically be\nretrieved when downstream functions coerce the `DelayedArray` into a regular\nmatrix. For example, \n[edgeR's calcNormFactors function](https://rdrr.io/bioc/edgeR/man/calcNormFactors.html)\naccepts a SummarizedExperiment and returns a `DGEList`, ready for exploratory\nanalysis e.g. multi-dimensional scaling.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny <- edgeR::calcNormFactors(se[, se$study == \"tau\"])\ny$samples$genotype <- factor(\n  ifelse(grepl(\"WT_\", y$samples$group), \"WT\", \"Transgenic\")\n)\ncolors <- palette.colors(n = nlevels(y$samples$genotype), \n                         palette = \"Set1\")[as.integer(y$samples$genotype)]\nlimma::plotMDS(y, col = colors, pch = 19)\nlegend(\"topright\", legend = levels(y$samples$genotype), bty = \"n\", pch = 19, \n       col = palette.colors(n = nlevels(y$samples$genotype), palette = \"Set1\"),\n       y.intersp=2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=384}\n:::\n:::\n\n\n## Summary\n\nBecause the `DelayedArray` package is so thoughtfully designed, it was\nsurprisingly straightforward to represent data stored in parquet files as a\nmatrix. This way, I can leverage familiar Bioconductor tools _and_ take\nadvantage of the language-agnostic file format.\n\nA few directions and caveats that I haven't explored, yet:\n\n- In this example, I am generating one parquet file for each of the studies,\n  e.g. I am manually partitioning the data by `study`. When I want to\n  retrieve all data for one of the studies, I could simply parse _only_ the\n  corresponding parquet file, instead of querying & filtering all files in\n  the directory (as a \n  [Dataset](https://arrow.apache.org/docs/r/articles/dataset.html#opening-datasets)\n  ).\n- My parquet files are stored on the local system. Accessing them in a cloud\n  storage location (e.g. on AWS S3) is supported by `duckdb` as well, but\n  network speed will likely become limiting. I will explore the use of\n  `AWS Athena`, a cloud-based SQL database, in a future post, as shown e.g. in \n  [this AWS blog post](https://aws.amazon.com/blogs/industries/fast-queries-of-scrnaseq-datasets-with-amazon-athena/).\n- The parquet files I generated here are relatively small, e.g. ~ 5 Mb,\n  reflecting the relatively small size of the example bulk RNA-seq datasets.\n  The\n  [arrow project recommends](https://arrow.apache.org/docs/r/articles/dataset.html#partitioning-performance-considerations)\n  avoiding accessing many files smaller than 20MB, but that's likely not a\n  problem until I need to handle thousands of studies.\n- Disk-backed arrays are great if computations can be performed on small chunks\n  of data, e.g. to visualize a subset of feature and / or samples. When it is \n  necessary to realize the full dataset in memory, the `DelayedArray` returns\n  a conventional matrix - e.g. sparse representations don't seem to be supported\n  right now (as far as I can tell).\n- Finally, I have only implemented three essential methods, but have not touched\n  on any optimized backend-specific methods. For example, we could issue a SQL\n  query to calculate `max` or `colSums` values instead of loading the full\n  data matrix into our R session. (This might be especially interesting if\n  the database engine is running on a remote server.)\n\nLots more to learn - and a big thank you to\n[Hervé Pagès](https://www.linkedin.com/in/herv%C3%A9-pag%C3%A8s-5038527)\nand the entire Bioconductor team!\n\n## Reproducibility\n\n<details>\n<summary>\nSession Information\n</summary>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessioninfo::session_info(\"attached\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.1 (2023-06-16)\n os       Debian GNU/Linux 12 (bookworm)\n system   x86_64, linux-gnu\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Los_Angeles\n date     2023-09-05\n pandoc   3.1.1 @ /usr/lib/rstudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package                            * version    date (UTC) lib source\n P abind                              * 1.4-5      2016-07-21 [?] CRAN (R 4.3.1)\n P AnnotationDbi                      * 1.62.2     2023-07-02 [?] Bioconductor\n P arrow                              * 13.0.0     2023-08-30 [?] CRAN (R 4.3.1)\n P Biobase                            * 2.60.0     2023-04-25 [?] Bioconductor\n P BiocGenerics                       * 0.46.0     2023-04-25 [?] Bioconductor\n P DBI                                * 1.1.3      2022-06-18 [?] CRAN (R 4.3.1)\n P DelayedArray                       * 0.26.7     2023-07-28 [?] Bioconductor\n P DESeq2                             * 1.40.2     2023-06-23 [?] Bioconductor\n P dplyr                              * 1.1.2      2023-04-20 [?] CRAN (R 4.3.1)\n P duckdb                             * 0.8.1-2    2023-08-25 [?] CRAN (R 4.3.1)\n P edgeR                              * 3.42.4     2023-05-31 [?] Bioconductor\n P GenomeInfoDb                       * 1.36.1     2023-06-21 [?] Bioconductor\n P GenomicFeatures                    * 1.52.2     2023-08-25 [?] Bioconductor\n P GenomicRanges                      * 1.52.0     2023-04-25 [?] Bioconductor\n P glue                               * 1.6.2      2022-02-24 [?] CRAN (R 4.3.1)\n P GO.db                              * 3.17.0     2023-09-04 [?] Bioconductor\n P IRanges                            * 2.34.1     2023-06-22 [?] Bioconductor\n P limma                              * 3.56.2     2023-06-04 [?] Bioconductor\n P Matrix                             * 1.5-4.1    2023-05-18 [?] CRAN (R 4.3.1)\n P MatrixGenerics                     * 1.12.3     2023-07-30 [?] Bioconductor\n P matrixStats                        * 1.0.0      2023-06-02 [?] CRAN (R 4.3.1)\n P Mus.musculus                       * 1.3.1      2023-09-04 [?] Bioconductor\n P org.Mm.eg.db                       * 3.17.0     2023-09-04 [?] Bioconductor\n P OrganismDbi                        * 1.42.0     2023-04-25 [?] Bioconductor\n P rnaseqExamples                     * 0.0.0.9000 2023-09-04 [?] Github (tomsing1/rnaseq-Examples@ac35304)\n P S4Arrays                           * 1.0.5      2023-07-24 [?] Bioconductor\n P S4Vectors                          * 0.38.1     2023-05-02 [?] Bioconductor\n P SummarizedExperiment               * 1.30.2     2023-06-06 [?] Bioconductor\n P tibble                             * 3.2.1      2023-03-20 [?] CRAN (R 4.3.1)\n P tidyr                              * 1.3.0      2023-01-24 [?] CRAN (R 4.3.1)\n P TxDb.Mmusculus.UCSC.mm10.knownGene * 3.10.0     2023-09-04 [?] Bioconductor\n\n [1] /home/sandmann/repositories/blog/renv/library/R-4.3/x86_64-pc-linux-gnu\n [2] /home/sandmann/.cache/R/renv/sandbox/R-4.3/x86_64-pc-linux-gnu/9a444a72\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────\n```\n:::\n:::\n\n\n</details>\n   ",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}