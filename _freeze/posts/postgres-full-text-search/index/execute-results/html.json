{
  "hash": "dd48218985804b10d062cdadddfa18e8",
  "result": {
    "markdown": "---\ntitle: \"Full text search in Postgres - the R way\"\nauthor: \"Thomas Sandmann\"\ndate: \"2022-12-12\"\nfreeze: true\ncategories: [TIL, R, postgres]\neditor: \n  markdown: \n    wrap: 72\n---\n\n\nI have been learning how to organize, search and modify data in a \n[Postgres](https://www.postgresql.org/) \ndatabase by working through \n[Anthony DeBarros'](https://www.wsj.com/news/author/anthony-debarros) \nexcellent book \n[Practical SQL](https://nostarch.com/practical-sql-2nd-edition).\n\nBecause I currently perform most of my data analyses in R, I am using the \ngreat \n[RPostgres](https://cran.r-project.org/package=RPostgres),\n[DBI](https://cran.r-project.org/package=DBI)\nand\n[glue](https://cran.r-project.org/package=glue)\npackages to interface with Postgres - without ever leaving my R session. \n\nToday I learned how to create a full text search index and how to search it\nwith one or more search terms.\n\n## Connecting to Postgres\n\nFor this example, I created a toy database `full_text_search` in my local\nPostgres server. I connect to it with the `DBI::dbConnect` command, and by \npassing it the `RPostgres::Postgres()` driver.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DBI)\nlibrary(glue)\nlibrary(RPostgres)\nlibrary(sessioninfo)\n\n# Connect to a (prexisting) postgres database called `full_text_search`\ncon <- DBI::dbConnect(\n  dbname = \"full_text_search\",\n  drv = RPostgres::Postgres(),\n  host = \"localhost\",\n  port = 5432L,\n  user = \"postgres\"\n  )\n```\n:::\n\n\n## Creating and populating a table\n\nBecause this is a toy example, I start with a fresh table `datasets`. (In case\nit already exists from previous experimentation, I drop the table if necessary).\n\nLet's define four fields for the table:\n\n- `id`: the unique identifier\n- `name`: the short name of each entry\n- `title`: a longer title\n- `description`: a paragraph describing the entry\n- `created`: a date and time the entry was added to the database \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# drop the `datasets` table if it already exists\nif (DBI::dbExistsTable(con, \"datasets\")) DBI::dbRemoveTable(con, \"datasets\")\n\n# create the empty `datasets` table\nsql <- glue_sql(\"\n      CREATE TABLE IF NOT EXISTS datasets (\n      id bigserial PRIMARY KEY,\n      name text,\n      title text,\n      description text,\n      created timestamp with time zone default current_timestamp not null\n    );\", .con = con)\nres <- suppressMessages(DBI::dbSendStatement(con, sql))\nDBI::dbClearResult(res)\nDBI::dbReadTable(con, \"datasets\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] id          name        title       description created    \n<0 rows> (or 0-length row.names)\n```\n:::\n:::\n\n\nInitially, our new database is empty. Let's populate them with three entries,\neach describing a popular dataset shipped with R's built-in\n[datasets](https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html)\npackage.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# some example entries\nbuildin_datasets <- list(\n  mtcars = list(\n    \"name\" = \"mtcars\", \n    \"title\" = \"The built-in mtcars dataset from the datasets R package.\",\n    \"description\" = gsub(\n      \"\\r?\\n|\\r\", \" \", \n      \"The data was extracted from the 1974 Motor Trend US magazine, and \ncomprises fuel consumption and 10 aspects of automobile design and\nperformance for 32 automobiles (1973–74 models).\")\n  ), \n  airmiles = list(\n    name = \"airmiles\",\n    title = \"The built-in airmiles dataset from the datasets R package\",\n    description = gsub(\n      \"\\r?\\n|\\r\", \" \", \n      \"The revenue passenger miles flown by commercial airlines in the United\nStates for each year from 1937 to 1960.\")\n  ),\n  attitude = list(\n    name = \"attitude\", \n    title = \"The built-in attitude dataset from the datasets R package\",\n    description = gsub(\n      \"\\r?\\n|\\r\", \" \", \n      \"From a survey of the clerical employees of a large financial\norganization, the data are aggregated from the questionnaires of the\napproximately 35 employees for each of 30 (randomly selected) departments. \nThe numbers give the percent proportion of favourable responses to seven\nquestions in each department.\")\n  )\n)\n```\n:::\n\n\nNext, we loop over each element of the list and use the `glue_sql()` command\nto unpack both the names (`names(dataset)`) and the values of each field for \nthis entry. Then we update the `datasets` table with this new information.\n\nAfterward, we retrieve the `name` and `title` fields to verify the\ncorrect import:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor (dataset in buildin_datasets) {\n  sql <- glue_sql(\n    \"INSERT INTO datasets ({`names(dataset)`*})\n   VALUES ({dataset*});\", \n    .con = con)\n  res <- suppressMessages(DBI::dbSendStatement(con, sql))\n  DBI::dbClearResult(res)\n}\nDBI::dbGetQuery(con, \"SELECT name, title from datasets;\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      name                                                     title\n1   mtcars  The built-in mtcars dataset from the datasets R package.\n2 airmiles The built-in airmiles dataset from the datasets R package\n3 attitude The built-in attitude dataset from the datasets R package\n```\n:::\n:::\n\n\n## Creating a tokenized index for full-text searches\n\nMy goal is to enable full-text search for the `description` field. First, we \nneed to add a `tsvector` field and populate it with the tokenized contents \nof each `description`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a column to hold tokens for full text search\nsql <- glue_sql(\n  \"ALTER TABLE datasets\n   ADD COLUMN search_description_text tsvector;\", \n  .con = con)\nres <- suppressMessages(DBI::dbSendStatement(con, sql))\nDBI::dbClearResult(res)\nDBI::dbListFields(con, \"datasets\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"id\"                      \"name\"                   \n[3] \"title\"                   \"description\"            \n[5] \"created\"                 \"search_description_text\"\n```\n:::\n:::\n\n\nAt this point, the `search_description_text` field is still empty. Let's \ncopy the `descriptions` into it - and tokenize them at the same time. For \nillustration, we retrieve the tokens for the first dataset:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# copy the description into search tokens\nsql <- glue_sql(\n  \"UPDATE datasets\n   SET search_description_text = to_tsvector('english', description);\", \n  .con = con)\nDBI::dbExecute(con, sql)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3\n```\n:::\n\n```{.r .cell-code}\nDBI::dbGetQuery(con, \n                \"SELECT name, search_description_text from datasets LIMIT 1;\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    name\n1 mtcars\n                                                                                                                                                                                          search_description_text\n1 '10':17 '1973':27 '1974':7 '32':25 '74':28 'aspect':18 'automobil':20,26 'compris':13 'consumpt':15 'data':2 'design':21 'extract':4 'fuel':14 'magazin':11 'model':29 'motor':8 'perform':23 'trend':9 'us':10\n```\n:::\n:::\n\n\nTo speed up the full-text search, we add a\n[Generalized Inverted Index (GIN)](https://www.postgresql.org/docs/current/gin-intro.html#:~:text=GIN%20stands%20for%20Generalized%20Inverted,appear%20within%20the%20composite%20items.)\nindex for the `search_description_text` column as well:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create the search index\nsql <- glue_sql(\n  \"CREATE INDEX search_description_idx\n   ON datasets\n   USING gin(search_description_text);\",\n  .con = con)\nDBI::dbExecute(con, sql)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\n## Searching!\n\nNow we are ready to perform our first search. Let's look up the term `data` in\nthe `description` fields. (The `ts_headline` command returns the location of the\nmatch, e.g. the context it was found in.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# search the description field and show the matching location\nterm <- \"data\"\nsql <- glue_sql(\n  \"SELECT id, name,\n  ts_headline(description, to_tsquery('english', {term}),\n     'StartSel = <,\n      StopSel = >,\n      MinWords = 5,\n      MaxWords = 7,\n      MaxFragments = 1')\n  FROM datasets\n  WHERE search_description_text @@ to_tsquery('english', {term})\n  ORDER BY created;\",\n  .con = con)\nres <- suppressMessages(DBI::dbSendStatement(con, sql))\nDBI::dbFetch(res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  id     name                                            ts_headline\n1  1   mtcars               <data> was extracted from the 1974 Motor\n2  3 attitude financial organization, the <data> are aggregated from\n```\n:::\n\n```{.r .cell-code}\nDBI::dbClearResult(res)\n```\n:::\n\n\nWe can also combine search terms, e.g. searching for either `employee` _or_ \n`motor` terms:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# using multiple search terms\nterm <- \"employee | motor\"  # OR\nsql <- glue_sql(\n  \"SELECT id, name,\n  ts_headline(description, to_tsquery('english', {term}),\n     'StartSel = <,\n      StopSel = >,\n      MinWords = 5,\n      MaxWords = 7,\n      MaxFragments = 1')\n  FROM datasets\n  WHERE search_description_text @@ to_tsquery('english', {term})\n  ORDER BY created;\",\n  .con = con)\nres <- suppressMessages(DBI::dbSendStatement(con, sql))\nDBI::dbFetch(res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  id     name                                            ts_headline\n1  1   mtcars                from the 1974 <Motor> Trend US magazine\n2  3 attitude clerical <employees> of a large financial organization\n```\n:::\n\n```{.r .cell-code}\nDBI::dbClearResult(res)\n```\n:::\n\n\nSimilarly, we can narrow our search by requiring both `data` _and_ `employee`\nterms to appear in the same description:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nterm <- \"data & employee\"  # AND\nsql <- glue_sql(\n  \"SELECT id, name,\n  ts_headline(description, to_tsquery('english', {term}),\n     'StartSel = <,\n      StopSel = >,\n      MinWords = 5,\n      MaxWords = 7,\n      MaxFragments = 1')\n  FROM datasets\n  WHERE search_description_text @@ to_tsquery('english', {term})\n  ORDER BY created;\",\n  .con = con)\nres <- suppressMessages(DBI::dbSendStatement(con, sql))\nDBI::dbFetch(res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  id     name                                            ts_headline\n1  3 attitude clerical <employees> of a large financial organization\n```\n:::\n\n```{.r .cell-code}\nDBI::dbClearResult(res)\n```\n:::\n\n\nThat's it. Thanks again to \n[Anthony DeBarros'](https://www.wsj.com/news/author/anthony-debarros) \nfor his excellent introduction to \n[Practical SQL](https://nostarch.com/practical-sql-2nd-edition)!\n\n## Reproducibility\n\n<details>\n\n::: {.cell}\n\n```{.r .cell-code}\nsessioninfo::session_info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Los_Angeles\n date     2022-12-12\n pandoc   2.19.2 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n askpass       1.1     2019-01-13 [1] CRAN (R 4.2.0)\n bit           4.0.5   2022-11-15 [1] CRAN (R 4.2.0)\n bit64         4.0.5   2020-08-30 [1] CRAN (R 4.2.0)\n blob          1.2.3   2022-04-10 [1] CRAN (R 4.2.0)\n cli           3.4.1   2022-09-23 [1] CRAN (R 4.2.0)\n credentials   1.3.2   2021-11-29 [1] CRAN (R 4.2.0)\n DBI         * 1.1.3   2022-06-18 [1] CRAN (R 4.2.0)\n digest        0.6.30  2022-10-18 [1] CRAN (R 4.2.0)\n ellipsis      0.3.2   2021-04-29 [1] CRAN (R 4.2.0)\n evaluate      0.18    2022-11-07 [1] CRAN (R 4.2.0)\n fastmap       1.1.0   2021-01-25 [1] CRAN (R 4.2.0)\n generics      0.1.3   2022-07-05 [1] CRAN (R 4.2.0)\n glue        * 1.6.2   2022-02-24 [1] CRAN (R 4.2.0)\n hms           1.1.2   2022-08-19 [1] CRAN (R 4.2.0)\n htmltools     0.5.4   2022-12-07 [1] CRAN (R 4.2.0)\n htmlwidgets   1.5.4   2021-09-08 [1] CRAN (R 4.2.0)\n jsonlite      1.8.4   2022-12-06 [1] CRAN (R 4.2.0)\n knitr         1.41    2022-11-18 [1] CRAN (R 4.2.0)\n lifecycle     1.0.3   2022-10-07 [1] CRAN (R 4.2.0)\n lubridate     1.9.0   2022-11-06 [1] CRAN (R 4.2.0)\n magrittr      2.0.3   2022-03-30 [1] CRAN (R 4.2.0)\n openssl       2.0.5   2022-12-06 [1] CRAN (R 4.2.0)\n pkgconfig     2.0.3   2019-09-22 [1] CRAN (R 4.2.0)\n Rcpp          1.0.9   2022-07-08 [1] CRAN (R 4.2.0)\n rlang         1.0.6   2022-09-24 [1] CRAN (R 4.2.0)\n rmarkdown     2.18    2022-11-09 [1] CRAN (R 4.2.0)\n RPostgres   * 1.4.4   2022-05-02 [1] CRAN (R 4.2.0)\n rstudioapi    0.14    2022-08-22 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n stringi       1.7.8   2022-07-11 [1] CRAN (R 4.2.0)\n stringr       1.5.0   2022-12-02 [1] CRAN (R 4.2.0)\n sys           3.4.1   2022-10-18 [1] CRAN (R 4.2.0)\n timechange    0.1.1   2022-11-04 [1] CRAN (R 4.2.0)\n vctrs         0.5.1   2022-11-16 [1] CRAN (R 4.2.0)\n xfun          0.35    2022-11-16 [1] CRAN (R 4.2.0)\n yaml          2.3.6   2022-10-18 [1] CRAN (R 4.2.0)\n\n [1] /Users/sandmann/Library/R/x86_64/4.2/library\n [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n```\n:::\n:::\n\n</details>",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}