[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Installing pyroe with conda",
    "section": "",
    "text": "Image credits: tOrange.biz, CC BY 4.0, via Wikimedia Commons"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is Thomas Sandmann’s personal blog, created with Quarto. I am planning to share e.g. “Things I learned today” (TIL) and other pieces of news around Computational Biolgy and Data Science."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\nReading Time\n\n\n\n\n\n\nJan 2, 2023\n\n\nSQL and noSQL approaches to creating & querying databases (using R)\n\n\nThomas Sandmann\n\n\n12 min\n\n\n\n\n\nDec 27, 2022\n\n\nInteractive GSEA results: visualizations with reactable & plotly\n\n\nThomas Sandmann\n\n\n25 min\n\n\n\n\nDec 24, 2022\n\n\nUpSet plots: comparing differential expression across contrasts\n\n\nThomas Sandmann\n\n\n7 min\n\n\n\n\nDec 22, 2022\n\n\nFigure size, layout & tabsets with Quarto\n\n\nThomas Sandmann\n\n\n1 min\n\n\n\n\nDec 12, 2022\n\n\nFull text search in Postgres - the R way\n\n\nThomas Sandmann\n\n\n10 min\n\n\n\n\nDec 11, 2022\n\n\nUpdating R the easy way: using rig command line tool\n\n\nThomas Sandmann\n\n\n1 min\n\n\n\n\nDec 10, 2022\n\n\n2022 normconf: lightning talks\n\n\nThomas Sandmann\n\n\n0 min\n\n\n\n\nDec 8, 2022\n\n\nThe rlist R package\n\n\nThomas Sandmann\n\n\n0 min\n\n\n\n\nNov 17, 2022\n\n\nCreating custom badges for your README\n\n\nThomas Sandmann\n\n\n0 min\n\n\n\n\nNov 15, 2022\n\n\nLearning nextflow: blasting multiple sequences\n\n\nThomas Sandmann\n\n\n7 min\n\n\n\n\nNov 14, 2022\n\n\nPython type hints\n\n\nThomas Sandmann\n\n\n0 min\n\n\n\n\nNov 13, 2022\n\n\nFujita et al: Cell-subtype specific effects of genetic variation in the aging and Alzheimer cortex\n\n\nThomas Sandmann\n\n\n2 min\n\n\n\n\nNov 13, 2022\n\n\nRefreshing & exporting temporary AWS credentials\n\n\nThomas Sandmann\n\n\n2 min\n\n\n\n\nNov 12, 2022\n\n\nInstalling pyroe with conda\n\n\nThomas Sandmann\n\n\n0 min\n\n\n\n\nNov 12, 2022\n\n\nWelcome To My Blog\n\n\nThomas Sandmann\n\n\n0 min\n\n\n\n\n\n\nNo matching items\n\nThis work is licensed under a Creative Commons Attribution 4.0 International License."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to Thomas Sandmann’s blog. Originally from Germany, my professional journey includes a degree in Biochemistry, a PhD in Developmental Biology from EMBL, postdoctoral research at Temasek Lifescience Laboratories and at the German Cancer research Center. Afterwards, I worked as a Computational Biologist at Genentech and Verily. In 2016 I joined Denali Therapeutics, where I am collaborating with colleagues across the organization to generate, analyze and understand genomics & genetics data.\nThis blog collects the personal lessons I am learning along the way.  (Opinions are my own and not the views of my employer.)\n\n\nThis work is licensed under a Creative Commons Attribution 4.0 International License."
  },
  {
    "objectID": "posts/pyroe-installation/index.html",
    "href": "posts/pyroe-installation/index.html",
    "title": "Installing pyroe with conda",
    "section": "",
    "text": "Alevin-fry is a highly accurate and performant method to process single-cell or single-nuclei RNA-seq data. For downstream processing, its output can be parsed into R with the fishpond::loadFry() function. For analysis using python, the pyroe module is available.\nIt can be installed either using pip or conda, and the latter will install additional dependencies (e.g. bedtools) and include the load_fry() as well.\nTo install pyroe with conda, I first followed bioconda’s instructions to add and configure the required channels:\nconda config --add channels defaults\nconda config --add channels bioconda\nconda config --add channels conda-forge\nconda config --set channel_priority strict\nand then installed pyroe\nconda install pyroe\nNow I can convert alevin-fry output to one of the following formats: zarr, csvs, h5ad or loom.\npyroe convert --help"
  },
  {
    "objectID": "posts/aws-export-credentials/index.html",
    "href": "posts/aws-export-credentials/index.html",
    "title": "Refreshing & exporting temporary AWS credentials",
    "section": "",
    "text": "Today I learned how to configure and refresh these credentials in the command line, as well how to export them either as environmental variables or write them to the credentials file where tools that do not interact with AWS SSO natively can access them.\n\nConfiguring an AWS SSO profile\nFirst, we need to configure a named profile for use with AWS SSO. The following AWS CLI version 2 command will interactively walk you through the necessary steps:\naws configure sso\nThe information you provide will be written to the config file, located in the ~/.aws directory on Mac OS. Here is an example:\n[profile my-dev-profile]\nsso_start_url = https://my-sso-portal.awsapps.com/start\nsso_region = us-east-1\nsso_account_id = 123456789011\nsso_role_name = readOnly\nregion = us-west-2\noutput = json\n\n\nLogging into the AWS SSO profile\nNow we can log into AWS SSO and request temporary credentials:\naws sso login --profile my-dev-profile\nThis command will try to open a web browser for you and prompt you to confirm the login. Alternatively, you can copy & paste the displayed URL and manually enter the confirmation code output by the command.\nIf the login was successful, you can now adopt the my-dev-profile when using the AWS CLI, e.g.\naws s3 ls --profile my-dev-profile\nThe AWS SSO endpoint recognizes many environmental variables that you can use to specify defaults, e.g.\n\nAWS_PROFILE: The profile to use (e.g. my-dev-profile)\nAWS_SHARED_CREDENTIALS_FILE: the location of the shared credentials files (default on Mac OS: ~/.aws/.credentials)\nAWS_CONFIG_FILE: the location of the AWS CLI configuration file (default on Mac OS: ~/.aws.config)\n\n\n\nAccessing temporary credentials\nThe AWS CLI and many of the AWS SKDs will automatically detect and use SSO credentials. But other tools might not (yet) be compatible with this authentication route. Instead, they might\n\nread credentials for a profile from the credentials file\nrely on environmental variables, e.g. AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY\n\nTo expose the temporary credentials, Ben Kehoe has made the aws-export-credentials tool available.\n\n\nInstalling aws-export-credentials\nThe recommended way to install aws-export-credentials is via pipx because it will automatically make it available in your PATH.\n\nIf you don’t have pipx available on your system, install it first.\nNext, install aws-export-credentials by executing the following steps in your shell:\n\npipx ensurepath  # in case you haven't run this before\npipx install aws-export-credentials\naws-export-credentials --version  # verify the installation\n\n\nUpdating the credentials file\nAt the beginning of your workday - or whenever needed - run the following set of commands. (Replace the SSO profile with the one you want to adopt.)\nPROFILE=\"my-dev-profile\"\n\n# retrieve new credentials from AWS\naws sso login --profile \"${PROFILE}\"\n\n# write the temporary credentials to the ~/.aws/credentials file\naws-export-credentials \\\n  --profile \"${PROFILE}\" \\\n  --credentials-file-profile \"${PROFILE}\"\nThis will refresh the credentials (via aws sso login) and then write them to the my-dev-profile profiles in the ~/.aws/.credentials file. Now we can access them e.g. in the aws.s3 R package:\nlibrary(aws.s3)\nlibrary(aws.signature)\naws.signature::use_credentials(profile = \"my-dev-profile\")\naws.s3::bucketlist()\n\n\nExposing environmental variables\nSome tools only recognize environmental variables. Luckily, aws-export-credentials can automate this process, too:\nexport $(aws-export-credentials --profile my-dev-profile --env-export)\nwill export AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY variables in your shell session.\n\n\nSourcing credentials with an external process\nFinally, you can also include a command that looks up credentials as a credential_process in your config file. (More information here) But that’s not a use case I have explored, yet."
  },
  {
    "objectID": "posts/fujita_2022/index.html",
    "href": "posts/fujita_2022/index.html",
    "title": "Fujita et al: Cell-subtype specific effects of genetic variation in the aging and Alzheimer cortex",
    "section": "",
    "text": "Fujita et al, Figure 1A/B: (A) Schema of the study. (B) UMAP visualization of 1,509,626 nuclei from 424 donors. Each of the seven major cell types is labeled with a different color.”\n\n\n\nThis large sample size enabled them to assess the effect of genetic variation (e.g. single-nucleotide variants) on gene expression - one cell type at a time. The authors created pseudo-bulk gene expression profiles for each patient for 7 cell types and 81 cell subtypes.\nBecause neurons are highly abundant in the DLPFC, the largest number of nuclei originated from neurons, and the statistical power to detect eQTLs was lower in rarer cell types (e.g. microglia). This highlights the potential of enrichment methods, e.g. by fluorescent activate nuclei sorting (FANS) approached. (See e.g. (Kamath et al. 2022), who specifically enriched dopaminergic neurons or (Sadick et al. 2022), who enriched astrocytes and oligodendrocytes.)\nFujita et al were able to identify ~ 10,000 eGenes1, about half of which were shared across cell types. For example, they identified a novel eQTL (rs128648) for the APOE gene specifically in microglia.\nHaving identified novel eQTL relationships in vivo, the authors then used bulk RNA-seq measurements from a panel of induced pluripotent stem cells that had been differentiated either into neurons (iNeurons) or astrocytes (iAstrocytes) to test whether they could also observe the variants’ effects in vitro.\nDespite a relatively small sample size, a subset of eQTLs were replicated. But the the authors also point out unexpected discrepancies in the MAPT locus where they observed variant effects in the opposite direction from what they had observed by snRNA-seq.\nGene expression was significantly heritable in most cell types (except for those from which only small numbers of nuclei had been sampled). This allowed the authors to use their snRNA-seq dataset to impute cell type specific gene expression for large GWAS studies, e.g. for Alzheimer’s Disease, ALS, Parkinson’s Disease, and schizophrenia. This TWAS analysis detected e.g. 48 novel loci associated with AD in microglia, 22 of which had not been implicated previously.\nIn summary, this work by Fujita et al is an impressive achievement, demonstrating that single-cell/single-nuclei approaches have now become sufficiently scalable to power human genetics analyses.\nThe authors have already made the raw data for their study available on the AD Knowledge Portal. Thank you for sharing your data!\n\n\n\n\n\nReferences\n\nFujita, Masashi, Zongmei Gao, Lu Zeng, Cristin McCabe, Charles C. White, Bernard Ng, Gilad Sahar Green, et al. n.d. “Cell-Subtype Specific Effects of Genetic Variation in the Aging and Alzheimer Cortex.” https://doi.org/10.1101/2022.11.07.515446.\n\n\nKamath, Tushar, Abdulraouf Abdulraouf, S. J. Burris, Jonah Langlieb, Vahid Gazestani, Naeem M. Nadaf, Karol Balderrama, Charles Vanderburg, and Evan Z. Macosko. 2022. “Single-Cell Genomic Profiling of Human Dopamine Neurons Identifies a Population That Selectively Degenerates in Parkinson’s Disease.” Nature Neuroscience, May, 1–8. https://doi.org/10.1038/s41593-022-01061-1.\n\n\nSadick, Jessica S., Michael R. O’Dea, Philip Hasel, Taitea Dykstra, Arline Faustin, and Shane A. Liddelow. 2022. “Astrocytes and Oligodendrocytes Undergo Subtype-Specific Transcriptional Changes in Alzheimer’s Disease.” Neuron, April, S0896627322002446. https://doi.org/10.1016/j.neuron.2022.03.008.\n\nFootnotes\n\n\nGene whose expression was significantly associated with one or more genetic variants (FDR < 5%)↩︎"
  },
  {
    "objectID": "posts/python-hints/index.html",
    "href": "posts/python-hints/index.html",
    "title": "Python type hints",
    "section": "",
    "text": "Today I learned about python type hints (again…) as I was tackling the first parts of pybites’ FastAPI learning track. The following resources were great to get a quick overview:\n\nCode Better with Type Hints – Part 1\nCode Better with Type Hints – Part 2\nFastAPI’s typing introduction\nPysheet: typing"
  },
  {
    "objectID": "posts/nextflow-blast-tutorial/index.html",
    "href": "posts/nextflow-blast-tutorial/index.html",
    "title": "Learning nextflow: blasting multiple sequences",
    "section": "",
    "text": "To start learning nextflow, I worked through Andrew Severin’s excellent Creating a NextFlow workflow tutorial. (The tutorial follows the older DSL1 specification of nextflow, but only a few small modifications were needed to run it under DSL2.)\nThe DSL2 code I wrote is here and these are notes I took while working through the tutorial:\n\nTo make a variable a pipeline parameter prepend it with params., then specify them in the command line:\nmain.nf:\n#! /usr/bin/env nextflow\nparams.query=\"file.fasta\"\nprintln \"Querying file $params.query\"\nshell command:\nnextflow run main.nf --query other_file.fasta\nThe -log argument directs logging to the specified file.\nnextflow -log nextflo.log run main.nf \nTo clean up intermediate files automatically upon workflow completion, use the cleanup parameter within a profile.\nprofiles {\n  standard {\n      cleanup = true\n  }\n  debug {\n      cleanup = false\n  }\n}\n\nBy convention the standard profile is implicitly used when no other\nprofile is specified by the user.\nCleaning up intermediate files precludes the use of -resume.\n\nThe nextflow.config file sets the global parameters, e.g.\n\nprocess\nmanifest\nexecutor\nprofiles\ndocker\nsingularity\ntimeline\nreport\netc\n\nContents of the work folder for a nextflow task:\n\n.command.begin is the begin script if you have one\n.command.err is useful when it crashes.\n.command.run is the full nextflow pipeline that was run, this is helpful when trouble shooting a nextflow error rather than the script error.\n.command.sh shows what was run.\n.exitcode will have the exit code in it.\n\nDisplaying help messages\nmain.nf\ndef helpMessage() {\nlog.info \"\"\"\n      Usage:\n      The typical command for running the pipeline is as follows:\n      nextflow run main.nf --query QUERY.fasta --dbDir \"blastDatabaseDirectory\" --dbName \"blastPrefixName\"\n\n      Mandatory arguments:\n       --query                        Query fasta file of sequences you wish to BLAST\n       --dbDir                        BLAST database directory (full path required)\n       [...]\n\"\"\"\n}\n\n// Show help message\nif (params.help) {\n    helpMessage()\n    exit 0\n}\nshell command:\nnextflow run main.nf --help\nThe publishDir directive accepts arguments like mode and pattern to fine tune its behavior, e.g.\noutput:\nfile(\"${label}/short_summary.specific.*.txt\")\npublishDir \"${params.outdir}/BUSCOResults/${label}/\", mode: 'copy', pattern: \"${label}/short_summary.specific.*.txt\"\nDSL2 allows piping, e.g.\nworkflow {\n  res = Channel\n      .fromPath(params.query)\n      .splitFasta(by: 1, file:true) |\n      runBlast\n  res.collectFile(name: 'blast_output_combined.txt', storeDir: params.outdir)\n}\nAdd a timeline report to the output with\ntimeline {\n    enabled = true\n    file = \"$params.outdir/timeline.html\"\n}\n(in nextflow.config).\nAdd a detailed execution report with\nreport {\nenabled = true\nfile = \"$params.outdir/report.html\"\n}\n(in nextflow.config).\nInclude a profile-specific configuration file\nnextflow.config\nprofiles {\n    slurm { includeConfig './configs/slurm.config' }\n}\nconfigs/slurm.config\nprocess {\n    executor = 'slurm'\n    clusterOptions =  '-N 1 -n 16 -t 24:00:00'\n}\nand use it via nextflow run main.nf -profile slurm\nSimilarly, refer to a test profile, specified in a separate file:\nnextflow.config\ntest { includeConfig './configs/test.config' }\nAdding a manifest to nextflow.config\nmanifest {\n    name = 'isugifNF/tutorial'\n    author = 'Andrew Severin'\n    homePage = 'www.bioinformaticsworkbook.org'\n    description = 'nextflow bash'\n    mainScript = 'main.nf'\n    version = '1.0.0'\n}\nUsing a label for a process allows granular control of a process’ configuration\nmain.nf\nprocess runBlast { \n    label 'blast'\n}\nnextflow.config\nprocess {\n    executor = 'slurm'\n    clusterOptions =  '-N 1 -n 16 -t 02:00:00'\n    withLabel: blast { module = 'blast-plus' }\n}\n\nThe label has to be placed before the input section.\n\nLoading a module specifically for a process\nprocess runBlast {\n\n    module = 'blast-plus'\n    publishDir \"${params.outdir}/blastout\"\n\n    input:\n    path queryFile from queryFile_ch\n    .\n    .\n    . // these three dots mean I didn't paste the whole process.\n}\nEnabling docker in the nextflow.config\ndocker { docker.enabled = true }\n\nThe docker container can be specified in the process, e.g.\n\ncontainer = 'ncbi/blast'\nor\ncontainer = `quay.io/biocontainers/blast/2.2.31--pl526he19e7b1_5`\n\nWe can include additional options to pass to the container as well:\n\ncontainerOptions = \"--bind $launchDir/$params.outdir/config:/augustus/config\"\nprojectDir refers to the directory where the main workflow script is located. (It used to be called baseDir.)\nRefering to local directories from within a docker container: create a channel\n\nWorking in containers, we need a way to pass the database file location directly into the runBlast process without the need of the local path.\n\nRepeating a process over each element of a channel with each: input repeaters\nTurning a queue channel into a value channel, which can be used multiple times.\n\nA value channel is implicitly created by a process when it is invoked with a simple value.\nA value channel is also implicitly created as output for a process whose inputs are all value channels.\nA queue channel can be converted into a value channel by returning a single value, using e.g. first, last, collect, count, min, max, reduce, sum, etc. For example: the runBlast process receives three inputs in the following example:\n\nthe queryFile_ch queue channel, with multiple sequences.\nthe dbDir_ch value channel, created by calling .first(), which is reused for all elements of queryFile_ch\nthe dbName_ch value channel, which is also reused for all elements of queryFile_ch\n\n\nworkflow {\n  channel.fromPath(params.dbDir).first()\n  .set { dbDir_ch }\n\n  channel.from(params.dbName).first()\n  .set { dbName_ch }\n\n  queryFile_ch = channel\n      .fromPath(params.query)\n      .splitFasta(by: 1, file:true)\n     res = runBlast(queryFile_ch, dbDir_ch, dbName_ch)\n  res.collectFile(name: 'blast_output_combined.txt', storeDir: params.outdir)\n}\n\n\nAdditional resources\n\nSoftware Carpentry course\nNextflow cheat sheet\nAwesome nextflow"
  },
  {
    "objectID": "posts/custom-badges/index.html",
    "href": "posts/custom-badges/index.html",
    "title": "Creating custom badges for your README",
    "section": "",
    "text": "Predefined badges\nMany open source software packages display key pieces of information as badges (aka shields) in their github README, indicating e.g. code coverage, unit test results, version numbers, license, etc.\nThe shields.io website provides many different ready-to-use badges, covering topics such as test results, code coverage, social media logos, activity, and many more.\n     \nBadges can show up to date information. For example, this badge shows the last commit to the github repository for this blog: . They can be returned either in svg (recommended) or png formats, from the img.shields.io and raster.shields.io servers, respectively.\n\n\nCustom badges\nIn addition to predefined outputs, you can also generate your own, entirely custom badges. They can be static like this one  or dynamically retrieve information from a JSON endpoint of your choice.\n\n\nAdding badges to a README.md file\nTo embed badges into your README.md, simply wrap its URL in markdown and surround it with the badges: start and badges: end tags:\n<!-- badges: start -->\n![](https://img.shields.io/github/last-commit/tomsing1/blog)\n<!-- badges: end -->"
  },
  {
    "objectID": "posts/rslist-r-package/index.html",
    "href": "posts/rslist-r-package/index.html",
    "title": "The rlist R package",
    "section": "",
    "text": "Luckily, there is help: the rlist R package offers lots of great functionality to extract, combine, filter, select and convert nested lists. It works with JSON arrays / files out of the box as well, so it’s super useful when you deal with the response from REST APIs, for example.\nAvailable from a your nearest CRAN mirror.\nCheck it out, you won’t regret it!"
  },
  {
    "objectID": "posts/conda-speedup/index.html",
    "href": "posts/conda-speedup/index.html",
    "title": "2022 normconf: lightning talks",
    "section": "",
    "text": "The full list of lightning talks is available here but here are my favorites:\n\nJacquelin Nolis: Alaska challenged my preconceived notions of storing sunset data\nJenny Bryan: How to name files like a normie\nChelsea Parlett: Why Are You The Way That You Are: Sklearn Quirks\nZachary Chetchavat: Hotkeys for Spreadsheets Cookbook, Practical Solutions from CTRL-Arrow, to F4\nShoili Pal: Data Science Intake Forms\nAmanda Fioritto: Qualify: The SQL Filtering Pattern You Never Knew You Needed\nJuulia Suvilehto: Trying to convince academics to use git\nAnuvabh Dutt: Config files for fast and reproducible ML experiments\nJane Adams: How to make six figures in an hour (slides)\nBryan Bischof: Toss that (model) in an endpoint\nSophia Yang: PyScript: Run Python in your HTML\nVictor Geislinger: Staying Alive: Persistent SSH Sessions w/ tmux\nTom Baldwin: Putting Git’s commit hash in version, two ways"
  },
  {
    "objectID": "posts/r-update-with-rig/index.html",
    "href": "posts/r-update-with-rig/index.html",
    "title": "Updating R the easy way: using rig command line tool",
    "section": "",
    "text": "I had previously installed rig with brew\nbrew tap r-lib/rig\nbrew install --cask rig\nso I first checked if there were any updates available for rig itself:\nbrew upgrade --cask rig\nThis command updated rig from version 0.5.0 to 0.5.2.\nThen I listed the R versions currently installed on my system:\nrig list\n  4.1   (R 4.1.3)\n* 4.2   (R 4.2.1)\nAt this point, I was using R release 4.2.1. Next, I updated to the latest release\nrig install\n\n[INFO] Downloading https://cloud.r-project.org/bin/macosx/base/R-4.2.2.pkg -> /tmp/rig/x86_64-R-4.2.2.pkg\n[INFO] Running installer\n[INFO] > installer: Package name is R 4.2.2 for macOS\n[INFO] > installer: Installing at base path /\n[INFO] > installer: The install was successful.\n[INFO] Forgetting installed versions\n[INFO] Fixing permissions\n[INFO] Adding R-* quick links (if needed)\n[INFO] Setting default CRAN mirror\n[INFO] Installing pak for R 4.2 (if not installed yet)\nOnce the rig install command had completed, my system had updated itself to R version 4.2.2:\nrig list\n  4.1   (R 4.1.3)\n* 4.2   (R 4.2.2)\nNow a new R session starts with R 4.2.2\n>R\n\nR version 4.2.2 (2022-10-31) -- \"Innocent and Trusting\"\nCopyright (C) 2022 The R Foundation for Statistical Computing\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nThank you, Gábor!"
  },
  {
    "objectID": "posts/2022-normconf/index.html",
    "href": "posts/2022-normconf/index.html",
    "title": "The rlist R package",
    "section": "",
    "text": "Luckily, there is help: the rlist R package offers lots of great functionality to extract, combine, filter, select and convert nested lists. It works with JSON arrays / files out of the box as well, so it’s super useful when you deal with the response from REST APIs, for example.\nAvailable from a your nearest CRAN mirror.\nCheck it out, you won’t regret it!"
  },
  {
    "objectID": "posts/postgres-full-text-search/index.html",
    "href": "posts/postgres-full-text-search/index.html",
    "title": "Full text search in Postgres - the R way",
    "section": "",
    "text": "I have been learning how to organize, search and modify data in a Postgres database by working through Anthony DeBarros’ excellent book Practical SQL.\nBecause I currently perform most of my data analyses in R, I am using the great RPostgres, DBI and glue packages to interface with Postgres - without ever leaving my R session.\nToday I learned how to create a full text search index and how to search it with one or more search terms."
  },
  {
    "objectID": "posts/postgres-full-text-search/index.html#connecting-to-postgres",
    "href": "posts/postgres-full-text-search/index.html#connecting-to-postgres",
    "title": "Full text search in Postgres - the R way",
    "section": "Connecting to Postgres",
    "text": "Connecting to Postgres\nFor this example, I created a toy database full_text_search in my local Postgres server. I connect to it with the DBI::dbConnect command, and by passing it the RPostgres::Postgres() driver.\n\nlibrary(DBI)\nlibrary(glue)\nlibrary(RPostgres)\nlibrary(sessioninfo)\n\n# Connect to a (prexisting) postgres database called `full_text_search`\ncon <- DBI::dbConnect(\n  dbname = \"full_text_search\",\n  drv = RPostgres::Postgres(),\n  host = \"localhost\",\n  port = 5432L,\n  user = \"postgres\"\n  )"
  },
  {
    "objectID": "posts/postgres-full-text-search/index.html#creating-and-populating-a-table",
    "href": "posts/postgres-full-text-search/index.html#creating-and-populating-a-table",
    "title": "Full text search in Postgres - the R way",
    "section": "Creating and populating a table",
    "text": "Creating and populating a table\nBecause this is a toy example, I start with a fresh table datasets. (In case it already exists from previous experimentation, I drop the table if necessary).\nLet’s define four fields for the table:\n\nid: the unique identifier\nname: the short name of each entry\ntitle: a longer title\ndescription: a paragraph describing the entry\ncreated: a date and time the entry was added to the database\n\n\n# drop the `datasets` table if it already exists\nif (DBI::dbExistsTable(con, \"datasets\")) DBI::dbRemoveTable(con, \"datasets\")\n\n# create the empty `datasets` table\nsql <- glue_sql(\"\n      CREATE TABLE IF NOT EXISTS datasets (\n      id bigserial PRIMARY KEY,\n      name text,\n      title text,\n      description text,\n      created timestamp with time zone default current_timestamp not null\n    );\", .con = con)\nres <- suppressMessages(DBI::dbSendStatement(con, sql))\nDBI::dbClearResult(res)\nDBI::dbReadTable(con, \"datasets\")\n\n[1] id          name        title       description created    \n<0 rows> (or 0-length row.names)\n\n\nInitially, our new database is empty. Let’s populate them with three entries, each describing a popular dataset shipped with R’s built-in datasets package.\n\n# some example entries\nbuildin_datasets <- list(\n  mtcars = list(\n    \"name\" = \"mtcars\", \n    \"title\" = \"The built-in mtcars dataset from the datasets R package.\",\n    \"description\" = gsub(\n      \"\\r?\\n|\\r\", \" \", \n      \"The data was extracted from the 1974 Motor Trend US magazine, and \ncomprises fuel consumption and 10 aspects of automobile design and\nperformance for 32 automobiles (1973–74 models).\")\n  ), \n  airmiles = list(\n    name = \"airmiles\",\n    title = \"The built-in airmiles dataset from the datasets R package\",\n    description = gsub(\n      \"\\r?\\n|\\r\", \" \", \n      \"The revenue passenger miles flown by commercial airlines in the United\nStates for each year from 1937 to 1960.\")\n  ),\n  attitude = list(\n    name = \"attitude\", \n    title = \"The built-in attitude dataset from the datasets R package\",\n    description = gsub(\n      \"\\r?\\n|\\r\", \" \", \n      \"From a survey of the clerical employees of a large financial\norganization, the data are aggregated from the questionnaires of the\napproximately 35 employees for each of 30 (randomly selected) departments. \nThe numbers give the percent proportion of favourable responses to seven\nquestions in each department.\")\n  )\n)\n\nNext, we loop over each element of the list and use the glue_sql() command to unpack both the names (names(dataset)) and the values of each field for this entry. Then we update the datasets table with this new information.\nAfterward, we retrieve the name and title fields to verify the correct import:\n\nfor (dataset in buildin_datasets) {\n  sql <- glue_sql(\n    \"INSERT INTO datasets ({`names(dataset)`*})\n   VALUES ({dataset*});\", \n    .con = con)\n  res <- suppressMessages(DBI::dbSendStatement(con, sql))\n  DBI::dbClearResult(res)\n}\nDBI::dbGetQuery(con, \"SELECT name, title from datasets;\")\n\n      name                                                     title\n1   mtcars  The built-in mtcars dataset from the datasets R package.\n2 airmiles The built-in airmiles dataset from the datasets R package\n3 attitude The built-in attitude dataset from the datasets R package"
  },
  {
    "objectID": "posts/postgres-full-text-search/index.html#creating-a-tokenized-index-for-full-text-searches",
    "href": "posts/postgres-full-text-search/index.html#creating-a-tokenized-index-for-full-text-searches",
    "title": "Full text search in Postgres - the R way",
    "section": "Creating a tokenized index for full-text searches",
    "text": "Creating a tokenized index for full-text searches\nMy goal is to enable full-text search for the description field. First, we need to add a tsvector field and populate it with the tokenized contents of each description.\n\n# create a column to hold tokens for full text search\nsql <- glue_sql(\n  \"ALTER TABLE datasets\n   ADD COLUMN search_description_text tsvector;\", \n  .con = con)\nres <- suppressMessages(DBI::dbSendStatement(con, sql))\nDBI::dbClearResult(res)\nDBI::dbListFields(con, \"datasets\")\n\n[1] \"id\"                      \"name\"                   \n[3] \"title\"                   \"description\"            \n[5] \"created\"                 \"search_description_text\"\n\n\nAt this point, the search_description_text field is still empty. Let’s copy the descriptions into it - and tokenize them at the same time. For illustration, we retrieve the tokens for the first dataset:\n\n# copy the description into search tokens\nsql <- glue_sql(\n  \"UPDATE datasets\n   SET search_description_text = to_tsvector('english', description);\", \n  .con = con)\nDBI::dbExecute(con, sql)\n\n[1] 3\n\nDBI::dbGetQuery(con, \n                \"SELECT name, search_description_text from datasets LIMIT 1;\")\n\n    name\n1 mtcars\n                                                                                                                                                                                          search_description_text\n1 '10':17 '1973':27 '1974':7 '32':25 '74':28 'aspect':18 'automobil':20,26 'compris':13 'consumpt':15 'data':2 'design':21 'extract':4 'fuel':14 'magazin':11 'model':29 'motor':8 'perform':23 'trend':9 'us':10\n\n\nTo speed up the full-text search, we add a Generalized Inverted Index (GIN) index for the search_description_text column as well:\n\n# create the search index\nsql <- glue_sql(\n  \"CREATE INDEX search_description_idx\n   ON datasets\n   USING gin(search_description_text);\",\n  .con = con)\nDBI::dbExecute(con, sql)\n\n[1] 0"
  },
  {
    "objectID": "posts/postgres-full-text-search/index.html#searching",
    "href": "posts/postgres-full-text-search/index.html#searching",
    "title": "Full text search in Postgres - the R way",
    "section": "Searching!",
    "text": "Searching!\nOur goal is to enable full-text search for the description field. Let’s look up the term data. To perform full-text search, both the records to search and our query need to be tokinzed first, with the to_tsvector and to_tsquery functions, respectively.\nHere is an example of the tokens that are generated:\n\nsql <- glue_sql(\n  \"SELECT to_tsvector('This is a my test phrase, and what \n                       a beautiful phrase it is.')\n   to_tsquery\", con = con)\nDBI::dbGetQuery(con, sql)\n\n                          to_tsquery\n1 'beauti':10 'phrase':6,11 'test':5\n\n\nThe following query correctly returns all records whose descriptions contain the word data:\n\n# search the description field\nterm <- \"data\"\nsql <- glue_sql(\n  \"SELECT id, name\n  FROM datasets\n  WHERE to_tsvector(description) @@ to_tsquery('english', {term})\n  ORDER BY created;\",\n  .con = con)\nDBI::dbGetQuery(con, sql)\n\n  id     name\n1  1   mtcars\n2  3 attitude\n\n\nWe can enrich the output by returning the output of the ts_headline function, highlighting the location / context of the the matched term:\n\n# search the description field and show the matching location\nterm <- \"data\"\nsql <- glue_sql(\n  \"SELECT id, name,\n    ts_headline(description, to_tsquery('english', {term}),\n     'StartSel = <,\n      StopSel = >,\n      MinWords = 5,\n      MaxWords = 7,\n      MaxFragments = 1')\n  FROM datasets\n  WHERE to_tsvector(description) @@ to_tsquery('english', {term})\n  ORDER BY created;\",\n  .con = con)\nDBI::dbGetQuery(con, sql)\n\n  id     name                                            ts_headline\n1  1   mtcars               <data> was extracted from the 1974 Motor\n2  3 attitude financial organization, the <data> are aggregated from\n\n\nWe can also combine search terms, e.g. searching for either employee or motor terms:\n\n# using multiple search terms\nterm <- \"employee | motor\"  # OR\nsql <- glue_sql(\n  \"SELECT id, name,\n  ts_headline(description, to_tsquery('english', {term}),\n     'StartSel = <,\n      StopSel = >,\n      MinWords = 5,\n      MaxWords = 7,\n      MaxFragments = 1')\n  FROM datasets\n  WHERE to_tsvector(description) @@ to_tsquery('english', {term})\n  ORDER BY created;\",\n  .con = con)\nDBI::dbGetQuery(con, sql)\n\n  id     name                                            ts_headline\n1  1   mtcars                from the 1974 <Motor> Trend US magazine\n2  3 attitude clerical <employees> of a large financial organization\n\n\nSimilarly, we can narrow our search by requiring both data and employee terms to appear in the same description:\n\nterm <- \"data & employee\"  # AND\nsql <- glue_sql(\n  \"SELECT id, name,\n  ts_headline(description, to_tsquery('english', {term}),\n     'StartSel = <,\n      StopSel = >,\n      MinWords = 5,\n      MaxWords = 7,\n      MaxFragments = 1')\n  FROM datasets\n  WHERE to_tsvector(description) @@ to_tsquery('english', {term})\n  ORDER BY created;\",\n  .con = con)\nDBI::dbGetQuery(con, sql)\n\n  id     name                                            ts_headline\n1  3 attitude clerical <employees> of a large financial organization"
  },
  {
    "objectID": "posts/postgres-full-text-search/index.html#reproducibility",
    "href": "posts/postgres-full-text-search/index.html#reproducibility",
    "title": "Full text search in Postgres - the R way",
    "section": "Reproducibility",
    "text": "Reproducibility\n\n\nsessioninfo::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Los_Angeles\n date     2022-12-12\n pandoc   2.19.2 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n askpass       1.1     2019-01-13 [1] CRAN (R 4.2.0)\n bit           4.0.5   2022-11-15 [1] CRAN (R 4.2.0)\n bit64         4.0.5   2020-08-30 [1] CRAN (R 4.2.0)\n blob          1.2.3   2022-04-10 [1] CRAN (R 4.2.0)\n cli           3.4.1   2022-09-23 [1] CRAN (R 4.2.0)\n credentials   1.3.2   2021-11-29 [1] CRAN (R 4.2.0)\n DBI         * 1.1.3   2022-06-18 [1] CRAN (R 4.2.0)\n digest        0.6.30  2022-10-18 [1] CRAN (R 4.2.0)\n ellipsis      0.3.2   2021-04-29 [1] CRAN (R 4.2.0)\n evaluate      0.18    2022-11-07 [1] CRAN (R 4.2.0)\n fastmap       1.1.0   2021-01-25 [1] CRAN (R 4.2.0)\n generics      0.1.3   2022-07-05 [1] CRAN (R 4.2.0)\n glue        * 1.6.2   2022-02-24 [1] CRAN (R 4.2.0)\n hms           1.1.2   2022-08-19 [1] CRAN (R 4.2.0)\n htmltools     0.5.4   2022-12-07 [1] CRAN (R 4.2.0)\n htmlwidgets   1.5.4   2021-09-08 [1] CRAN (R 4.2.0)\n jsonlite      1.8.4   2022-12-06 [1] CRAN (R 4.2.0)\n knitr         1.41    2022-11-18 [1] CRAN (R 4.2.0)\n lifecycle     1.0.3   2022-10-07 [1] CRAN (R 4.2.0)\n lubridate     1.9.0   2022-11-06 [1] CRAN (R 4.2.0)\n magrittr      2.0.3   2022-03-30 [1] CRAN (R 4.2.0)\n openssl       2.0.5   2022-12-06 [1] CRAN (R 4.2.0)\n pkgconfig     2.0.3   2019-09-22 [1] CRAN (R 4.2.0)\n Rcpp          1.0.9   2022-07-08 [1] CRAN (R 4.2.0)\n rlang         1.0.6   2022-09-24 [1] CRAN (R 4.2.0)\n rmarkdown     2.18    2022-11-09 [1] CRAN (R 4.2.0)\n RPostgres   * 1.4.4   2022-05-02 [1] CRAN (R 4.2.0)\n rstudioapi    0.14    2022-08-22 [1] CRAN (R 4.2.0)\n sessioninfo * 1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n stringi       1.7.8   2022-07-11 [1] CRAN (R 4.2.0)\n stringr       1.5.0   2022-12-02 [1] CRAN (R 4.2.0)\n sys           3.4.1   2022-10-18 [1] CRAN (R 4.2.0)\n timechange    0.1.1   2022-11-04 [1] CRAN (R 4.2.0)\n vctrs         0.5.1   2022-11-16 [1] CRAN (R 4.2.0)\n xfun          0.35    2022-11-16 [1] CRAN (R 4.2.0)\n yaml          2.3.6   2022-10-18 [1] CRAN (R 4.2.0)\n\n [1] /Users/sandmann/Library/R/x86_64/4.2/library\n [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/postgres-full-text-search/index.html#adding-new-entries",
    "href": "posts/postgres-full-text-search/index.html#adding-new-entries",
    "title": "Full text search in Postgres - the R way",
    "section": "Adding new entries",
    "text": "Adding new entries\nWe have successfully indexed and searched the existing three entries in our database. But what if we add new information? Let’s create a new record for the euro dataset.\n\nnew_data = list(\n  name = \"euro\", \n  title = \"The built-in euro dataset from the datasets R package\",\n  description = gsub(\n    \"\\r?\\n|\\r\", \" \", \n    \"The data set euro contains the value of 1 Euro in all currencies\nparticipating in the European monetary union (Austrian Schilling ATS, \nBelgian Franc BEF, German Mark DEM, Spanish Peseta ESP, Finnish Markka FIM, \nFrench Franc FRF, Irish Punt IEP, Italian Lira ITL, Luxembourg Franc LUF, \nDutch Guilder NLG and Portuguese Escudo PTE). These conversion rates were \nfixed by the European Union on December 31, 1998. To convert old prices to \nEuro prices, divide by the respective rate and round to 2 digits.\")\n)\n\nTo enter this record, we not only have to populate the name, title and description fields - but also the list of tokens derived from the description in the search_description_text column. In other words, we have to execute the to_tsvector function inside our INSERT statement:\n\nsql <- glue_sql(\n  \"INSERT INTO datasets ({`names(dataset)`*}, search_description_text)\n   VALUES ({new_data*}, to_tsvector({new_data[['description']]}));\", \n  .con = con)\nDBI::dbExecute(con, sql)\n\n[1] 1\n\n\nNow, when we search for the term data, we find both the original and the new record:\n\n# search the description field and show the matching location\nterm <- \"data\"\nsql <- glue_sql(\n  \"SELECT id, name,\n  ts_headline(description, to_tsquery('english', {term}),\n     'StartSel = <,\n      StopSel = >,\n      MinWords = 5,\n      MaxWords = 7,\n      MaxFragments = 1')\n  FROM datasets\n  WHERE search_description_text @@ to_tsquery('english', {term})\n  ORDER BY created;\",\n  .con = con)\nres <- suppressMessages(DBI::dbSendStatement(con, sql))\nDBI::dbFetch(res)\n\n  id     name                                            ts_headline\n1  1   mtcars               <data> was extracted from the 1974 Motor\n2  3 attitude financial organization, the <data> are aggregated from\n3  4     euro                     <data> set euro contains the value\n\nDBI::dbClearResult(res)\n\nThat’s it. Thanks again to Anthony DeBarros’ for his excellent introduction to Practical SQL!"
  },
  {
    "objectID": "posts/postgres-full-text-search/index.html#creating-indices",
    "href": "posts/postgres-full-text-search/index.html#creating-indices",
    "title": "Full text search in Postgres - the R way",
    "section": "Creating indices",
    "text": "Creating indices\nIn the examples above, we performed tokenization of the search term and the description field at run time, e.g. when the query was executed. As our database grows, this will soon become too cumbersome and degrade performance.\nAdding an index to our database will maintain full-text search speed even with large datasets. We have two different options:\n\nCreate an index based on an expression.\nCreate a new field to hold the output of the to_tsvector function, and then index this new field.\n\n\nCreating an expression index\nA simple way to create a full-text index is to include the to_tsvector() expression in the definition of the index itself. Here, we add a Generalized Inverted Index (GIN) index for the description column:\n\nsql = glue_sql(\n  \"CREATE INDEX description_idx ON datasets \n  USING gin(to_tsvector('english', description));\",\n  con = con\n)\nDBI::dbExecute(con, sql)\n\n[1] 0\n\n\nThe same type of query we issued above will now take advantage of the description_idx:\n\n# search the description field using its index\nterm <- \"questioning\"\nsql <- glue_sql(\n  \"SELECT id, name,\n    ts_headline(description, to_tsquery('english', {term}),\n     'StartSel = <,\n      StopSel = >,\n      MinWords = 5,\n      MaxWords = 7,\n      MaxFragments = 1')\n  FROM datasets\n  WHERE to_tsvector('english', description) @@ to_tsquery('english', {term})\n  ORDER BY created;\",\n  .con = con)\nDBI::dbGetQuery(con, sql)\n\n  id     name                                       ts_headline\n1  3 attitude responses to seven <questions> in each department\n\n\nThe description fields of new records, e.g those that are added later, will automatically be added to the index. Let’s create a new record for the euro dataset, for example.\n\nnew_data = list(\n  name = \"euro\", \n  title = \"The built-in euro dataset from the datasets R package\",\n  description = gsub(\n    \"\\r?\\n|\\r\", \" \", \n    \"The data set euro contains the value of 1 Euro in all currencies\nparticipating in the European monetary union (Austrian Schilling ATS, \nBelgian Franc BEF, German Mark DEM, Spanish Peseta ESP, Finnish Markka FIM, \nFrench Franc FRF, Irish Punt IEP, Italian Lira ITL, Luxembourg Franc LUF, \nDutch Guilder NLG and Portuguese Escudo PTE). These conversion rates were \nfixed by the European Union on December 31, 1998. To convert old prices to \nEuro prices, divide by the respective rate and round to 2 digits.\")\n)\nsql <- glue_sql(\n  \"INSERT INTO datasets ({`names(dataset)`*})\n   VALUES ({new_data*});\", \n  .con = con)\nDBI::dbExecute(con, sql)\n\n[1] 1\n\n\nThis new record will now be included in the search results for the term data, for example:\n\n# search the description field using its index\nterm <- \"data\"\nsql <- glue_sql(\n  \"SELECT id, name,\n    ts_headline(description, to_tsquery('english', {term}),\n     'StartSel = <,\n      StopSel = >,\n      MinWords = 5,\n      MaxWords = 7,\n      MaxFragments = 1')\n  FROM datasets\n  WHERE to_tsvector('english', description) @@ to_tsquery('english', {term})\n  ORDER BY created;\",\n  .con = con)\nDBI::dbGetQuery(con, sql)\n\n  id     name                                            ts_headline\n1  1   mtcars               <data> was extracted from the 1974 Motor\n2  3 attitude financial organization, the <data> are aggregated from\n3  4     euro                     <data> set euro contains the value\n\n\n\n\nAdding a tokenized field for full-text searches\nAlternatively, another option is to create a new column to hold the output of the to_tsvector() function, and then to index it for future use. Let’s create a new column search_description_text:\n\n# create a column to hold tokens for full text search\nsql <- glue_sql(\n  \"ALTER TABLE datasets\n   ADD COLUMN search_description_text tsvector;\", \n  .con = con)\nDBI::dbExecute(con, sql)\n\n[1] 0\n\nDBI::dbListFields(con, \"datasets\")\n\n[1] \"id\"                      \"name\"                   \n[3] \"title\"                   \"description\"            \n[5] \"created\"                 \"search_description_text\"\n\n\nNext, we tokenize the descriptions field, and store the output in our new search_description_text column:\n\nsql <- glue_sql(\n  \"UPDATE datasets\n   SET search_description_text = to_tsvector('english', description);\", \n  .con = con)\nDBI::dbExecute(con, sql)\n\n[1] 4\n\n\nHere are the tokens generated from the description of the first record, for example:\n\nDBI::dbGetQuery(con, \n                \"SELECT name, search_description_text from datasets LIMIT 1;\")\n\n    name\n1 mtcars\n                                                                                                                                                                                          search_description_text\n1 '10':17 '1973':27 '1974':7 '32':25 '74':28 'aspect':18 'automobil':20,26 'compris':13 'consumpt':15 'data':2 'design':21 'extract':4 'fuel':14 'magazin':11 'model':29 'motor':8 'perform':23 'trend':9 'us':10\n\n\nAs before, we can add an index - but this time, we index the pre-tokenized search_description_text column instead:\n\n# create the search index\nsql <- glue_sql(\n  \"CREATE INDEX search_description_idx\n   ON datasets\n   USING gin(search_description_text);\",\n  .con = con)\nDBI::dbExecute(con, sql)\n\n[1] 0\n\n\nTime to run our search again. When we search the search_description_text field, we can omit the to_tsvector() call, because its has been tokenized already:\n\n# search the description field and show the matching location\nterm <- \"data\"\nsql <- glue_sql(\n  \"SELECT id, name,\n  ts_headline(description, to_tsquery('english', {term}),\n     'StartSel = <,\n      StopSel = >,\n      MinWords = 5,\n      MaxWords = 7,\n      MaxFragments = 1')\n  FROM datasets\n  WHERE search_description_text @@ to_tsquery('english', {term})\n  ORDER BY created;\",\n  .con = con)\nDBI::dbGetQuery(con, sql)\n\n  id     name                                            ts_headline\n1  1   mtcars               <data> was extracted from the 1974 Motor\n2  3 attitude financial organization, the <data> are aggregated from\n3  4     euro                     <data> set euro contains the value\n\n\n🚨 But beware: because we have precalculated the tokens, any new records added to the database will not automatically be processed, nor will they be indexed!\nLet’s add a final record, the morely dataset:\n\nmore_data = list(\n  name = \"morley\", \n  title = \"The built-in morley dataset from the datasets R package\",\n  description = gsub(\n    \"\\r?\\n|\\r\", \" \", \n    \"A classical data of Michelson (but not this one with Morley) on \nmeasurements done in 1879 on the speed of light. The data consists of five \nexperiments, each consisting of 20 consecutive ‘runs’. The response is the speed\nof light measurement, suitably coded (km/sec, with 299000 subtracted).\")\n)\n\nTo enter this record, we not only have to populate the name, title and description fields - but also the list of tokens derived from the description in the search_description_text column. In other words, we have to execute the to_tsvector function inside our INSERT statement:\n\nsql <- glue_sql(\n  \"INSERT INTO datasets ({`names(dataset)`*}, search_description_text)\n   VALUES ({more_data*}, to_tsvector({more_data[['description']]}));\", \n  .con = con)\nDBI::dbExecute(con, sql)\n\n[1] 1\n\n\nNow, our query returns both the original matches and the new record:\n\n# search the description field and show the matching location\nterm <- \"data\"\nsql <- glue_sql(\n  \"SELECT id, name,\n  ts_headline(description, to_tsquery('english', {term}),\n     'StartSel = <,\n      StopSel = >,\n      MinWords = 5,\n      MaxWords = 7,\n      MaxFragments = 1')\n  FROM datasets\n  WHERE search_description_text @@ to_tsquery('english', {term})\n  ORDER BY created;\",\n  .con = con)\nDBI::dbGetQuery(con, sql)\n\n  id     name                                            ts_headline\n1  1   mtcars               <data> was extracted from the 1974 Motor\n2  3 attitude financial organization, the <data> are aggregated from\n3  4     euro                     <data> set euro contains the value\n4  5   morley            classical <data> of Michelson (but not this\n\n\n\n\nChoosing between indexing strategies\nAccording to the Postgres documentation:\n\nOne advantage of the separate-column approach over an expression index is that it is not necessary to explicitly specify the text search configuration in queries in order to make use of the index. Another advantage is that searches will be faster, since it will not be necessary to redo the to_tsvector calls to verify index matches. The expression-index approach is simpler to set up, however, and it requires less disk space since the tsvector representation is not stored explicitly.\n\nThat’s it. Thanks again to Anthony DeBarros’ for his excellent introduction to Practical SQL!"
  },
  {
    "objectID": "posts/quarto-figure-size-and-layout/index.html",
    "href": "posts/quarto-figure-size-and-layout/index.html",
    "title": "Figure size, layout & tabsets with Quarto",
    "section": "",
    "text": "In this document, I am experimenting with various attributes that organize the layout, size and placement of figures of Quarto document. For more details, please check out the official documentation, especially the topics on figures and article layout.\n\n\n\n\n\n\nNote\n\n\n\nFor illustration, I am displaying both the code that generates a simple plot as well as the attributes that determine how it is rendered, e.g. the ::: tags interspersed with the code blocks, and the #| attributes within individual code cells. See the documentation on executable blocks for details.\n\n\nFirst, let’s generate a simple plot, so we can see the effect of different attributes on how it is rendered in subsequent code cells.\nTo start, we render the output without specifying any custom attributes, e.g. using the default settings for this Quarto website:\n\nlibrary(ggplot2)\ntheme_set(theme_linedraw(base_size = 14))\np <- ggplot(mtcars, aes(x = mpg, y = drat)) + \n  geom_point(color = \"skyblue\", size = 3, alpha = 0.7) +\n  geom_smooth(method = \"lm\", formula = 'y ~ x', se = FALSE) +\n  theme(panel.grid = element_blank())\np\n\n\n\n\n\nWidth and height of individual figures\nThe fig-width and fig-height attributes specify the dimensions of the image file that is generated. The out-width attribute determines the size at which that image is displayed in the rendered HTML page.\n#| fig-width: 4\n#| figh-height: 5\n#| out-width: \"50%\"\n#| fig-align: \"center\"\n\np\n\n\n\n\n\n\n\n\nFor example, the same image can be displayed at 50% of the width of the enclosing <div>.\n#| fig-width: 4\n#| figh-height: 5\n#| out-width: \"25%\"\n#| fig-align: \"center\"\n\np\n\n\n\n\n\n\n\n\n\n\nLayout: columns and rows\nThe layout-ncol and layout-nrow attributes govern the placement of multiple figures within the same element. For example, we can place two figures next to each other, in two column.\nThe fig-align attributes specify the figure alignment within each column.\n\n\n\n\n\n\nTip\n\n\n\nThe out-width attribute is always relative to its enclosing element, e.g. here out-width: \"50%\" refers to half of the width of a column, not the page width.\n\n\n::: {layout-ncol=2}\n\n\n\n#| out-width: \"50%\"\n#| fig-align: \"center\"\n\n\n#| out-width: \"30%\"\n#| fig-align: \"right\"\n\n\n\n\np\n\n\n\n\n\n\n\n\n\np\n\n\n\n\n\n\n\n\n\n\n:::\n\n\nTabsets\nTabsets can be used to organize contents, e.g. by hiding content until the other clicks on the tab’s header.\nThe layout of the first tabset contains just one column and row.\n::: {.panel-tabset}\n\npanel 1panel 2\n\n\n\np\n\n\n\n\n\n\n\n\n\n\nThe second panel is subdivided into two columns. (Note the use of the :::: tag, nested within the ::: parent tag.)\n:::: {layout-ncol=2}\n\n\n\np\n\n\n\n\n\np\n\n\n\n\n\n\n\n::::\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "posts/upset_plots/index.html",
    "href": "posts/upset_plots/index.html",
    "title": "UpSet plots: comparing differential expression across contrasts",
    "section": "",
    "text": "Today I learned how to use UpSet plots to visualize the overlap between sets of differentially expressed genes.\nI often analyze RNA-seq experiments with multiple factors, e.g. different treatments, conditions, cell lines, genotypes, time points, etc. The scientific questions typically involve not just one, but multiple comparisons between experimental groups. For example:\n\nHow do wildtype cells respond to drug treatment?\nHow do mutant cells respond?\nWhat is the effect of drug treatment in growth medium A? Or B? Or C?\nIs there a significant difference between treatment effects in wildtype and mutant cells?\netc\n\nTo answer these questions, I typically fit a single linear model and then extract the comparisons of interest by specifying each of them as as contrast. (Check out the vignette of the excellent designmatrices Bioconductor package for details on creating design matrices and extracting contrasts.)\nAfter applying a suitable p-value / FDR threshold, each comparison / contrast yields a list of differentially expressed genes1. When the lists are long, it is difficult to assess the degree of overlap, e.g. the number of genes that were detected in multiple contrasts.\nIf the number of comparisons is small (say < 5), then a Venn diagram is an excellent way of displaying how these sets of genes overlap. But when the number of sets increases, so does the number of intersections - and Venn diagrams soon become hard to draw (and interpret).\nUpset plots can be used to clearly visualize larger numbers of sets. Here, I am using the airway Bioconductor dataset, an RNA-Seq experiment on four human airway smooth muscle cell lines treated with dexamethasone, to illustrate how to\n\nFit a linear model using limma/voom\nExtract multiple contrasts\nVisualize the numbers and intersections of differentially expressed gene sets using Venn diagrams and UpSet plots.\n\n\nNormalization, filtering & linear modeling\n\nlibrary(airway)\nlibrary(ComplexHeatmap)\nlibrary(edgeR)\nlibrary(limma)\n\nMy typical analysis workflow uses functions from the edgeR and limma R packages.\nThe airway experiment is multifactorial, and it includes:\n\nCells from different donors (cell covariate)\nTreatment with dexamethasone - or not (dex covariate)\nDifferent read lengths (avgLength covariate)\n\n\ndata(airway, package = \"airway\")\nwith(colData(airway), table(cell, dex))\n\n         dex\ncell      trt untrt\n  N052611   1     1\n  N061011   1     1\n  N080611   1     1\n  N61311    1     1\n\n\nHere, I will focus only on the cell and dex variables, formulating a linear model that includes these two additive predictors: ~ 0 + cell + dex\n\n\n\n\n\n\nNote\n\n\n\nThere are alternative ways to parameterize a linear model. For example, to obtain the pairwise comparisons between the first and the other three cell, lines (see below) the model ~ cell + dex would have returned the same results without the need for contrasts. But for complex multivariate experiments, I personally find it easier to exclude the intercept term and to manually define contrasts of interest.\n\n\nFirst, the data is normalized with the TMM method. Next, we focus only on genes exceeding a minimal expression threshold by filtering the dataset with the filterByExpr function. Then we are ready to fit the linear model - performing both the voom transformation and the model fitting with the voomLmFit function.\n\nairway <- calcNormFactors(airway)\ndesign <- model.matrix(~ 0 + cell + dex, data = airway$samples)\ncolnames(design) <- sub(\"cell\", \"\", colnames(design))\nkeep <- filterByExpr(airway, design = design)\nfit <- voomLmFit(airway[keep, row.names(design)], design = design)\n\nFor simplicity, we extract three contrasts, comparing gene expression between cell line N052611 and each of the other three lines (adjusted for dexamethasone treatment). (These might not be the most biologically interesting comparisons, but this post is focused on visualization - not biology.)\n\n# contrasts: differences between the first and all other cell lines\ncontrasts <- makeContrasts(\n  \"N061011-N052611\",\n  \"N080611-N052611\",\n  \"N61311-N052611\",\n  levels = design\n)\nfit2 <- contrasts.fit(fit, contrasts)\nresults <- limma::decideTests(fit2)\nsummary(results)\n\n       N061011-N052611 N080611-N052611 N61311-N052611\nDown               279            1107            913\nNotSig           16336           15046          15329\nUp                 272             734            645\n\n\n\n\nVenn diagram\nEach of the pairwise comparisons yields hundreds of differentially expressed genes (at the default FDR < 5% threshold for each contrast imposed by limma’s decideTests function.) But are these genes similar across cell lines?\nFor three comparisons, limma’s built-in vennDiagram function is very useful:\n\nlimma::vennDiagram(\n  results,\n  counts.col = \"black\",\n  circle.col = c(\"red\", \"blue\", \"green3\"),\n  names = sub(\"-\", \"/\\n\", colnames(results)),\n  mar = rep(0,4),\n  cex = c(1.2,1,0.7)\n)\n\n\n\n\n\n\n\n\nThe diagram shows that only a minority of genes is differentially expressed between all three cell lines and our reference (cell line N052611). Most of the genes are only observed in the comparison between lines N080611 and N052611.\n\n\n\n\n\n\nTip\n\n\n\nThis example doesn’t distinguish between up- and down-regulated genes, e.g. a gene that is up-regulated in one contrast but down-regulated in another would be found in the intersection. To display separate counts for up- and downregulated genes, add the include=c(\"up\", \"down\") argument to the vennDiagram call.\n\n\nIf the number of comparisons increases, Venn diagrams are less useful (e.g. the famous banagram with six sets).\n\n\nUpset plots\nThere are multiple R packages that can generate UpSet plots, including e.g. UpSetR. I ran into difficulties customizing both the names of the sets and select specific intersections for plotting with UpSetR. Instead, I am using the UpSet function included in the ComplexHeatmap R package here.\nIn preparation for plotting, multiple helper functions are available, including\n\nmake_comb_mat: calculcate the overlap between different sets, according to the user-specified mode: one of distinct, intersect or union.\ncomb_degree: return the degree of each combination, e.g. how many sets were included.\nset_size: return the size of each input set\ncomb_size: return the size of each of the intersected sets (e.g. the same sets shown in the Venn diagram above, because the mode was set to distinct).\n\nFor example, let’s first restrict our input to all genes called significant in at least one of the comparisons:\n\n# remove genes not signif. in any contrast\nresults <- results[rowSums(abs(results)) > 0, ]\n\nNext, we determine the number of genes in each intersection. (Because make_comb_mat includes single sets as well, we exclude them by filtering out all results for intersections of degree one.)\n\n# calculate the intersection between the differentially expressed gene sets\nm <- make_comb_mat(abs(results), mode = \"distinct\")\n# exclude self-intersects (total # of diff. genes will be displayed separately)\nm <- m[comb_degree(m) > 1]\n\nLet’s check the size of the input sets (e.g. all up- and down-regulated genes in each comparison):\n\n(ss <- set_size(m))\n\nN061011-N052611 N080611-N052611  N61311-N052611 \n            551            1841            1558 \n\n\nand their intersections:\n\n(cs <- comb_size(m))\n\n111 110 101 011 \n172 116 102 405 \n\n\n(Together, these numbers reproduce what was shown in the Venn diagram above.) Now we are ready to generate an UpSet plot!\nBecause the UpSet function uses the ComplexHeatmap::Heatmap function under the hood, the resulting plot can be annotated / decorated with the same set of functions. Here, we plot the intersections in the main plot, and then add the size of the individual sets on the right-hand margin.\n\nht <- UpSet(m, \n      set_order = colnames(m), \n      comb_order = order(comb_degree(m)),\n      top_annotation = HeatmapAnnotation(\n        \"Distinct diff. genes\" = anno_barplot(\n          cs, \n          ylim = c(0, max(cs)*1.1),\n          border = FALSE, \n          gp = gpar(fill = \"black\"), \n          height = unit(4, \"cm\")\n        ), \n        annotation_name_side = \"left\", \n        annotation_name_rot = 90),\n      right_annotation = HeatmapAnnotation(\n        which = \"row\",\n        \"Total\" = anno_barplot(\n          ss, \n          ylim = c(0, max(ss)*1.1),\n          border = FALSE, \n          gp = gpar(fill = \"black\"), \n          width = unit(4, \"cm\")\n        )\n      ),\n      column_title = \"Intersection between contrasts\"\n)\nht = draw(ht)\nod = column_order(ht)\nrod = row_order(ht)\ndecorate_annotation(\"Distinct diff. genes\", {\n  grid.text(cs[od], \n            x = seq_along(cs), \n            y = unit(cs[od], \"native\") + unit(2, \"pt\"), \n            default.units = \"native\", just = c(\"left\", \"bottom\"), \n            gp = gpar(fontsize = 8, col = \"#404040\"), rot = 45)\n})\ndecorate_annotation(\"Total\", {\n  grid.text(ss[rod], \n            x = unit(ss[rod], \"native\") + unit(20, \"pt\"), \n            y = rev(seq_along(ss)), \n            default.units = \"native\", just = c(\"right\", \"bottom\"), \n            gp = gpar(fontsize = 8, col = \"#404040\"))\n})\n\n\n\n\n\n\n\n\nEach column of the main plot shows the number of genes that are unique to the intersection of the two (or three) indicated comparisons, matching those in the previous Venn diagram.\nFor a small number of sets, a Venn diagram might be the preferred e.g. because readers might be familiar this visualization. But an UpSet plot is well suited for the analysis more than three sets. (See more examples here ).\n\n\nReproducibility\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Los_Angeles\n date     2022-12-24\n pandoc   2.19.2 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package              * version  date (UTC) lib source\n airway               * 1.18.0   2022-11-03 [1] Bioconductor\n askpass                1.1      2019-01-13 [1] CRAN (R 4.2.0)\n Biobase              * 2.58.0   2022-11-01 [1] Bioconductor\n BiocGenerics         * 0.44.0   2022-11-01 [1] Bioconductor\n bitops                 1.0-7    2021-04-24 [1] CRAN (R 4.2.0)\n circlize               0.4.15   2022-05-10 [1] CRAN (R 4.2.0)\n cli                    3.4.1    2022-09-23 [1] CRAN (R 4.2.0)\n clue                   0.3-63   2022-11-19 [1] CRAN (R 4.2.0)\n cluster                2.1.4    2022-08-22 [2] CRAN (R 4.2.2)\n codetools              0.2-18   2020-11-04 [2] CRAN (R 4.2.2)\n colorspace             2.0-3    2022-02-21 [1] CRAN (R 4.2.0)\n ComplexHeatmap       * 2.14.0   2022-11-01 [1] Bioconductor\n crayon                 1.5.2    2022-09-29 [1] CRAN (R 4.2.0)\n credentials            1.3.2    2021-11-29 [1] CRAN (R 4.2.0)\n DelayedArray           0.24.0   2022-11-01 [1] Bioconductor\n digest                 0.6.31   2022-12-11 [1] CRAN (R 4.2.0)\n doParallel             1.0.17   2022-02-07 [1] CRAN (R 4.2.0)\n edgeR                * 3.40.1   2022-12-14 [1] Bioconductor\n evaluate               0.19     2022-12-13 [1] CRAN (R 4.2.0)\n fastmap                1.1.0    2021-01-25 [1] CRAN (R 4.2.0)\n foreach                1.5.2    2022-02-02 [1] CRAN (R 4.2.0)\n GenomeInfoDb         * 1.34.4   2022-12-01 [1] Bioconductor\n GenomeInfoDbData       1.2.9    2022-12-12 [1] Bioconductor\n GenomicRanges        * 1.50.2   2022-12-16 [1] Bioconductor\n GetoptLong             1.0.5    2020-12-15 [1] CRAN (R 4.2.0)\n GlobalOptions          0.1.2    2020-06-10 [1] CRAN (R 4.2.0)\n glue                   1.6.2    2022-02-24 [1] CRAN (R 4.2.0)\n htmltools              0.5.4    2022-12-07 [1] CRAN (R 4.2.0)\n htmlwidgets            1.5.4    2021-09-08 [1] CRAN (R 4.2.2)\n IRanges              * 2.32.0   2022-11-01 [1] Bioconductor\n iterators              1.0.14   2022-02-05 [1] CRAN (R 4.2.0)\n jsonlite               1.8.4    2022-12-06 [1] CRAN (R 4.2.0)\n knitr                  1.41     2022-11-18 [1] CRAN (R 4.2.0)\n lattice                0.20-45  2021-09-22 [2] CRAN (R 4.2.2)\n lifecycle              1.0.3    2022-10-07 [1] CRAN (R 4.2.0)\n limma                * 3.54.0   2022-11-01 [1] Bioconductor\n locfit                 1.5-9.6  2022-07-11 [1] CRAN (R 4.2.0)\n magrittr               2.0.3    2022-03-30 [1] CRAN (R 4.2.0)\n Matrix                 1.5-3    2022-11-11 [1] CRAN (R 4.2.0)\n MatrixGenerics       * 1.10.0   2022-11-01 [1] Bioconductor\n matrixStats          * 0.63.0   2022-11-18 [1] CRAN (R 4.2.0)\n openssl                2.0.5    2022-12-06 [1] CRAN (R 4.2.0)\n png                    0.1-8    2022-11-29 [1] CRAN (R 4.2.0)\n RColorBrewer           1.1-3    2022-04-03 [1] CRAN (R 4.2.0)\n Rcpp                   1.0.9    2022-07-08 [1] CRAN (R 4.2.0)\n RCurl                  1.98-1.9 2022-10-03 [1] CRAN (R 4.2.0)\n rjson                  0.2.21   2022-01-09 [1] CRAN (R 4.2.0)\n rlang                  1.0.6    2022-09-24 [1] CRAN (R 4.2.0)\n rmarkdown              2.19     2022-12-15 [1] CRAN (R 4.2.0)\n rstudioapi             0.14     2022-08-22 [1] CRAN (R 4.2.0)\n S4Vectors            * 0.36.1   2022-12-05 [1] Bioconductor\n sessioninfo            1.2.2    2021-12-06 [1] CRAN (R 4.2.0)\n shape                  1.4.6    2021-05-19 [1] CRAN (R 4.2.0)\n stringi                1.7.8    2022-07-11 [1] CRAN (R 4.2.0)\n stringr                1.5.0    2022-12-02 [1] CRAN (R 4.2.0)\n SummarizedExperiment * 1.28.0   2022-11-01 [1] Bioconductor\n sys                    3.4.1    2022-10-18 [1] CRAN (R 4.2.0)\n vctrs                  0.5.1    2022-11-16 [1] CRAN (R 4.2.0)\n xfun                   0.35     2022-11-16 [1] CRAN (R 4.2.0)\n XVector                0.38.0   2022-11-01 [1] Bioconductor\n yaml                   2.3.6    2022-10-18 [1] CRAN (R 4.2.0)\n zlibbioc               1.44.0   2022-11-01 [1] Bioconductor\n\n [1] /Users/sandmann/Library/R/x86_64/4.2/library\n [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\n\n\n\n\n\n\n\nFootnotes\n\n\nBoth Venn diagrams and upset plots operate on sets, e.g. they require that a hard threshold has been applied to the results of a differential expression analysis. That’s problematic, because p-values themselves display high variability and dichotomizing quantitative information looses information.↩︎"
  },
  {
    "objectID": "posts/upset_plots/index.html#reproducibility",
    "href": "posts/upset_plots/index.html#reproducibility",
    "title": "UpSet plots: comparing differential expression across contrasts",
    "section": "Reproducibility",
    "text": "Reproducibility\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Los_Angeles\n date     2022-12-24\n pandoc   2.19.2 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package              * version  date (UTC) lib source\n airway               * 1.18.0   2022-11-03 [1] Bioconductor\n askpass                1.1      2019-01-13 [1] CRAN (R 4.2.0)\n Biobase              * 2.58.0   2022-11-01 [1] Bioconductor\n BiocGenerics         * 0.44.0   2022-11-01 [1] Bioconductor\n bitops                 1.0-7    2021-04-24 [1] CRAN (R 4.2.0)\n circlize               0.4.15   2022-05-10 [1] CRAN (R 4.2.0)\n cli                    3.4.1    2022-09-23 [1] CRAN (R 4.2.0)\n clue                   0.3-63   2022-11-19 [1] CRAN (R 4.2.0)\n cluster                2.1.4    2022-08-22 [2] CRAN (R 4.2.2)\n codetools              0.2-18   2020-11-04 [2] CRAN (R 4.2.2)\n colorspace             2.0-3    2022-02-21 [1] CRAN (R 4.2.0)\n ComplexHeatmap       * 2.14.0   2022-11-01 [1] Bioconductor\n crayon                 1.5.2    2022-09-29 [1] CRAN (R 4.2.0)\n credentials            1.3.2    2021-11-29 [1] CRAN (R 4.2.0)\n DelayedArray           0.24.0   2022-11-01 [1] Bioconductor\n digest                 0.6.31   2022-12-11 [1] CRAN (R 4.2.0)\n doParallel             1.0.17   2022-02-07 [1] CRAN (R 4.2.0)\n edgeR                * 3.40.1   2022-12-14 [1] Bioconductor\n evaluate               0.19     2022-12-13 [1] CRAN (R 4.2.0)\n fastmap                1.1.0    2021-01-25 [1] CRAN (R 4.2.0)\n foreach                1.5.2    2022-02-02 [1] CRAN (R 4.2.0)\n GenomeInfoDb         * 1.34.4   2022-12-01 [1] Bioconductor\n GenomeInfoDbData       1.2.9    2022-12-12 [1] Bioconductor\n GenomicRanges        * 1.50.2   2022-12-16 [1] Bioconductor\n GetoptLong             1.0.5    2020-12-15 [1] CRAN (R 4.2.0)\n GlobalOptions          0.1.2    2020-06-10 [1] CRAN (R 4.2.0)\n glue                   1.6.2    2022-02-24 [1] CRAN (R 4.2.0)\n htmltools              0.5.4    2022-12-07 [1] CRAN (R 4.2.0)\n htmlwidgets            1.5.4    2021-09-08 [1] CRAN (R 4.2.2)\n IRanges              * 2.32.0   2022-11-01 [1] Bioconductor\n iterators              1.0.14   2022-02-05 [1] CRAN (R 4.2.0)\n jsonlite               1.8.4    2022-12-06 [1] CRAN (R 4.2.0)\n knitr                  1.41     2022-11-18 [1] CRAN (R 4.2.0)\n lattice                0.20-45  2021-09-22 [2] CRAN (R 4.2.2)\n lifecycle              1.0.3    2022-10-07 [1] CRAN (R 4.2.0)\n limma                * 3.54.0   2022-11-01 [1] Bioconductor\n locfit                 1.5-9.6  2022-07-11 [1] CRAN (R 4.2.0)\n magrittr               2.0.3    2022-03-30 [1] CRAN (R 4.2.0)\n Matrix                 1.5-3    2022-11-11 [1] CRAN (R 4.2.0)\n MatrixGenerics       * 1.10.0   2022-11-01 [1] Bioconductor\n matrixStats          * 0.63.0   2022-11-18 [1] CRAN (R 4.2.0)\n openssl                2.0.5    2022-12-06 [1] CRAN (R 4.2.0)\n png                    0.1-8    2022-11-29 [1] CRAN (R 4.2.0)\n RColorBrewer           1.1-3    2022-04-03 [1] CRAN (R 4.2.0)\n Rcpp                   1.0.9    2022-07-08 [1] CRAN (R 4.2.0)\n RCurl                  1.98-1.9 2022-10-03 [1] CRAN (R 4.2.0)\n rjson                  0.2.21   2022-01-09 [1] CRAN (R 4.2.0)\n rlang                  1.0.6    2022-09-24 [1] CRAN (R 4.2.0)\n rmarkdown              2.19     2022-12-15 [1] CRAN (R 4.2.0)\n rstudioapi             0.14     2022-08-22 [1] CRAN (R 4.2.0)\n S4Vectors            * 0.36.1   2022-12-05 [1] Bioconductor\n sessioninfo            1.2.2    2021-12-06 [1] CRAN (R 4.2.0)\n shape                  1.4.6    2021-05-19 [1] CRAN (R 4.2.0)\n stringi                1.7.8    2022-07-11 [1] CRAN (R 4.2.0)\n stringr                1.5.0    2022-12-02 [1] CRAN (R 4.2.0)\n SummarizedExperiment * 1.28.0   2022-11-01 [1] Bioconductor\n sys                    3.4.1    2022-10-18 [1] CRAN (R 4.2.0)\n vctrs                  0.5.1    2022-11-16 [1] CRAN (R 4.2.0)\n xfun                   0.35     2022-11-16 [1] CRAN (R 4.2.0)\n XVector                0.38.0   2022-11-01 [1] Bioconductor\n yaml                   2.3.6    2022-10-18 [1] CRAN (R 4.2.0)\n zlibbioc               1.44.0   2022-11-01 [1] Bioconductor\n\n [1] /Users/sandmann/Library/R/x86_64/4.2/library\n [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/interactive-gene-set-results/index.html",
    "href": "posts/interactive-gene-set-results/index.html",
    "title": "Interactive GSEA results: visualizations with reactable & plotly",
    "section": "",
    "text": "As a Computational Biologist, I frequently analyze data from high throughput experiments, including transcriptomics, proteomics or metabolomics results. As a first step, I usually examine the behavior of individual analysis - genes, proteins or metabolites - and obtain a long list of effect sizes, p- or q-values.\nFrequently, another layer of analysis focuses on the behavior of predefined gene sets, e.g. groups of genes whose up- or down-regulation reflects the activity of a biological process, a metabolic pathway or is indicative of a cellular state.\nThere are numerous methods to perform gene set enrichment (GSEA), over-representation (ORA) or pathway analysis, with more than 140 R packages on Bioconductor alone.\nThis work is licensed under a Creative Commons Attribution 4.0 International License."
  },
  {
    "objectID": "posts/interactive-gene-set-results/index.html#sharing-analysis-results",
    "href": "posts/interactive-gene-set-results/index.html#sharing-analysis-results",
    "title": "Interactive GSEA results: visualizations with reactable & plotly",
    "section": "Sharing analysis results",
    "text": "Sharing analysis results\nRegardless of the chosen statistical approach, GSEA or ORA analyses typically produce set-level statistics, e.g. a summary of the effect size across all members of a gene set alongside a statistic, p-value, etc.\nTo share results with my collaborators, I would like to enable them to\n\nBrowse set-level results to hone in on specific pathways / processes of interest.\nVisualize the behavior of the analytes in the set.\nDrill down to a subset of analytes and export e.g. gene-level results\n\nThe pioneering ReportingTools Bioconductor package creates static web pages for gene-set enrichment results, including gene- and set-level plots and statistics. But all of the plots are generated in advance, and interactivity is limited.\nIn this blog post, I take advantage of the reactable, plotly, crosstalk and htmlwidgets R packages to create a stand-alone interactive HTML report, allowing my collaborators to explore the results without the need for a server.\nI learned a lot about these incredibly useful packages!\n\n\n\n\n\n\nNote\n\n\n\nAt the time of writing, the current release of the reactable R package (v0.4.1) is not compatible with the latest release of the htmlwidgets (v1.6.0). This issue has already been fixed in reactable’s development version, which is available from github Alternatively, you can use the previous release of htmlwidgets (v1.5.4), e.g.  by installing it with remotes::install_version(\"htmlwidgets\", version = \"1.5.4\").\n\n\n\nFeatures\nHere, I am combining several interactive elements, linked through SharedData objects via crosstalk:\n\nAt the top, an interactive volcano plot showing the effects sizes (mean trimmed log2 fold changes) and nominal p-values for each tested gene set.\nBelow, a nested reatable table displays the results for each set. When a row is expanded\n\nIt shows a volcano plot with gene-level results, as well as a linked table with the corresponding statistics.\nThe reader can hone in on specific genes by selecting points in the volcano plot, or by searching the table.\n\n\n\n\nShow the code\nlibrary(Biobase)\nlibrary(crosstalk)\nlibrary(dplyr)\nlibrary(htmltools)\nlibrary(plotly)\nlibrary(reactable)\nlibrary(sparrow)\nlibrary(stringr)\nlibrary(htmlwidgets)  \nlibrary(V8)  # to create static HTML\n\n#' Retrieve gene-level statistics for a single gene set\n#' \n#' @param stats named list of data.frames with gene-level statistics, one for\n#' each gene set \n#' @gene_set_name Scalar character, the name of an element of `stats`.\n#' in `data`.\n#' @return A data.frame with results for a single gene set\n.get_gene_data <- function(mg, gene_set_name, keep.cols = c(\n  \"symbol\", \"entrez_id\", \"logFC\", \"pval\", \"CI.L\", \"CI.R\", \"pval\", \"padj\")) {\n  sparrow::geneSet(mg, name = gene_set_name) %>%\n    dplyr::select(tidyselect::any_of(keep.cols)) %>%\n    dplyr::arrange(pval)\n}\n\n#' @importFrom htmltools tags\n.entrez_url <- function(value) {\n  if(!is.na(value) & nzchar(value)) {\n    url <- sprintf(\"http://www.ncbi.nlm.nih.gov/gene/%s\",\n                   value)\n    return(htmltools::tags$a(href = url, target = \"_blank\", \n                             as.character(value)))\n  } else {\n    return(value)\n  }\n}\n\n#' @importFrom htmltools tags\n.symbol_url <- function(value) {\n  if(!is.na(value) & nzchar(value)) {\n    url <- sprintf(\n      \"https://www.genenames.org/tools/search/#!/?query=%s\",\n      value)\n    return(\n      htmltools::tags$a(href = url, target = \"_blank\", as.character(value))\n    )\n  } else {\n    return(value)\n  }\n}\n\n#' @importFrom htmltools tags\n.msigdb_url <- function(value) {\n  if(!is.na(value) & nzchar(value)) {\n    url <- sprintf(\n      \"https://www.gsea-msigdb.org/gsea/msigdb/human/geneset/%s.html\",\n      value)\n    return(\n      htmltools::tags$a(href = url, target = \"_blank\", as.character(value))\n    )\n  } else {\n    return(value)\n  }\n}\n\n#' Create a reactable table with gene-level results\n#' \n#' @param data A data.frame or a `SharedData` object.\n#' @param defaultColDef A list that defines the default configuration for a \n#' column, typically the output of the [reactable::colDef] function.\n#' @param columns A list of column definitions, each generated with the \n#' [reactable::colDef] function.\n#' @param theme A `reactableTheme` object, typically generated with a call to\n#' the [reactable::reactableTheme] function.\n#' @param striped Scalar flag, display stripes?\n#' @param bordered Scalar flag, display borders?\n#' @param highlight Scalar flag, highlight selected rows?\n#' @param searchable Scalar flag, add search box?\n#' @param defaultPageSize Scalar integer, the default number of rows to display.\n#' @param elementId Scalar character, an (optional) element identifier\n#' @param ... Additional arguments for the [reactable::reactable] function.\n#' @return A `reactable` object.\n#' @export\n#' @importFrom reactable colDef reactable colFormat\n#' @examples\n#' \\dontrun{\n#' df <- data.frame(\n#'    symbol = c(\"TP53\", \"KRAS\", \"PIK3CA\"),\n#'    pval = runif(3, 0, 1),\n#'    logFC = rnorm(3)\n#' )\n#' stats_table(df)\n#' }\nstats_table <- function(\n    data, \n    defaultColDef = reactable::colDef(\n      align = \"center\",\n      minWidth = 100,\n      sortNALast = TRUE\n    ),\n    columns = list(\n      symbol = reactable::colDef(\n        name = \"Symbol\",\n        cell = .symbol_url\n      ),\n      entrezid = reactable::colDef(\n        name = \"EntrezId\",\n        cell = .entrez_url\n      ),\n      entrez_id = reactable::colDef(\n        name = \"EntrezId\",\n        cell = .entrez_url\n      ),\n      entrez = reactable::colDef(\n        name = \"EntrezId\",\n        cell = .entrez_url\n      ),\n      pval = reactable::colDef(\n        name = \"P-value\",\n        format = reactable::colFormat(digits = 4)),\n      padj = reactable::colDef(\n        name = \"P-value\",\n        format = reactable::colFormat(digits = 4)),\n      t = reactable::colDef(\n        name = \"t-statistic\",\n        format = reactable::colFormat(digits = 2)),\n      B = reactable::colDef(\n        name = \"log-odds\",\n        format = reactable::colFormat(digits = 2)),\n      AveExpr = reactable::colDef(\n        name = \"Mean expr\",\n        format = reactable::colFormat(digits = 2)),\n      CI.L = reactable::colDef(\n        name = \"Lower 95% CI\",\n        format = reactable::colFormat(digits = 2)),\n      CI.R = reactable::colDef(\n        name = \"Upper 95% CI\",\n        format = reactable::colFormat(digits = 2)),\n      logFC = reactable::colDef(\n        name = \"logFC\", \n        format = reactable::colFormat(digits = 2),\n        style = function(value) {\n          if (value > 0) {\n            color <- \"firebrick\"\n          } else if (value < 0) {\n            color <- \"navy\"\n          } else {\n            color <- \"lightgrey\"\n          }\n          list(color = color, fontWeight = \"bold\")\n        }\n      )\n    ),\n    theme = reactable::reactableTheme(\n      stripedColor = \"#f6f8fa\",\n      highlightColor = \"#f0f5f9\",\n      cellPadding = \"8px 12px\",\n      style = list(\n        fontFamily = \"-apple-system, BlinkMacSystemFont, Segoe UI, Helvetica, \n        Arial, sans-serif\")\n    ),\n    striped = FALSE,\n    bordered = FALSE,\n    highlight = TRUE,\n    searchable = TRUE,\n    defaultPageSize = 10L,\n    elementId = NULL,\n    ...\n) {\n  reactable::reactable(\n    data = data,\n    searchable = searchable,\n    striped = striped,\n    bordered = bordered,\n    highlight = highlight,\n    selection = \"multiple\",\n    onClick = \"select\",\n    rowStyle = list(cursor = \"pointer\"),\n    theme = theme,\n    defaultPageSize = defaultPageSize,\n    defaultColDef = defaultColDef,\n    columns = columns,\n    elementId = elementId,\n    ...\n  )\n}\n\n#' Wrap stats_table() output in a div html tag\n#' \n#' @param style Scalar character, the style tag for the tag\n#' @param elementId Scalar character, the element identifier\n#' @param ... Arguments passed on to the `stats_table` function.\n#' @return A `shiny.tag` object.\n#' @importFrom htmltools div tags\n.stats_table_div <- function(\n    style = paste0(\n      \"width: 50%;\",\n      \"float: right;\",\n      \"padding-top: 1rem;\"\n    ),\n    elementId = NULL,\n    ...) {\n  if (is.null(elementId)) {\n    elementId <- basename(tempfile(pattern = \"id\"))\n  }    \n  htmltools::div(\n    style = style,\n    htmltools::tagList(\n      stats_table(..., elementId = elementId),\n      # download button\n      htmltools::tags$button(\n        \"\\u21E9 Download as CSV\",\n        onclick = sprintf(\"Reactable.downloadDataCSV('%s', 'gene-results.csv')\",\n                          elementId)\n      )\n    )    \n  )\n}\n\n#' Create an interactive volcano plot\n#' \n#' @param data A data.frame or a `SharedData` object.\n#' @param x A `formula` defining the column of `data` mapped to the x-axis.\n#' @param y A `formula` defining the column of `data` mapped to the y-axis.\n#' @param text A `formula` defining the column of `data` mapped to the tooltip.\n#' @param title Scalar character, the title of the plot.\n#' @param xlab Scalar character, the title of the x-axis\n#' @param ylab Scalar character, the title pf the y-axis\n#' @param title.width Scalar integer, the target line width (passed on to the\n#' [stringr::str_wrap] function.\n#' @param opacity Scalar numeric between 0 and 1, the opacity of the points.\n#' @param marker A list defining the size, line and color limits of the points.\n#' @param colors Character vector of colors used to shade the points.\n#' @param highlight.color Scalar character, the color used to highlight selected\n#' points.\n#' @param webGL Scalar flag, use webGL to render the plot?\n#' @param width Scalar numeric or scalar character, width of the plot\n#' @param height Scalar numeric or scalar character, height of the plot\n#' @param ... Additional arguments passed to the [plotly::plot_ly] function.\n#' @return A `plotly` object.\n#' @importFrom plotly plot_ly add_trace config layout highlight toWebGL\n#' @importFrom grDevices colorRampPalette\n#' @export\n#' @examples\n#' \\dontrun{\n#' df <- data.frame(\n#'    symbol = letters,\n#'    pval = runif(length(letters), 0, 1),\n#'    logFC = rnorm(length(letters))\n#' )\n#' volcano_plot(df)\n#' }\nvolcano_plot <- function(\n    data, \n    x = ~logFC,\n    y = ~-log10(pval),\n    text = ~symbol,\n    title = \"\",\n    xlab = \"Fold change (log2)\",\n    ylab = \"-log10(pval)\",\n    title.width = 35L,\n    opacity = 0.5,\n    marker = list(\n      color = ~logFC,\n      size = 10, \n      cmax = 3,\n      cmid = 0,\n      cmin = -3,\n      line = list(color = \"grey\", width = 1)),\n    colors = grDevices::colorRampPalette(\n      c('navy', 'lightgrey', 'firebrick'))(15),\n    highlight.color = \"red\",\n    webGL = FALSE,\n    width = NULL,\n    height = NULL,\n    ...) {\n  p <- plotly::plot_ly(\n    width = width,\n    height = height\n  ) %>% \n    plotly::add_trace(\n      data = data, \n      name = \"\",\n      type = 'scatter',\n      mode = 'markers',\n      x = x,\n      y = y,\n      text = text,\n      hoverinfo =\"text\",\n      opacity = opacity,\n      colors = colors,\n      marker = marker,\n      ...\n    ) %>%\n    plotly::config(displaylogo = FALSE) %>%\n    plotly::layout(\n        xaxis = list(title = xlab),\n        yaxis = list(title = ylab),\n        title = stringr::str_wrap(\n          stringr::str_replace_all(title, \"_\", \" \"),\n          width = title.width)\n    ) %>%\n    plotly::highlight(\n      color = highlight.color,\n      on = \"plotly_selected\",\n      off = \"plotly_deselect\"\n    )\n  if (isTRUE(webGL)) p <- plotly::toWebGL(p)\n  return(p)\n}\n\n#' Create an interactive volcano plot for gene-set results\n#' \n#' @param data A data.frame or a `SharedData` object.\n#' @param x A `formula` defining the column of `data` mapped to the x-axis.\n#' @param y A `formula` defining the column of `data` mapped to the y-axis.\n#' @param text A `formula` defining the column of `data` mapped to the tooltip.\n#' @param xlab Scalar character, the title of the x-axis\n#' @param text.width Scalar integer, the target line width (passed on to the\n#' [stringr::str_wrap] function.\n#' @param hovertemplate Scalar character defining the tooltip template.\n#' @param marker A list defining the size, line and color limits of the points.\n#' @param width Scalar numeric or scalar character, width of the plot\n#' @param height Scalar numeric or scalar character, height of the plot\n#' @param ... Additional arguments passed to the [volcano_plot] function.\n#' @return A `plotly` object.\n#' @importFrom grDevices colorRampPalette\n#' @importFrom stringr str_wrap str_replace_all\n#' @export\n#' @examples\n#' \\dontrun{\n#' df <- data.frame(\n#'    name = paste(\"Set\", letters),\n#'    pval = runif(length(letters), 0, 1),\n#'    mean.logFC.trim = rnorm(length(letters)),\n#'    n = sample(1:100, size = length(letters))\n#' )\n#' volcano_gene_set_plot(df)\n#' }\nvolcano_gene_set_plot <- function(\n    data,\n    text = ~stringr::str_wrap(\n          stringr::str_replace_all(name, \"_\", \" \"),\n          width = text.width),\n    text.width = 25,\n    x = ~mean.logFC.trim,\n    y = ~-log10(pval),\n    marker = list(\n      color = ~mean.logFC.trim,\n      size = ~n, \n      sizemode = 'area', \n      cmax = 2,\n      cmid = 0,\n      cmin = -2,\n      line = list(color = \"grey\", width = 1)\n    ), \n    hovertemplate = paste(\n            '<b>%{text}</b>',\n            '<br><i>logFC</i>: %{x:.2f}',\n            '<br><i>-log10(pval)</i>: %{y:.2f}',\n            '<br><i>n</i>: %{marker.size}',\n            '<br>'),\n    xlab = \"Fold change (log2)\",\n    width = NULL,\n    height = NULL,\n    ...)\n{\n  volcano_plot(\n    data = data, \n    text = text, \n    x = x, \n    y = y,\n    marker = marker, \n    xlab = xlab,\n    hovertemplate = hovertemplate,\n    width = width,\n    height = height,\n    ...)\n}\n\n#' Wrap volcano_plot() output in a div html tag\n#' \n#' @param helptext Scalar character, text to display below the plot.\n#' @param style Scalar character, the style tag for the tag\n#' @param ... Arguments passed on to the `volcano_plot` function.\n#' @return A `shiny.tag` object.\n#' @importFrom htmltools div tagList p\n.volcano_plot_div <- function(\n    helptext = paste(\"Draw a rectangle / use the lasso tool to select points,\",\n                     \"double-click to deselect all.\"), \n    style = paste0(\n      \"width: 50%;\",\n      \"float: left;\",\n      \"padding-right: 1rem;\",\n      \"padding-top: 4rem;\"\n    ), \n    ...) {\n  htmltools::div(\n    style = style, {\n      htmltools::tagList(\n        volcano_plot(...),\n        htmltools::p(helptext)\n      )\n    }\n  )\n}\n\n#' Helper function to combine gene-level outputs into a single div\n#' \n#' @param data A data.frame with gene-set results.\n#' @param stats A named list of data.frames whose names much match the `name`\n#' column of `data`.\n#' @param index Scalar count, the row of `data` to plot.\n#' @return A `shiny.tag` object containing the output of the \n#' `.volcano_plot_div()` and `.stats_table_div()` functions.\n#' @importFrom crosstalk SharedData\n#' @importfrom htmltools tagList div\n.row_details <- function(data, mg, index) {\n  gene_data <- .get_gene_data(mg = mg, gene_set_name = data$name[index])\n  gd <- crosstalk::SharedData$new(gene_data)\n  htmltools::div(\n    htmltools::tagList(\n      # volcano plot\n      .volcano_plot_div(data = gd, title = data$name[index]),\n      # interactive gene-stat table\n      .stats_table_div(data = gd)\n    )\n  )\n}\n\n#' Create a nested gene set result table\n#' \n#' @param mg A `SparrowResult` object\n#' @param max.pval Scalar numeric, the largest (uncorrected) p-value for which\n#' to return results.\n#' @param max.results Scalar integer, the top number of rows to return\n#' (ordered by p-value).\n#' @param color.up Scalar character, the color for positive log2 fold changes.\n#' @param color.down Scalar character, the color for negative log2 fold changes.\n#' @param color.ns Scalar character, the color for zero log2 fold change.\n#' @param theme A `reactableTheme` object, typically generated with a call to\n#' the [reactable::reactableTheme] function.\n#' @param defaultColDef A list that defines the default configuration for a \n#' column, typically the output of the [reactable::colDef] function.\n#' @param columns A list of column definitions, each generated with the \n#' [reactable::colDef] function.\n#' @param bordered Scalar flag, display borders?\n#' @param highlight Scalar flag, highlight selected rows?\n#' @param searchable Scalar flag, add search box?\n#' @param striped Scalar flag, alternate row shading?\n#' @param defaultPageSize Scalar integer, the default number of rows to display.\n#' @param pageSizeOptions Integer vector that will populate the pagination menu.\n#' @param paginationType Scalar character, the pagination control to use. Either\n#' `numbers` for page number buttons (the default), `jump` for a page jump, or \n#' `simple` to show 'Previous' and 'Next' buttons only.\n#' @param elementId Scalar character, an (optional) element identifier\n#' @param defaultSorted Character vector of column names to sort by default. Or\n#' to customize sort order, a named list with values of `asc` or `desc`.\n#' @param name_url A function that returns a `shiny.tag` (usually an \n#' `<a href></a>` tag) for each element of the `name` column of `data` to link\n#' to more information about the gene set (e.g. on the MSigDb website, etc).\n#' @param ... Additional arguments for the [reactable::reactable] function.\n#' @importFrom reactable reactable reactableTheme colDef colFormat\n#' @return A `reactable` object with one row for each row in `data`, each of\n#' which can be expanded into the output of the `.row_details()` function\n#' for that specific gene set.\n#' @export\n#' @examples\n#' \\dontrun{\n#' library(sparrow)\n#' vm <- sparrow::exampleExpressionSet()\n#' gdb <- sparrow::exampleGeneSetDb()\n#' mg <- sparrow::seas(vm, gdb, c('fry'), design = vm$design, \n#'                     contrast = 'tumor')\n#' gene_set_table(mg, max.results = 10)\n#' }\ngene_set_table <- function(\n    mg,\n    max.pval = 0.05,\n    max.results = Inf,\n    keep.cols = c(\"collection\", \"name\", \"n\", \"pval\", \"padj\", \n                      \"mean.logFC.trim\"),\n    method = resultNames(mg)[1],\n    color.up = \"firebrick\", \n    color.down = \"navy\",\n    color.ns = \"grey50\",\n    theme = reactable::reactableTheme(\n      stripedColor = \"grey95\",\n      highlightColor = \"grey80\",\n      cellPadding = \"8px 12px\",\n      style = list(\n        fontFamily = \"-apple-system, BlinkMacSystemFont, Segoe UI, Helvetica, \n        Arial, sans-serif\")\n    ),\n    defaultColDef = reactable::colDef(\n      header = function(value) value,\n      align = \"center\",\n      minWidth = 100,\n      headerStyle = list(background = \"#f7f7f8\"),\n      sortNALast = TRUE\n    ),\n    name_url = function(value) {value},\n    columns = list(\n      collection = reactable::colDef(\n        name = \"Collection\"),\n      name = reactable::colDef(\n        name = \"Gene set\",\n        cell = name_url,\n        minWidth = 150),\n      pval = reactable::colDef(\n        name = \"P-value\", aggregate = \"min\",\n        format = reactable::colFormat(digits = 4)),\n      padj = reactable::colDef(\n        name = \"FDR\", aggregate = \"min\",\n        format = reactable::colFormat(digits = 4)),\n      Direction =  reactable::colDef(\n        name = \"dir\", minWidth = 45, \n        cell = function(value) {\n          if (value == \"Up\")  \"\\u2B06\" else \"\\u2B07\"\n        }),\n      logFC = reactable::colDef(\n        name = \"logFC\", format = reactable::colFormat(digits = 2),\n        style = function(value) {\n          if (value > 0) {\n            color <- color.up\n          } else if (value < 0) {\n            color <- color.down\n          } else {\n            color <- color.ns\n          }\n          list(color = color, fontWeight = \"bold\")\n        }\n      ),\n      mean.logFC.trim = reactable::colDef(\n        name = \"logFC\", format = reactable::colFormat(digits = 2),\n        style = function(value) {\n          if (value > 0) {\n            color <- color.up\n          } else if (value < 0) {\n            color <- color.down\n          } else {\n            color <- color.ns\n          }\n          list(color = color, fontWeight = \"bold\")\n        }\n      )\n    ),\n    elementId = \"expansion-table\",\n    static = TRUE,\n    filterable = TRUE,\n    searchable = TRUE,\n    bordered = TRUE,\n    striped = FALSE,\n    highlight = TRUE,\n    defaultPageSize = 25L,\n    showPageSizeOptions = TRUE,\n    pageSizeOptions = sort(unique(c(25, 50, 100, nrow(data)))),\n    paginationType = \"simple\",\n    defaultSorted = list(pval = \"asc\")\n) {\n  data = sparrow::result(mg, method) %>%\n    dplyr::slice_min(n = max.results, order_by = pval) %>%\n    dplyr::filter(pval <= max.pval) %>%\n    dplyr::select(tidyselect::any_of(keep.cols))\n  if (nrow(data) == 0) {\n    warning(\"None of the gene sets pass the `max.pval` threshold.\")\n    return(NULL)\n  }\n  reactable::reactable(\n    data,\n    elementId = elementId,\n    defaultColDef = defaultColDef,\n    static = static,\n    filterable = filterable,\n    searchable = searchable,\n    bordered = bordered,\n    highlight = highlight,\n    theme = theme,\n    defaultPageSize = defaultPageSize,\n    showPageSizeOptions = showPageSizeOptions,\n    pageSizeOptions = pageSizeOptions,\n    paginationType = paginationType,\n    defaultSorted = defaultSorted,\n    columns = columns,\n    details = function(index) {\n      .row_details(data = data, mg = mg, index)\n    }\n  )\n}\n\n#' Wrapper to create a div HTML tag\n#' @param mg A `SparrowResult` object\n#' @param method Scalar character, which results to return from `mg`.\n#' @param max.pal Scalar numeric, return only results wiht an (uncorrected)\n#' <= `max.pal`.\n#' @param verbose Scalar flag, show messages?\n#' @param title Scalar character, the `h1` title for the element\n#' @param elementId Scalar character, the element identifier for the interactive\n#' table.\n#' @param style Scalar character, the style tag for the tag\n#' @param ... Additional arguments passed on to the `gene_set_table` function.\n#' @return A `shiny.tag` object containing the output of the \n#' `gene_set_table()` function.\n#' @importFrom htmltools div h1 tagList tags\n#' @export\ngene_set_report <- function(\n    mg,\n    method = resultNames(mg)[1], \n    max.pval = 0.05,\n    max.results = Inf,\n    verbose = TRUE,\n    title = \"Gene set enrichment analysis\",\n    elementId = \"expansion-table\",\n    style = \"\",\n    ...\n) {\n  if (!is.finite(max.results)) {\n    message.log <- sprintf(\n      paste(\"Reporting all '%s' results with (uncorrected)\",\n            \"p-value <= %s\"), \n      method, max.pval)\n  } else {\n    message.log <- sprintf(\n      paste(\"Reporting up to %s '%s' results with (uncorrected)\",\n            \"p-value <= %s\"), \n      max.results, method, max.pval)\n  }\n  if (isTRUE(verbose)) {\n    message(message.log)\n  }\n  htmltools::div(\n    style = style, \n    {\n      htmltools::tagList(\n        htmltools::h1(title),\n        htmltools::p(message.log),\n        # volcano plot\n        sparrow::result(mg, method) %>%\n          dplyr::slice_min(n = max.results, order_by = pval) %>%\n          volcano_gene_set_plot(width = \"50%\"),\n        htmltools::br(),\n        # expansion button\n        htmltools::tags$button(\n          \"Expand/collapse all rows\",\n          onclick = sprintf(\"Reactable.toggleAllRowsExpanded('%s')\", elementId)\n        ),\n        gene_set_table(mg = mg, max.pval = max.pval, max.results = max.results,\n                       ...)\n      )\n    })\n}\n\n# gene set enrichment analysis with the sparrow Bioconductor package\nvm <- exampleExpressionSet()\ngdb <- exampleGeneSetDb()\nmg <- seas(vm, gdb, c('fry'), design = vm$design, contrast = 'tumor')\n\n\n\n\nShow the code\n# create an interactive report\nhtmltools::browsable(\n  gene_set_report(mg, method = \"fry\", max.pval = 0.05, max.results = Inf)\n)\n\n\nReporting all 'fry' results with (uncorrected) p-value <= 0.05\n\n\n\n\nGene set enrichment analysis\nReporting all 'fry' results with (uncorrected) p-value <= 0.05\n\n\n\nExpand/collapse all rows\nCollectionGene setnP-valueFDRlogFC​​c2LOPEZ_MESOTELIOMA_SURVIVAL_TIME_UP140.00070.02141.92​​c2BOYAULT_LIVER_CANCER_SUBCLASS_G123_DN410.00090.0214-0.65​​c2BIOCARTA_AGPCR_PATHWAY110.00130.0214-0.50​​c2GUTIERREZ_WALDENSTROEMS_MACROGLOBULINEMIA_1_UP90.00150.0214-0.60​​c6KRAS.LUNG.BREAST_UP.V1_DN960.00160.0214-0.34​​c2DARWICHE_PAPILLOMA_RISK_HIGH_VS_LOW_DN260.00170.0214-0.39​​c6KRAS.600.LUNG.BREAST_UP.V1_DN1890.00240.0259-0.26​​c2YAMASHITA_LIVER_CANCER_STEM_CELL_DN470.00310.0278-0.44​​c7GSE12845_IGD_POS_BLOOD_VS_PRE_GC_TONSIL_BCELL_UP1770.00350.0278-0.13​​c2SOTIRIOU_BREAST_CANCER_GRADE_1_VS_3_UP1490.00370.02781.83​​c6KRAS.BREAST_UP.V1_DN900.00450.0314-0.31​​c6KRAS.50_UP.V1_UP330.00540.0341-0.67​​c6GLI1_UP.V1_DN240.00600.03520.18​​c2SCHAEFFER_PROSTATE_DEVELOPMENT_48HR_DN3560.00730.0377-0.33​​c7GSE22886_IGG_IGA_MEMORY_BCELL_VS_BLOOD_PLASMA_CELL_UP1760.00760.0377-0.29​​c6CRX_NRL_DN.V1_DN990.00790.0377-0.21​​c6ATM_DN.V1_UP890.01130.0504-0.41​​c6CAMP_UP.V1_DN1830.01350.0569-0.23​​c6KRAS.DF.V1_DN1460.01630.0622-0.19​​c2REACTOME_MRNA_SPLICING_MINOR_PATHWAY420.01640.06220.34​​c2HUPER_BREAST_BASAL_VS_LUMINAL_UP520.01920.0679-0.76​​c6MEL18_DN.V1_DN1250.01960.0679-0.35​​c6KRAS.LUNG_UP.V1_DN980.02320.0741-0.43​​c6TBK1.DN.48HRS_DN500.02430.07410.17​​c2TURASHVILI_BREAST_LOBULAR_CARCINOMA_VS_DUCTAL_NORMAL_DN910.02450.0741-0.941–25 of 34 rowsShow 253450100Previous1 of 2Next\n\n\n\n\n\n\n\nDetails\n\nGene set enrichment analysis\nIn this example, I am using Steve Lianoglou’s sparrow Bioconductor package to perform gene set enrichment analysis. But any other method could be used, as long as both set-level and gene-level differential expression statistics can be obtained.\nsparrow supports numerous GSEA and ORA methods. Here, I am using the fry algorithm from the limma Bioconductor package for illustration.\n\n\nReproducibility\n\n\nSessionInfo\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Los_Angeles\n date     2022-12-29\n pandoc   2.19.2 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package          * version     date (UTC) lib source\n annotate           1.76.0      2022-11-01 [1] Bioconductor\n AnnotationDbi      1.60.0      2022-11-01 [1] Bioconductor\n askpass            1.1         2019-01-13 [1] CRAN (R 4.2.0)\n assertthat         0.2.1       2019-03-21 [1] CRAN (R 4.2.0)\n babelgene          22.9        2022-09-29 [1] CRAN (R 4.2.0)\n backports          1.4.1       2021-12-13 [1] CRAN (R 4.2.0)\n Biobase          * 2.58.0      2022-11-01 [1] Bioconductor\n BiocGenerics     * 0.44.0      2022-11-01 [1] Bioconductor\n BiocIO             1.8.0       2022-11-01 [1] Bioconductor\n BiocParallel       1.32.4      2022-12-01 [1] Bioconductor\n BiocSet            1.12.0      2022-11-01 [1] Bioconductor\n Biostrings         2.66.0      2022-11-01 [1] Bioconductor\n bit                4.0.5       2022-11-15 [1] CRAN (R 4.2.0)\n bit64              4.0.5       2020-08-30 [1] CRAN (R 4.2.0)\n bitops             1.0-7       2021-04-24 [1] CRAN (R 4.2.0)\n blob               1.2.3       2022-04-10 [1] CRAN (R 4.2.0)\n cachem             1.0.6       2021-08-19 [1] CRAN (R 4.2.0)\n checkmate          2.1.0       2022-04-21 [1] CRAN (R 4.2.0)\n circlize           0.4.15      2022-05-10 [1] CRAN (R 4.2.0)\n cli                3.4.1       2022-09-23 [1] CRAN (R 4.2.0)\n clue               0.3-63      2022-11-19 [1] CRAN (R 4.2.0)\n cluster            2.1.4       2022-08-22 [2] CRAN (R 4.2.2)\n codetools          0.2-18      2020-11-04 [2] CRAN (R 4.2.2)\n colorspace         2.0-3       2022-02-21 [1] CRAN (R 4.2.0)\n ComplexHeatmap     2.14.0      2022-11-01 [1] Bioconductor\n crayon             1.5.2       2022-09-29 [1] CRAN (R 4.2.0)\n credentials        1.3.2       2021-11-29 [1] CRAN (R 4.2.0)\n crosstalk        * 1.2.0       2021-11-04 [1] CRAN (R 4.2.0)\n curl               4.3.3       2022-10-06 [1] CRAN (R 4.2.0)\n data.table         1.14.6      2022-11-16 [1] CRAN (R 4.2.0)\n DBI                1.1.3       2022-06-18 [1] CRAN (R 4.2.0)\n digest             0.6.31      2022-12-11 [1] CRAN (R 4.2.0)\n doParallel         1.0.17      2022-02-07 [1] CRAN (R 4.2.0)\n dplyr            * 1.0.10      2022-09-01 [1] CRAN (R 4.2.0)\n edgeR              3.40.1      2022-12-14 [1] Bioconductor\n ellipsis           0.3.2       2021-04-29 [1] CRAN (R 4.2.0)\n evaluate           0.19        2022-12-13 [1] CRAN (R 4.2.0)\n fansi              1.0.3       2022-03-24 [1] CRAN (R 4.2.0)\n fastmap            1.1.0       2021-01-25 [1] CRAN (R 4.2.0)\n foreach            1.5.2       2022-02-02 [1] CRAN (R 4.2.0)\n generics           0.1.3       2022-07-05 [1] CRAN (R 4.2.0)\n GenomeInfoDb       1.34.4      2022-12-01 [1] Bioconductor\n GenomeInfoDbData   1.2.9       2022-12-12 [1] Bioconductor\n GetoptLong         1.0.5       2020-12-15 [1] CRAN (R 4.2.0)\n ggplot2          * 3.4.0       2022-11-04 [1] CRAN (R 4.2.0)\n GlobalOptions      0.1.2       2020-06-10 [1] CRAN (R 4.2.0)\n glue               1.6.2       2022-02-24 [1] CRAN (R 4.2.0)\n graph              1.76.0      2022-11-01 [1] Bioconductor\n gridExtra          2.3         2017-09-09 [1] CRAN (R 4.2.0)\n GSEABase           1.60.0      2022-11-01 [1] Bioconductor\n gtable             0.3.1       2022-09-01 [1] CRAN (R 4.2.0)\n htmltools        * 0.5.4       2022-12-07 [1] CRAN (R 4.2.0)\n htmlwidgets      * 1.5.4       2021-09-08 [1] CRAN (R 4.2.2)\n httpuv             1.6.7       2022-12-14 [1] CRAN (R 4.2.0)\n httr               1.4.4       2022-08-17 [1] CRAN (R 4.2.0)\n IRanges            2.32.0      2022-11-01 [1] Bioconductor\n irlba              2.3.5.1     2022-10-03 [1] CRAN (R 4.2.0)\n iterators          1.0.14      2022-02-05 [1] CRAN (R 4.2.0)\n jsonlite           1.8.4       2022-12-06 [1] CRAN (R 4.2.0)\n KEGGREST           1.38.0      2022-11-01 [1] Bioconductor\n knitr              1.41        2022-11-18 [1] CRAN (R 4.2.0)\n later              1.3.0       2021-08-18 [1] CRAN (R 4.2.0)\n lattice            0.20-45     2021-09-22 [2] CRAN (R 4.2.2)\n lazyeval           0.2.2       2019-03-15 [1] CRAN (R 4.2.0)\n lifecycle          1.0.3       2022-10-07 [1] CRAN (R 4.2.0)\n limma              3.54.0      2022-11-01 [1] Bioconductor\n locfit             1.5-9.6     2022-07-11 [1] CRAN (R 4.2.0)\n magrittr           2.0.3       2022-03-30 [1] CRAN (R 4.2.0)\n Matrix             1.5-3       2022-11-11 [1] CRAN (R 4.2.0)\n matrixStats        0.63.0      2022-11-18 [1] CRAN (R 4.2.0)\n memoise            2.0.1       2021-11-26 [1] CRAN (R 4.2.0)\n mime               0.12        2021-09-28 [1] CRAN (R 4.2.0)\n munsell            0.5.0       2018-06-12 [1] CRAN (R 4.2.0)\n ontologyIndex      2.10        2022-08-24 [1] CRAN (R 4.2.0)\n openssl            2.0.5       2022-12-06 [1] CRAN (R 4.2.0)\n pillar             1.8.1       2022-08-19 [1] CRAN (R 4.2.0)\n pkgconfig          2.0.3       2019-09-22 [1] CRAN (R 4.2.0)\n plotly           * 4.10.1.9000 2022-12-20 [1] Github (plotly/plotly.R@3a33b1a)\n plyr               1.8.8       2022-11-11 [1] CRAN (R 4.2.0)\n png                0.1-8       2022-11-29 [1] CRAN (R 4.2.0)\n promises           1.2.0.1     2021-02-11 [1] CRAN (R 4.2.0)\n purrr              0.3.5       2022-10-06 [1] CRAN (R 4.2.0)\n R6                 2.5.1       2021-08-19 [1] CRAN (R 4.2.0)\n RColorBrewer       1.1-3       2022-04-03 [1] CRAN (R 4.2.0)\n Rcpp               1.0.9       2022-07-08 [1] CRAN (R 4.2.0)\n RCurl              1.98-1.9    2022-10-03 [1] CRAN (R 4.2.0)\n reactable        * 0.4.1.9000  2022-12-20 [1] Github (glin/reactable@cf500a1)\n reactR             0.4.4       2021-02-22 [1] CRAN (R 4.2.0)\n rjson              0.2.21      2022-01-09 [1] CRAN (R 4.2.0)\n rlang              1.0.6       2022-09-24 [1] CRAN (R 4.2.0)\n rmarkdown          2.19        2022-12-15 [1] CRAN (R 4.2.0)\n RSQLite            2.2.19      2022-11-24 [1] CRAN (R 4.2.0)\n rstudioapi         0.14        2022-08-22 [1] CRAN (R 4.2.0)\n S4Vectors          0.36.1      2022-12-05 [1] Bioconductor\n scales             1.2.1       2022-08-20 [1] CRAN (R 4.2.0)\n sessioninfo        1.2.2       2021-12-06 [1] CRAN (R 4.2.0)\n shape              1.4.6       2021-05-19 [1] CRAN (R 4.2.0)\n shiny              1.7.4       2022-12-15 [1] CRAN (R 4.2.0)\n sparrow          * 1.4.0       2022-11-01 [1] Bioconductor\n statmod            1.4.37      2022-08-12 [1] CRAN (R 4.2.0)\n stringi            1.7.8       2022-07-11 [1] CRAN (R 4.2.0)\n stringr          * 1.5.0       2022-12-02 [1] CRAN (R 4.2.0)\n sys                3.4.1       2022-10-18 [1] CRAN (R 4.2.0)\n tibble             3.1.8       2022-07-22 [1] CRAN (R 4.2.0)\n tidyr              1.2.1       2022-09-08 [1] CRAN (R 4.2.0)\n tidyselect         1.2.0       2022-10-10 [1] CRAN (R 4.2.0)\n utf8               1.2.2       2021-07-24 [1] CRAN (R 4.2.0)\n V8               * 4.2.2       2022-11-03 [1] CRAN (R 4.2.0)\n vctrs              0.5.1       2022-11-16 [1] CRAN (R 4.2.0)\n viridis            0.6.2       2021-10-13 [1] CRAN (R 4.2.0)\n viridisLite        0.4.1       2022-08-22 [1] CRAN (R 4.2.0)\n withr              2.5.0       2022-03-03 [1] CRAN (R 4.2.0)\n xfun               0.35        2022-11-16 [1] CRAN (R 4.2.0)\n XML                3.99-0.13   2022-12-04 [1] CRAN (R 4.2.0)\n xtable             1.8-4       2019-04-21 [1] CRAN (R 4.2.0)\n XVector            0.38.0      2022-11-01 [1] Bioconductor\n yaml               2.3.6       2022-10-18 [1] CRAN (R 4.2.0)\n zlibbioc           1.44.0      2022-11-01 [1] Bioconductor\n\n [1] /Users/sandmann/Library/R/x86_64/4.2/library\n [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/interactive-gene-set-results/index.html#dependencies",
    "href": "posts/interactive-gene-set-results/index.html#dependencies",
    "title": "Interactive GSEA results: visualizations with reactable & plotly",
    "section": "Dependencies",
    "text": "Dependencies\nIn this example, I am using Steve Lianoglou’s sparrow Bioconductor package to perform gene set enrichment analysis. But any other method could be used, as long as both set-level and gene-level differential expression statistics can be obtained.\n\n\n\n\n\n\nWarn\n\n\n\nAt the time of writing, the current release of the reactable R package (v0.4.1) is not compatible with the latest release of the htmlwidgets (v1.6.0). This issue has already been fixed in reactable’s development version, which is available from github Alternatively, you can use the previous release of htmlwidgets (v1.5.4), e.g.  by installing it with remotes::install_version(\"htmlwidgets\", version = \"1.5.4\").\n\n\n\nlibrary(Biobase)\nlibrary(crosstalk)\nlibrary(dplyr)\nlibrary(htmltools)\nlibrary(plotly)\nlibrary(reactable)\nlibrary(sparrow)\nlibrary(stringr)\nlibrary(htmlwidgets)  \nlibrary(V8)  # to create static HTML\n\nif (Biobase::package.version(\"htmlwidgets\") > \"1.5.4\") {\n  # see https://github.com/ramnathv/htmlwidgets/issues/457\n  stop(\n    \"htmlwidgets version 1.6.0 is not compatible with nested reactable tables.\"\n  )\n}\n\n\n#' Retrieve gene-level statistics for a single gene set\n#' \n#' @param stats named list of data.frames with gene-level statistics, one for\n#' each gene set \n#' @gene_set_name Scalar character, the name of an element of `stats`.\n#' in `data`.\n#' @return A data.frame with results for a single gene set\n.get_gene_data <- function(mg, gene_set_name, keep.cols = c(\n  \"symbol\", \"entrez_id\", \"logFC\", \"pval\", \"CI.L\", \"CI.R\", \"pval\", \"padj\")) {\n  sparrow::geneSet(mg, name = gene_set_name) %>%\n    dplyr::select(tidyselect::any_of(keep.cols)) %>%\n    dplyr::arrange(pval)\n}\n\n#' @importFrom htmltools tags\n.entrez_url <- function(value) {\n  if(!is.na(value) & nzchar(value)) {\n    url <- sprintf(\"http://www.ncbi.nlm.nih.gov/gene/%s\",\n                   value)\n    return(htmltools::tags$a(href = url, target = \"_blank\", \n                             as.character(value)))\n  } else {\n    return(value)\n  }\n}\n\n#' @importFrom htmltools tags\n.symbol_url <- function(value) {\n  if(!is.na(value) & nzchar(value)) {\n    url <- sprintf(\n      \"https://www.genenames.org/tools/search/#!/?query=%s\",\n      value)\n    return(\n      htmltools::tags$a(href = url, target = \"_blank\", as.character(value))\n    )\n  } else {\n    return(value)\n  }\n}\n\n#' @importFrom htmltools tags\n.msigdb_url <- function(value) {\n  if(!is.na(value) & nzchar(value)) {\n    url <- sprintf(\n      \"https://www.gsea-msigdb.org/gsea/msigdb/human/geneset/%s.html\",\n      value)\n    return(\n      htmltools::tags$a(href = url, target = \"_blank\", as.character(value))\n    )\n  } else {\n    return(value)\n  }\n}\n\n#' Create a reactable table with gene-level results\n#' \n#' @param data A data.frame or a `SharedData` object.\n#' @param defaultColDef A list that defines the default configuration for a \n#' column, typically the output of the [reactable::colDef] function.\n#' @param columns A list of column definitions, each generated with the \n#' [reactable::colDef] function.\n#' @param theme A `reactableTheme` object, typically generated with a call to\n#' the [reactable::reactableTheme] function.\n#' @param striped Scalar flag, display stripes?\n#' @param bordered Scalar flag, display borders?\n#' @param highlight Scalar flag, highlight selected rows?\n#' @param searchable Scalar flag, add search box?\n#' @param defaultPageSize Scalar integer, the default number of rows to display.\n#' @param elementId Scalar character, an (optional) element identifier\n#' @param ... Additional arguments for the [reactable::reactable] function.\n#' @return A `reactable` object.\n#' @export\n#' @importFrom reactable colDef reactable colFormat\n#' @examples\n#' \\dontrun{\n#' df <- data.frame(\n#'    symbol = c(\"TP53\", \"KRAS\", \"PIK3CA\"),\n#'    pval = runif(3, 0, 1),\n#'    logFC = rnorm(3)\n#' )\n#' stats_table(df)\n#' }\nstats_table <- function(\n    data, \n    defaultColDef = reactable::colDef(\n      align = \"center\",\n      minWidth = 100,\n      sortNALast = TRUE\n    ),\n    columns = list(\n      symbol = reactable::colDef(\n        name = \"Symbol\",\n        cell = .symbol_url\n      ),\n      entrezid = reactable::colDef(\n        name = \"EntrezId\",\n        cell = .entrez_url\n      ),\n      entrez_id = reactable::colDef(\n        name = \"EntrezId\",\n        cell = .entrez_url\n      ),\n      entrez = reactable::colDef(\n        name = \"EntrezId\",\n        cell = .entrez_url\n      ),\n      pval = reactable::colDef(\n        name = \"P-value\",\n        format = reactable::colFormat(digits = 4)),\n      padj = reactable::colDef(\n        name = \"P-value\",\n        format = reactable::colFormat(digits = 4)),\n      t = reactable::colDef(\n        name = \"t-statistic\",\n        format = reactable::colFormat(digits = 2)),\n      B = reactable::colDef(\n        name = \"log-odds\",\n        format = reactable::colFormat(digits = 2)),\n      AveExpr = reactable::colDef(\n        name = \"Mean expr\",\n        format = reactable::colFormat(digits = 2)),\n      CI.L = reactable::colDef(\n        name = \"Lower 95% CI\",\n        format = reactable::colFormat(digits = 2)),\n      CI.R = reactable::colDef(\n        name = \"Upper 95% CI\",\n        format = reactable::colFormat(digits = 2)),\n      logFC = reactable::colDef(\n        name = \"logFC\", \n        format = reactable::colFormat(digits = 2),\n        style = function(value) {\n          if (value > 0) {\n            color <- \"firebrick\"\n          } else if (value < 0) {\n            color <- \"navy\"\n          } else {\n            color <- \"lightgrey\"\n          }\n          list(color = color, fontWeight = \"bold\")\n        }\n      )\n    ),\n    theme = reactable::reactableTheme(\n      stripedColor = \"#f6f8fa\",\n      highlightColor = \"#f0f5f9\",\n      cellPadding = \"8px 12px\",\n      style = list(\n        fontFamily = \"-apple-system, BlinkMacSystemFont, Segoe UI, Helvetica, \n        Arial, sans-serif\")\n    ),\n    striped = FALSE,\n    bordered = FALSE,\n    highlight = TRUE,\n    searchable = TRUE,\n    defaultPageSize = 10L,\n    elementId = NULL,\n    ...\n) {\n  reactable::reactable(\n    data = data,\n    searchable = searchable,\n    striped = striped,\n    bordered = bordered,\n    highlight = highlight,\n    selection = \"multiple\",\n    onClick = \"select\",\n    rowStyle = list(cursor = \"pointer\"),\n    theme = theme,\n    defaultPageSize = defaultPageSize,\n    defaultColDef = defaultColDef,\n    columns = columns,\n    elementId = elementId,\n    ...\n  )\n}\n\n#' Wrap stats_table() output in a div html tag\n#' \n#' @param style Scalar character, the style tag for the tag\n#' @param elementId Scalar character, the element identifier\n#' @param ... Arguments passed on to the `stats_table` function.\n#' @return A `shiny.tag` object.\n#' @importFrom htmltools div tags\n.stats_table_div <- function(\n    style = paste0(\n      \"width: 50%;\",\n      \"float: right;\",\n      \"padding-top: 1rem;\"\n    ),\n    elementId = NULL,\n    ...) {\n  if (is.null(elementId)) {\n    elementId <- basename(tempfile(pattern = \"id\"))\n  }    \n  htmltools::div(\n    style = style,\n    htmltools::tagList(\n      stats_table(..., elementId = elementId),\n      # download button\n      htmltools::tags$button(\n        \"\\u21E9 Download as CSV\",\n        onclick = sprintf(\"Reactable.downloadDataCSV('%s', 'gene-results.csv')\",\n                          elementId)\n      )\n    )    \n  )\n}\n\n#' Create an interactive volcano plot\n#' \n#' @param data A data.frame or a `SharedData` object.\n#' @param x A `formula` defining the column of `data` mapped to the x-axis.\n#' @param y A `formula` defining the column of `data` mapped to the y-axis.\n#' @param text A `formula` defining the column of `data` mapped to the tooltip.\n#' @param title Scalar character, the title of the plot.\n#' @param xlab Scalar character, the title of the x-axis\n#' @param ylab Scalar character, the title pf the y-axis\n#' @param title.width Scalar integer, the target line width (passed on to the\n#' [stringr::str_wrap] function.\n#' @param opacity Scalar numeric between 0 and 1, the opacity of the points.\n#' @param marker A list defining the size, line and color limits of the points.\n#' @param colors Character vector of colors used to shade the points.\n#' @param highlight.color Scalar character, the color used to highlight selected\n#' points.\n#' @param webGL Scalar flag, use webGL to render the plot?\n#' @param width Scalar numeric or scalar character, width of the plot\n#' @param height Scalar numeric or scalar character, height of the plot\n#' @param ... Additional arguments passed to the [plotly::plot_ly] function.\n#' @return A `plotly` object.\n#' @importFrom plotly plot_ly add_trace config layout highlight toWebGL\n#' @importFrom grDevices colorRampPalette\n#' @export\n#' @examples\n#' \\dontrun{\n#' df <- data.frame(\n#'    symbol = letters,\n#'    pval = runif(length(letters), 0, 1),\n#'    logFC = rnorm(length(letters))\n#' )\n#' volcano_plot(df)\n#' }\nvolcano_plot <- function(\n    data, \n    x = ~logFC,\n    y = ~-log10(pval),\n    text = ~symbol,\n    title = \"\",\n    xlab = \"Fold change (log2)\",\n    ylab = \"-log10(pval)\",\n    title.width = 35L,\n    opacity = 0.5,\n    marker = list(\n      color = ~logFC,\n      size = 10, \n      cmax = 3,\n      cmid = 0,\n      cmin = -3,\n      line = list(color = \"grey\", width = 1)),\n    colors = grDevices::colorRampPalette(\n      c('navy', 'lightgrey', 'firebrick'))(15),\n    highlight.color = \"red\",\n    webGL = FALSE,\n    width = NULL,\n    height = NULL,\n    ...) {\n  p <- plotly::plot_ly(\n    width = width,\n    height = height\n  ) %>% \n    plotly::add_trace(\n      data = data, \n      name = \"\",\n      type = 'scatter',\n      mode = 'markers',\n      x = x,\n      y = y,\n      text = text,\n      hoverinfo =\"text\",\n      opacity = opacity,\n      colors = colors,\n      marker = marker,\n      ...\n    ) %>%\n    plotly::config(displaylogo = FALSE) %>%\n    plotly::layout(\n        xaxis = list(title = xlab),\n        yaxis = list(title = ylab),\n        title = stringr::str_wrap(\n          stringr::str_replace_all(title, \"_\", \" \"),\n          width = title.width)\n    ) %>%\n    plotly::highlight(\n      color = highlight.color,\n      on = \"plotly_selected\",\n      off = \"plotly_deselect\"\n    )\n  if (isTRUE(webGL)) p <- plotly::toWebGL(p)\n  return(p)\n}\n\n#' Create an interactive volcano plot for gene-set results\n#' \n#' @param data A data.frame or a `SharedData` object.\n#' @param x A `formula` defining the column of `data` mapped to the x-axis.\n#' @param y A `formula` defining the column of `data` mapped to the y-axis.\n#' @param text A `formula` defining the column of `data` mapped to the tooltip.\n#' @param xlab Scalar character, the title of the x-axis\n#' @param text.width Scalar integer, the target line width (passed on to the\n#' [stringr::str_wrap] function.\n#' @param hovertemplate Scalar character defining the tooltip template.\n#' @param marker A list defining the size, line and color limits of the points.\n#' @param width Scalar numeric or scalar character, width of the plot\n#' @param height Scalar numeric or scalar character, height of the plot\n#' @param ... Additional arguments passed to the [volcano_plot] function.\n#' @return A `plotly` object.\n#' @importFrom grDevices colorRampPalette\n#' @importFrom stringr str_wrap str_replace_all\n#' @export\n#' @examples\n#' \\dontrun{\n#' df <- data.frame(\n#'    name = paste(\"Set\", letters),\n#'    pval = runif(length(letters), 0, 1),\n#'    mean.logFC.trim = rnorm(length(letters)),\n#'    n = sample(1:100, size = length(letters))\n#' )\n#' volcano_gene_set_plot(df)\n#' }\nvolcano_gene_set_plot <- function(\n    data,\n    text = ~stringr::str_wrap(\n          stringr::str_replace_all(name, \"_\", \" \"),\n          width = text.width),\n    text.width = 25,\n    x = ~mean.logFC.trim,\n    y = ~-log10(pval),\n    marker = list(\n      color = ~mean.logFC.trim,\n      size = ~n, \n      sizemode = 'area', \n      cmax = 2,\n      cmid = 0,\n      cmin = -2,\n      line = list(color = \"grey\", width = 1)\n    ), \n    hovertemplate = paste(\n            '<b>%{text}</b>',\n            '<br><i>logFC</i>: %{x:.2f}',\n            '<br><i>-log10(pval)</i>: %{y:.2f}',\n            '<br><i>n</i>: %{marker.size}',\n            '<br>'),\n    xlab = \"Fold change (log2)\",\n    width = NULL,\n    height = NULL,\n    ...)\n{\n  volcano_plot(\n    data = data, \n    text = text, \n    x = x, \n    y = y,\n    marker = marker, \n    xlab = xlab,\n    hovertemplate = hovertemplate,\n    width = width,\n    height = height,\n    ...)\n}\n\n#' Wrap volcano_plot() output in a div html tag\n#' \n#' @param helptext Scalar character, text to display below the plot.\n#' @param style Scalar character, the style tag for the tag\n#' @param ... Arguments passed on to the `volcano_plot` function.\n#' @return A `shiny.tag` object.\n#' @importFrom htmltools div tagList p\n.volcano_plot_div <- function(\n    helptext = paste(\"Draw a rectangle / use the lasso tool to select points,\",\n                     \"double-click to deselect all.\"), \n    style = paste0(\n      \"width: 50%;\",\n      \"float: left;\",\n      \"padding-right: 1rem;\",\n      \"padding-top: 4rem;\"\n    ), \n    ...) {\n  htmltools::div(\n    style = style, {\n      htmltools::tagList(\n        volcano_plot(...),\n        htmltools::p(helptext)\n      )\n    }\n  )\n}\n\n#' Helper function to combine gene-level outputs into a single div\n#' \n#' @param data A data.frame with gene-set results.\n#' @param stats A named list of data.frames whose names much match the `name`\n#' column of `data`.\n#' @param index Scalar count, the row of `data` to plot.\n#' @return A `shiny.tag` object containing the output of the \n#' `.volcano_plot_div()` and `.stats_table_div()` functions.\n#' @importFrom crosstalk SharedData\n#' @importfrom htmltools tagList div\n.row_details <- function(data, mg, index) {\n  gene_data <- .get_gene_data(mg = mg, gene_set_name = data$name[index])\n  gd <- crosstalk::SharedData$new(gene_data)\n  htmltools::div(\n    htmltools::tagList(\n      # volcano plot\n      .volcano_plot_div(data = gd, title = data$name[index]),\n      # interactive gene-stat table\n      .stats_table_div(data = gd)\n    )\n  )\n}\n\n#' Create a nested gene set result table\n#' \n#' @param mg A `SparrowResult` object\n#' @param max.pval Scalar numeric, the largest (uncorrected) p-value for which\n#' to return results.\n#' @param max.results Scalar integer, the top number of rows to return\n#' (ordered by p-value).\n#' @param color.up Scalar character, the color for positive log2 fold changes.\n#' @param color.down Scalar character, the color for negative log2 fold changes.\n#' @param color.ns Scalar character, the color for zero log2 fold change.\n#' @param theme A `reactableTheme` object, typically generated with a call to\n#' the [reactable::reactableTheme] function.\n#' @param defaultColDef A list that defines the default configuration for a \n#' column, typically the output of the [reactable::colDef] function.\n#' @param columns A list of column definitions, each generated with the \n#' [reactable::colDef] function.\n#' @param bordered Scalar flag, display borders?\n#' @param highlight Scalar flag, highlight selected rows?\n#' @param searchable Scalar flag, add search box?\n#' @param striped Scalar flag, alternate row shading?\n#' @param defaultPageSize Scalar integer, the default number of rows to display.\n#' @param pageSizeOptions Integer vector that will populate the pagination menu.\n#' @param paginationType Scalar character, the pagination control to use. Either\n#' `numbers` for page number buttons (the default), `jump` for a page jump, or \n#' `simple` to show 'Previous' and 'Next' buttons only.\n#' @param elementId Scalar character, an (optional) element identifier\n#' @param defaultSorted Character vector of column names to sort by default. Or\n#' to customize sort order, a named list with values of `asc` or `desc`.\n#' @param name_url A function that returns a `shiny.tag` (usually an \n#' `<a href></a>` tag) for each element of the `name` column of `data` to link\n#' to more information about the gene set (e.g. on the MSigDb website, etc).\n#' @param ... Additional arguments for the [reactable::reactable] function.\n#' @importFrom reactable reactable reactableTheme colDef colFormat\n#' @return A `reactable` object with one row for each row in `data`, each of\n#' which can be expanded into the output of the `.row_details()` function\n#' for that specific gene set.\n#' @export\n#' @examples\n#' \\dontrun{\n#' library(sparrow)\n#' vm <- sparrow::exampleExpressionSet()\n#' gdb <- sparrow::exampleGeneSetDb()\n#' mg <- sparrow::seas(vm, gdb, c('fry'), design = vm$design, \n#'                     contrast = 'tumor')\n#' gene_set_table(mg, max.results = 10)\n#' }\ngene_set_table <- function(\n    mg,\n    max.pval = 0.05,\n    max.results = Inf,\n    keep.cols = c(\"collection\", \"name\", \"n\", \"pval\", \"padj\", \n                      \"mean.logFC.trim\"),\n    method = resultNames(mg)[1],\n    color.up = \"firebrick\", \n    color.down = \"navy\",\n    color.ns = \"grey50\",\n    theme = reactable::reactableTheme(\n      stripedColor = \"grey95\",\n      highlightColor = \"grey80\",\n      cellPadding = \"8px 12px\",\n      style = list(\n        fontFamily = \"-apple-system, BlinkMacSystemFont, Segoe UI, Helvetica, \n        Arial, sans-serif\")\n    ),\n    defaultColDef = reactable::colDef(\n      header = function(value) value,\n      align = \"center\",\n      minWidth = 100,\n      headerStyle = list(background = \"#f7f7f8\"),\n      sortNALast = TRUE\n    ),\n    name_url = function(value) {value},\n    columns = list(\n      collection = reactable::colDef(\n        name = \"Collection\"),\n      name = reactable::colDef(\n        name = \"Gene set\",\n        cell = name_url,\n        minWidth = 150),\n      pval = reactable::colDef(\n        name = \"P-value\", aggregate = \"min\",\n        format = reactable::colFormat(digits = 4)),\n      padj = reactable::colDef(\n        name = \"FDR\", aggregate = \"min\",\n        format = reactable::colFormat(digits = 4)),\n      Direction =  reactable::colDef(\n        name = \"dir\", minWidth = 45, \n        cell = function(value) {\n          if (value == \"Up\")  \"\\u2B06\" else \"\\u2B07\"\n        }),\n      logFC = reactable::colDef(\n        name = \"logFC\", format = reactable::colFormat(digits = 2),\n        style = function(value) {\n          if (value > 0) {\n            color <- color.up\n          } else if (value < 0) {\n            color <- color.down\n          } else {\n            color <- color.ns\n          }\n          list(color = color, fontWeight = \"bold\")\n        }\n      ),\n      mean.logFC.trim = reactable::colDef(\n        name = \"logFC\", format = reactable::colFormat(digits = 2),\n        style = function(value) {\n          if (value > 0) {\n            color <- color.up\n          } else if (value < 0) {\n            color <- color.down\n          } else {\n            color <- color.ns\n          }\n          list(color = color, fontWeight = \"bold\")\n        }\n      )\n    ),\n    elementId = \"expansion-table\",\n    static = TRUE,\n    filterable = TRUE,\n    searchable = TRUE,\n    bordered = TRUE,\n    striped = FALSE,\n    highlight = TRUE,\n    defaultPageSize = 25L,\n    showPageSizeOptions = TRUE,\n    pageSizeOptions = sort(unique(c(25, 50, 100, nrow(data)))),\n    paginationType = \"simple\",\n    defaultSorted = list(pval = \"asc\")\n) {\n  data = sparrow::result(mg, method) %>%\n    dplyr::slice_min(n = max.results, order_by = pval) %>%\n    dplyr::filter(pval <= max.pval) %>%\n    dplyr::select(tidyselect::any_of(keep.cols))\n  if (nrow(data) == 0) {\n    warning(\"None of the gene sets pass the `max.pval` threshold.\")\n    return(NULL)\n  }\n  reactable::reactable(\n    data,\n    elementId = elementId,\n    defaultColDef = defaultColDef,\n    static = static,\n    filterable = filterable,\n    searchable = searchable,\n    bordered = bordered,\n    highlight = highlight,\n    theme = theme,\n    defaultPageSize = defaultPageSize,\n    showPageSizeOptions = showPageSizeOptions,\n    pageSizeOptions = pageSizeOptions,\n    paginationType = paginationType,\n    defaultSorted = defaultSorted,\n    columns = columns,\n    details = function(index) {\n      .row_details(data = data, mg = mg, index)\n    }\n  )\n}\n\n#' Wrapper to create a div HTML tag\n#' @param mg A `SparrowResult` object\n#' @param method Scalar character, which results to return from `mg`.\n#' @param max.pal Scalar numeric, return only results wiht an (uncorrected)\n#' <= `max.pal`.\n#' @param verbose Scalar flag, show messages?\n#' @param title Scalar character, the `h1` title for the element\n#' @param elementId Scalar character, the element identifier for the interactive\n#' table.\n#' @param style Scalar character, the style tag for the tag\n#' @param ... Additional arguments passed on to the `gene_set_table` function.\n#' @return A `shiny.tag` object containing the output of the \n#' `gene_set_table()` function.\n#' @importFrom htmltools div h1 tagList tags\n#' @export\ngene_set_report <- function(\n    mg,\n    method = resultNames(mg)[1], \n    max.pval = 0.05,\n    max.results = Inf,\n    verbose = TRUE,\n    title = \"Gene set enrichment analysis\",\n    elementId = \"expansion-table\",\n    style = \"\",\n    ...\n) {\n  if (!is.finite(max.results)) {\n    message.log <- sprintf(\n      paste(\"Reporting all '%s' results with (uncorrected)\",\n            \"p-value <= %s\"), \n      method, max.pval)\n  } else {\n    message.log <- sprintf(\n      paste(\"Reporting up to %s '%s' results with (uncorrected)\",\n            \"p-value <= %s\"), \n      max.results, method, max.pval)\n  }\n  if (isTRUE(verbose)) {\n    message(message.log)\n  }\n  htmltools::div(\n    style = style, \n    {\n      htmltools::tagList(\n        htmltools::h1(title),\n        htmltools::p(message.log),\n        # volcano plot\n        sparrow::result(mg, method) %>%\n          dplyr::slice_min(n = max.results, order_by = pval) %>%\n          volcano_gene_set_plot(width = \"50%\"),\n        htmltools::br(),\n        # expansion button\n        htmltools::tags$button(\n          \"Expand/collapse all rows\",\n          onclick = sprintf(\"Reactable.toggleAllRowsExpanded('%s')\", elementId)\n        ),\n        gene_set_table(mg = mg, max.pval = max.pval, max.results = max.results,\n                       ...)\n      )\n    })\n}\n\n\n# gene set enrichment analysis with the sparrow Bioconductor package\nvm <- exampleExpressionSet()\ngdb <- exampleGeneSetDb()\nmg <- seas(vm, gdb, c('fry'), design = vm$design, contrast = 'tumor')\n\n\n# create an interactive report\nhtmltools::browsable(\n  gene_set_report(mg, method = \"fry\", max.pval = 0.05, max.results = Inf)\n)\n\nReporting all 'fry' results with (uncorrected) p-value <= 0.05\n\n\n\n?(caption)\n\n\n\n\n\nGene set enrichment analysis\nReporting all 'fry' results with (uncorrected) p-value <= 0.05\n\n\n\nExpand/collapse all rows\nCollectionGene setnP-valueFDRlogFC​​c2LOPEZ_MESOTELIOMA_SURVIVAL_TIME_UP140.00070.02141.92​​c2BOYAULT_LIVER_CANCER_SUBCLASS_G123_DN410.00090.0214-0.65​​c2BIOCARTA_AGPCR_PATHWAY110.00130.0214-0.50​​c2GUTIERREZ_WALDENSTROEMS_MACROGLOBULINEMIA_1_UP90.00150.0214-0.60​​c6KRAS.LUNG.BREAST_UP.V1_DN960.00160.0214-0.34​​c2DARWICHE_PAPILLOMA_RISK_HIGH_VS_LOW_DN260.00170.0214-0.39​​c6KRAS.600.LUNG.BREAST_UP.V1_DN1890.00240.0259-0.26​​c2YAMASHITA_LIVER_CANCER_STEM_CELL_DN470.00310.0278-0.44​​c7GSE12845_IGD_POS_BLOOD_VS_PRE_GC_TONSIL_BCELL_UP1770.00350.0278-0.13​​c2SOTIRIOU_BREAST_CANCER_GRADE_1_VS_3_UP1490.00370.02781.83​​c6KRAS.BREAST_UP.V1_DN900.00450.0314-0.31​​c6KRAS.50_UP.V1_UP330.00540.0341-0.67​​c6GLI1_UP.V1_DN240.00600.03520.18​​c2SCHAEFFER_PROSTATE_DEVELOPMENT_48HR_DN3560.00730.0377-0.33​​c7GSE22886_IGG_IGA_MEMORY_BCELL_VS_BLOOD_PLASMA_CELL_UP1760.00760.0377-0.29​​c6CRX_NRL_DN.V1_DN990.00790.0377-0.21​​c6ATM_DN.V1_UP890.01130.0504-0.41​​c6CAMP_UP.V1_DN1830.01350.0569-0.23​​c6KRAS.DF.V1_DN1460.01630.0622-0.19​​c2REACTOME_MRNA_SPLICING_MINOR_PATHWAY420.01640.06220.34​​c2HUPER_BREAST_BASAL_VS_LUMINAL_UP520.01920.0679-0.76​​c6MEL18_DN.V1_DN1250.01960.0679-0.35​​c6KRAS.LUNG_UP.V1_DN980.02320.0741-0.43​​c6TBK1.DN.48HRS_DN500.02430.07410.17​​c2TURASHVILI_BREAST_LOBULAR_CARCINOMA_VS_DUCTAL_NORMAL_DN910.02450.0741-0.941–25 of 34 rowsShow 253450100Previous1 of 2Next\n\n\n\n\n\n\n\n\nReproducibility\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Los_Angeles\n date     2022-12-27\n pandoc   2.19.2 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package          * version     date (UTC) lib source\n annotate           1.76.0      2022-11-01 [1] Bioconductor\n AnnotationDbi      1.60.0      2022-11-01 [1] Bioconductor\n askpass            1.1         2019-01-13 [1] CRAN (R 4.2.0)\n assertthat         0.2.1       2019-03-21 [1] CRAN (R 4.2.0)\n babelgene          22.9        2022-09-29 [1] CRAN (R 4.2.0)\n backports          1.4.1       2021-12-13 [1] CRAN (R 4.2.0)\n Biobase          * 2.58.0      2022-11-01 [1] Bioconductor\n BiocGenerics     * 0.44.0      2022-11-01 [1] Bioconductor\n BiocIO             1.8.0       2022-11-01 [1] Bioconductor\n BiocParallel       1.32.4      2022-12-01 [1] Bioconductor\n BiocSet            1.12.0      2022-11-01 [1] Bioconductor\n Biostrings         2.66.0      2022-11-01 [1] Bioconductor\n bit                4.0.5       2022-11-15 [1] CRAN (R 4.2.0)\n bit64              4.0.5       2020-08-30 [1] CRAN (R 4.2.0)\n bitops             1.0-7       2021-04-24 [1] CRAN (R 4.2.0)\n blob               1.2.3       2022-04-10 [1] CRAN (R 4.2.0)\n cachem             1.0.6       2021-08-19 [1] CRAN (R 4.2.0)\n checkmate          2.1.0       2022-04-21 [1] CRAN (R 4.2.0)\n circlize           0.4.15      2022-05-10 [1] CRAN (R 4.2.0)\n cli                3.4.1       2022-09-23 [1] CRAN (R 4.2.0)\n clue               0.3-63      2022-11-19 [1] CRAN (R 4.2.0)\n cluster            2.1.4       2022-08-22 [2] CRAN (R 4.2.2)\n codetools          0.2-18      2020-11-04 [2] CRAN (R 4.2.2)\n colorspace         2.0-3       2022-02-21 [1] CRAN (R 4.2.0)\n ComplexHeatmap     2.14.0      2022-11-01 [1] Bioconductor\n crayon             1.5.2       2022-09-29 [1] CRAN (R 4.2.0)\n credentials        1.3.2       2021-11-29 [1] CRAN (R 4.2.0)\n crosstalk        * 1.2.0       2021-11-04 [1] CRAN (R 4.2.0)\n curl               4.3.3       2022-10-06 [1] CRAN (R 4.2.0)\n data.table         1.14.6      2022-11-16 [1] CRAN (R 4.2.0)\n DBI                1.1.3       2022-06-18 [1] CRAN (R 4.2.0)\n digest             0.6.31      2022-12-11 [1] CRAN (R 4.2.0)\n doParallel         1.0.17      2022-02-07 [1] CRAN (R 4.2.0)\n dplyr            * 1.0.10      2022-09-01 [1] CRAN (R 4.2.0)\n edgeR              3.40.1      2022-12-14 [1] Bioconductor\n ellipsis           0.3.2       2021-04-29 [1] CRAN (R 4.2.0)\n evaluate           0.19        2022-12-13 [1] CRAN (R 4.2.0)\n fansi              1.0.3       2022-03-24 [1] CRAN (R 4.2.0)\n fastmap            1.1.0       2021-01-25 [1] CRAN (R 4.2.0)\n foreach            1.5.2       2022-02-02 [1] CRAN (R 4.2.0)\n generics           0.1.3       2022-07-05 [1] CRAN (R 4.2.0)\n GenomeInfoDb       1.34.4      2022-12-01 [1] Bioconductor\n GenomeInfoDbData   1.2.9       2022-12-12 [1] Bioconductor\n GetoptLong         1.0.5       2020-12-15 [1] CRAN (R 4.2.0)\n ggplot2          * 3.4.0       2022-11-04 [1] CRAN (R 4.2.0)\n GlobalOptions      0.1.2       2020-06-10 [1] CRAN (R 4.2.0)\n glue               1.6.2       2022-02-24 [1] CRAN (R 4.2.0)\n graph              1.76.0      2022-11-01 [1] Bioconductor\n gridExtra          2.3         2017-09-09 [1] CRAN (R 4.2.0)\n GSEABase           1.60.0      2022-11-01 [1] Bioconductor\n gtable             0.3.1       2022-09-01 [1] CRAN (R 4.2.0)\n htmltools        * 0.5.4       2022-12-07 [1] CRAN (R 4.2.0)\n htmlwidgets      * 1.5.4       2021-09-08 [1] CRAN (R 4.2.2)\n httpuv             1.6.7       2022-12-14 [1] CRAN (R 4.2.0)\n httr               1.4.4       2022-08-17 [1] CRAN (R 4.2.0)\n IRanges            2.32.0      2022-11-01 [1] Bioconductor\n irlba              2.3.5.1     2022-10-03 [1] CRAN (R 4.2.0)\n iterators          1.0.14      2022-02-05 [1] CRAN (R 4.2.0)\n jsonlite           1.8.4       2022-12-06 [1] CRAN (R 4.2.0)\n KEGGREST           1.38.0      2022-11-01 [1] Bioconductor\n knitr              1.41        2022-11-18 [1] CRAN (R 4.2.0)\n later              1.3.0       2021-08-18 [1] CRAN (R 4.2.0)\n lattice            0.20-45     2021-09-22 [2] CRAN (R 4.2.2)\n lazyeval           0.2.2       2019-03-15 [1] CRAN (R 4.2.0)\n lifecycle          1.0.3       2022-10-07 [1] CRAN (R 4.2.0)\n limma              3.54.0      2022-11-01 [1] Bioconductor\n locfit             1.5-9.6     2022-07-11 [1] CRAN (R 4.2.0)\n magrittr           2.0.3       2022-03-30 [1] CRAN (R 4.2.0)\n Matrix             1.5-3       2022-11-11 [1] CRAN (R 4.2.0)\n matrixStats        0.63.0      2022-11-18 [1] CRAN (R 4.2.0)\n memoise            2.0.1       2021-11-26 [1] CRAN (R 4.2.0)\n mime               0.12        2021-09-28 [1] CRAN (R 4.2.0)\n munsell            0.5.0       2018-06-12 [1] CRAN (R 4.2.0)\n ontologyIndex      2.10        2022-08-24 [1] CRAN (R 4.2.0)\n openssl            2.0.5       2022-12-06 [1] CRAN (R 4.2.0)\n pillar             1.8.1       2022-08-19 [1] CRAN (R 4.2.0)\n pkgconfig          2.0.3       2019-09-22 [1] CRAN (R 4.2.0)\n plotly           * 4.10.1.9000 2022-12-20 [1] Github (plotly/plotly.R@3a33b1a)\n plyr               1.8.8       2022-11-11 [1] CRAN (R 4.2.0)\n png                0.1-8       2022-11-29 [1] CRAN (R 4.2.0)\n promises           1.2.0.1     2021-02-11 [1] CRAN (R 4.2.0)\n purrr              0.3.5       2022-10-06 [1] CRAN (R 4.2.0)\n R6                 2.5.1       2021-08-19 [1] CRAN (R 4.2.0)\n RColorBrewer       1.1-3       2022-04-03 [1] CRAN (R 4.2.0)\n Rcpp               1.0.9       2022-07-08 [1] CRAN (R 4.2.0)\n RCurl              1.98-1.9    2022-10-03 [1] CRAN (R 4.2.0)\n reactable        * 0.4.1.9000  2022-12-20 [1] Github (glin/reactable@cf500a1)\n reactR             0.4.4       2021-02-22 [1] CRAN (R 4.2.0)\n rjson              0.2.21      2022-01-09 [1] CRAN (R 4.2.0)\n rlang              1.0.6       2022-09-24 [1] CRAN (R 4.2.0)\n rmarkdown          2.19        2022-12-15 [1] CRAN (R 4.2.0)\n RSQLite            2.2.19      2022-11-24 [1] CRAN (R 4.2.0)\n rstudioapi         0.14        2022-08-22 [1] CRAN (R 4.2.0)\n S4Vectors          0.36.1      2022-12-05 [1] Bioconductor\n scales             1.2.1       2022-08-20 [1] CRAN (R 4.2.0)\n sessioninfo        1.2.2       2021-12-06 [1] CRAN (R 4.2.0)\n shape              1.4.6       2021-05-19 [1] CRAN (R 4.2.0)\n shiny              1.7.4       2022-12-15 [1] CRAN (R 4.2.0)\n sparrow          * 1.4.0       2022-11-01 [1] Bioconductor\n statmod            1.4.37      2022-08-12 [1] CRAN (R 4.2.0)\n stringi            1.7.8       2022-07-11 [1] CRAN (R 4.2.0)\n stringr          * 1.5.0       2022-12-02 [1] CRAN (R 4.2.0)\n sys                3.4.1       2022-10-18 [1] CRAN (R 4.2.0)\n tibble             3.1.8       2022-07-22 [1] CRAN (R 4.2.0)\n tidyr              1.2.1       2022-09-08 [1] CRAN (R 4.2.0)\n tidyselect         1.2.0       2022-10-10 [1] CRAN (R 4.2.0)\n utf8               1.2.2       2021-07-24 [1] CRAN (R 4.2.0)\n V8               * 4.2.2       2022-11-03 [1] CRAN (R 4.2.0)\n vctrs              0.5.1       2022-11-16 [1] CRAN (R 4.2.0)\n viridis            0.6.2       2021-10-13 [1] CRAN (R 4.2.0)\n viridisLite        0.4.1       2022-08-22 [1] CRAN (R 4.2.0)\n withr              2.5.0       2022-03-03 [1] CRAN (R 4.2.0)\n xfun               0.35        2022-11-16 [1] CRAN (R 4.2.0)\n XML                3.99-0.13   2022-12-04 [1] CRAN (R 4.2.0)\n xtable             1.8-4       2019-04-21 [1] CRAN (R 4.2.0)\n XVector            0.38.0      2022-11-01 [1] Bioconductor\n yaml               2.3.6       2022-10-18 [1] CRAN (R 4.2.0)\n zlibbioc           1.44.0      2022-11-01 [1] Bioconductor\n\n [1] /Users/sandmann/Library/R/x86_64/4.2/library\n [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/geneset-sqlite-db/index.html",
    "href": "posts/geneset-sqlite-db/index.html",
    "title": "SQL and noSQL approaches to creating & querying databases (using R)",
    "section": "",
    "text": "The first step of any data analysis is to obtain and explore the available data, often by accessing and querying a database. There many great introductions on how to read data into an R session. But I found it harder to find tutorials on how to create and populate a new database from scratch.\nIn this document, I explore both noSQL and SQL approaches to data management. As an example use case, we store a collection of gene sets, specifically the mouse MSigDb hallmark gene sets (MH), either as unstructured documents or in relational tables.\n\n\nBioconductor offers well designed S4 Classes to store gene set collections, including e.g. in a list-like GSEABase::GeneSetCollection or a set of three tibbles within a BiocSet::BiocSet object. So why could we be interested in storing this information in a database?\n\nA database (e.g. SQLite, Postgres, etc) offers a standardized way to store, manage and access information in a language-agnostic way. E.g. some of my colleagues use python for their analyses and are comfortable retrieving gene set information from a database, but not necessarily from an R S4 object.\nGene sets capture knowledge from multiple experiments, studies and sources. If you are part of a larger organization a single source of truth, available in a central location, is very useful.\nCollaborators might not be interested / able to access information programmatically, e.g. they may prefer a web application to search, share and edit gene sets. Many tools to build web applications have built-in capabilities to interact with a database.\nAs the number of gene sets grows, sharing them in the form of one or more files might become cumbersome. A hosted database (e.g.  Postgres or MariaDB ) allows users to retrieve only the information they need.\n\nIn this tutorial, I am using the SQLite engine to explore both relational and non-relational ways to manage gene sets. SQLite can be embedded into applications, and does not require a central server, making it ideal for experimentation. (But as you move into a scenario where multiple users need to access a central, it is time to switch to a hosted database instead; my favorite is Postgres.)\n\nlibrary(BiocSet)\nlibrary(dm)\nlibrary(dplyr)\nlibrary(jsonlite)\nlibrary(nodbi)\nlibrary(org.Mm.eg.db)\nlibrary(purrr)\nlibrary(RSQLite)\nlibrary(tibble)\nlibrary(tidyr)\nThis work is licensed under a Creative Commons Attribution 4.0 International License."
  },
  {
    "objectID": "posts/geneset-sqlite-db/index.html#filtering-json-columns",
    "href": "posts/geneset-sqlite-db/index.html#filtering-json-columns",
    "title": "Experimenting with SQLite: storing gene set collections",
    "section": "Filtering JSON columns",
    "text": "Filtering JSON columns\n\n\n\n\n\n\nNote\n\n\n\nAll of the methods shown below (e.g. using json_each and json_tree) scan through the full table, e.g. they don’t usee an index to make the search more efficient.\n\n\nIf we have information about the structure of the JSON object, then we can unpack its elements and to focus on specific fields. (See this tutorial for some nice examples.)\nFor example, we might want to return all users like skating, e.g. whose likes JSON field contains this value, e.g. regardless of the position of the value within the array.\n\njson_each\nThe json_each table-valued function walks along the specified JSON field and returns a new table with row for each value. The returned table includes e.g. key and value columns we can use to filter.\n\nSELECT DISTINCT user.id, name, interests->'likes' as likes\nFROM user, json_each(interests, '$.likes')\nWHERE json_each.value LIKE '%swimming%'\n\n\n3 records\n\n\nid\nname\nlikes\n\n\n\n\n1\nJohn\n[“skating”,“reading”,“swimming”]\n\n\n2\nKate\n[“reading”,“swimming”]\n\n\n3\nJim\n[“reading”,“swimming”]\n\n\n\n\n\n\n\njson_tree\nThe json_tree function steps through the full JSON object, e.g. it also descends into the two sub-arrays likes and dislikes.\n\nSELECT name, key, value\nFROM user, json_tree(interests) \n\n\nDisplaying records 1 - 10\n\n\n\n\n\n\n\nname\nkey\nvalue\n\n\n\n\nJohn\nNA\n{“likes”:[“skating”,“reading”,“swimming”],“dislikes”:[“cooking”]}\n\n\nJohn\nlikes\n[“skating”,“reading”,“swimming”]\n\n\nJohn\n0\nskating\n\n\nJohn\n1\nreading\n\n\nJohn\n2\nswimming\n\n\nJohn\ndislikes\n[“cooking”]\n\n\nJohn\n0\ncooking\n\n\nKate\nNA\n{“likes”:[“reading”,“swimming”],“dislikes”:[“skating”]}\n\n\nKate\nlikes\n[“reading”,“swimming”]\n\n\nKate\n0\nreading\n\n\n\n\n\nWe can define the root for the tree by providing a second argument, e.g. to focus only on the likes sub-array:\n\nSELECT name, key, value\nFROM user, json_tree(interests, '$.likes')\n\n\nDisplaying records 1 - 10\n\n\nname\nkey\nvalue\n\n\n\n\nJohn\nlikes\n[“skating”,“reading”,“swimming”]\n\n\nJohn\n0\nskating\n\n\nJohn\n1\nreading\n\n\nJohn\n2\nswimming\n\n\nKate\nlikes\n[“reading”,“swimming”]\n\n\nKate\n0\nreading\n\n\nKate\n1\nswimming\n\n\nJim\nlikes\n[“reading”,“swimming”]\n\n\nJim\n0\nreading\n\n\nJim\n1\nswimming\n\n\n\n\n\nTo focus only on the node leafs of the tree, we can retain only atomic fields:\n\nSELECT name, key, value\nFROM user, json_tree(interests, '$.likes')\nWHERE json_tree.atom IS NOT NULL\n\n\n7 records\n\n\nname\nkey\nvalue\n\n\n\n\nJohn\n0\nskating\n\n\nJohn\n1\nreading\n\n\nJohn\n2\nswimming\n\n\nKate\n0\nreading\n\n\nKate\n1\nswimming\n\n\nJim\n0\nreading\n\n\nJim\n1\nswimming\n\n\n\n\n\nNow that we have row for each value of the likes sub-array, we can filter the table:\n\nSELECT name, key, value\nFROM user, json_tree(interests, '$.likes')\nWHERE json_tree.atom IS NOT NULL AND json_tree.value LIKE '%skating%'\n\n\n1 records\n\n\nname\nkey\nvalue\n\n\n\n\nJohn\n0\nskating\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBoth the json_each and json_tree function scan the entire interests column of the table, e.g. they don’t use an index. I have not been able to find documentation on how to add an (expression) index to speed up the search, so for large datasets the queries shown above might be slow."
  },
  {
    "objectID": "posts/geneset-sqlite-db/index.html#casting-json-to-text",
    "href": "posts/geneset-sqlite-db/index.html#casting-json-to-text",
    "title": "Experimenting with SQLite: storing gene set collections",
    "section": "Casting JSON to text",
    "text": "Casting JSON to text\nAnother way to filter JSON columns is to simply cast them into text, e.g. a JSON string, and perform a text comparison. (Note that we are including the double quotes in the search term to avoid unexpected partial matches.)\n\nSELECT id, name, CAST(interests->'likes' AS TEXT)\nFROM user\nWHERE CAST(interests->'likes' AS TEXT) LIKE '%\"skating\"%'\n\n\n1 records\n\n\nid\nname\nCAST(interests->‘likes’ AS TEXT)\n\n\n\n\n1\nJohn\n[“skating”,“reading”,“swimming”]\n\n\n\n\n\nAlternatively, we can also extract the TEXT representation of the likes sub-array with the json_extract function:\n\nSELECT id, name, json_extract(interests, '$.likes') as likes\nFROM user\nWHERE json_extract(interests, '$.likes') LIKE '%\"skating\"%'\n\n\n1 records\n\n\nid\nname\nlikes\n\n\n\n\n1\nJohn\n[“skating”,“reading”,“swimming”]\n\n\n\n\n\n\nIndexing\n\n\n\n\n\n\nWarning\n\n\n\nUsing an index for fuzzy matching with the LIKE operator is only supported for patterns of the format XXX%, e.g. a leading constant value before any wildcards (as outlined here). It is also necessary to make sure the search is case insensitive by defining the casted TEXT explicitely as such with the COLLATE NOCASE clause.\n\n\nWithout an index, the table is scanned entirely:\n\nEXPLAIN QUERY PLAN \nSELECT name, CAST(interests->'dislikes' AS TEXT) COLLATE NOCASE as dislikes\nFROM user\nWHERE dislikes = '[\"cooking\"]'\n\n\n1 records\n\n\nid\nparent\nnotused\ndetail\n\n\n\n\n2\n0\n0\nSCAN user\n\n\n\n\n\nTo speed up future queries, we can add an index based on the same expression we are planning to use in the query:\n\nCREATE INDEX dislikes_idx\nON user(CAST(interests->'dislikes' AS TEXT) COLLATE NOCASE);\n\nWhen the equality (=) filter is returned using the likes_idx index, speeding up the search.\n\nEXPLAIN QUERY PLAN \nSELECT name, CAST(interests->'dislikes' AS TEXT) COLLATE NOCASE as dislikes\nFROM user\nWHERE dislikes = '[\"cooking\"]'\n\n\n1 records\n\n\nid\nparent\nnotused\ndetail\n\n\n\n\n3\n0\n0\nSEARCH user USING INDEX dislikes_idx (=?)\n\n\n\n\n\nSimilarly, when we use a pattern with a wildcard at the end, the index is used as well:\n\nEXPLAIN QUERY PLAN \nSELECT name, CAST(interests->'dislikes' AS TEXT) COLLATE NOCASE as dislikes\nFROM user\nWHERE dislikes LIKE 'cooking\"%'\n\n\n1 records\n\n\n\n\n\n\n\n\nid\nparent\nnotused\ndetail\n\n\n\n\n3\n0\n0\nSEARCH user USING INDEX dislikes_idx (>? AND <?)\n\n\n\n\n\nBut a wildcard at the start of the term triggers a full scan of the table.\n\nEXPLAIN QUERY PLAN \nSELECT name, CAST(interests->'dislikes' AS TEXT) COLLATE NOCASE as dislikes\nFROM user\nWHERE dislikes LIKE '%cooking'\n\n\n1 records\n\n\nid\nparent\nnotused\ndetail\n\n\n\n\n2\n0\n0\nSCAN user\n\n\n\n\n\nThat’s a severe limitation because it precludes matching patterns that are not at the start of the TEXT string.\nThere might be other ways to implement a full text search in SQLite, but I haven’t discovered these features, yet."
  },
  {
    "objectID": "posts/geneset-sqlite-db/index.html#cleanup",
    "href": "posts/geneset-sqlite-db/index.html#cleanup",
    "title": "Experimenting with SQLite: storing gene set collections",
    "section": "Cleanup",
    "text": "Cleanup\nAs always, we disconnect from the database when we are done.\n\ndbDisconnect(con)"
  },
  {
    "objectID": "posts/geneset-sqlite-db/index.html#gene-set-collection-sqlite",
    "href": "posts/geneset-sqlite-db/index.html#gene-set-collection-sqlite",
    "title": "Experimenting with SQLite: storing gene set collections",
    "section": "Gene set collection & SQLite",
    "text": "Gene set collection & SQLite\nIn this document, I explore different approaches to store a gene set collection (e.g. the MSigDb hallmark gene sets (MH) ) in a relational database.\nBioconductor offers well designed S4 Classes to store gene set collections, including e.g. in a list-like GSEABase::GeneSetCollection or a set of three tibbles within a BiocSet::BiocSet object. So why could we be interested in storing this information in a database?\n\nA database (e.g. SQLite, Postgres, etc) offers a highly standardized way to store and manage information in a language-agnostic way. E.g. some of my colleagues use python for their analyses and are comfortable retrieving gene set information from a database, but not necessarily from an R S4 object.\nGene sets capture knowledge from multiple experiments, studies and sources. If you are part of a larger organization a single source of truth, available in a central location, is very useful.\nCollaborators might not be interested / able to access information programmatically, e.g. they may prefer a web application to search, share and edit gene sets. Many tools to build web applications have built-in capabilities to interact with a database.\nAs the number of gene sets grows, sharing them in the form of one or more files might become cumbersome. A hosted database (e.g.  Postgres or MariaDB ) allows users to retrieve only the information they need.\n\nHere, I am using the SQLite engine to explore both relational and non-relational ways to manage gene sets. SQLite can be embedded into applications, and does not require a central server, making it ideal for experimentation. (But as you move into a scenario where multiple users need to access a central, it is time to switch to a hosted database instead; my favorite is Postgres.)"
  },
  {
    "objectID": "posts/geneset-sqlite-db/index.html#the-mouse-hallmarks-msigdb-collection",
    "href": "posts/geneset-sqlite-db/index.html#the-mouse-hallmarks-msigdb-collection",
    "title": "SQL and noSQL approaches to creating & querying databases (using R)",
    "section": "The Mouse Hallmarks MSigDB collection",
    "text": "The Mouse Hallmarks MSigDB collection\nAt the time of writing, Mouse Molecular Signatures Database (MSigDB) contains 15918 gene sets, organized into numerous different collections. For example, the 50 hallmark gene sets (MH) summarize and represent specific well-defined biological states or processes ( Liberzon et al, Cell Systems, 2015 ).\n\n\n\n\n\n\nGene symbols\n\n\n\nEach of the 50 sets in the collection contains between 32 and 200 official gene symbols, specifying the members of the gene set.\n\n\nHere, I will use the hallmarks collection as an example but the overall approach can be applied to other gene set collection in a similar way. (You might need additional / different annotation fields, though.)\nThe mouse hallmarks collection is available in different formats, including as a JSON file. Let’s start by reading it into an R session as nested list mh.\n\njson_file <- paste0(\n  \"https://raw.githubusercontent.com/tomsing1/blog/sqlite/posts/\",\n  \"geneset-sqlite-db/mh.all.v2022.1.Mm.json\")\nmh <- jsonlite::read_json(json_file, simplifyVector = TRUE)\n\nEach of the 50 elements in the JSON file corresponds to a different gene set,\n\nhead(names(mh))\n\n[1] \"HALLMARK_ADIPOGENESIS\"        \"HALLMARK_ALLOGRAFT_REJECTION\"\n[3] \"HALLMARK_ANDROGEN_RESPONSE\"   \"HALLMARK_ANGIOGENESIS\"       \n[5] \"HALLMARK_APICAL_JUNCTION\"     \"HALLMARK_APICAL_SURFACE\"     \n\n\neach gene set is a nested list with the following elements,\n\nlengths(mh[[1]])\n\n              systematicName                         pmid \n                           1                            1 \n                 exactSource                  geneSymbols \n                           1                          200 \n                   msigdbURL           externalDetailsURL \n                           1                            1 \n        filteredBySimilarity externalNamesForSimilarTerms \n                           0                            0 \n                  collection \n                           1 \n\n\nand the gene symbols that make up the set are listed in the geneSymbols vector:\n\nhead(mh[[1]]$geneSymbols)\n\n[1] \"Abca1\" \"Abcb8\" \"Acaa2\" \"Acadl\" \"Acadm\" \"Acads\""
  },
  {
    "objectID": "posts/geneset-sqlite-db/index.html#nosql-storing-gene-sets-as-unstructured-documents",
    "href": "posts/geneset-sqlite-db/index.html#nosql-storing-gene-sets-as-unstructured-documents",
    "title": "SQL and noSQL approaches to creating & querying databases (using R)",
    "section": "noSQL: storing gene sets as unstructured documents",
    "text": "noSQL: storing gene sets as unstructured documents\nEach gene set is represented as a list - so why not store it in the same way? A noSQL database is designed to store unstructed information, e.g. data models that are not organized in tables, making them flexible and scalable. Examples of noSQL databases include e.g. Mongodb, CouchDB or AWS dynamodb.\nIn addition, traditional relational database engines - including SQLite and Postgres - can also store unstructured data in dedicated JSON fields.\nThe nodbi R package provides a unified interface to multiple noSQL implementations, including SQLite. (If you are interested in a deeper look at how to create & query a JSON field in SQLite with raw SQL, check out this gist ).\n\nCreating & populating a noSQL database with the nodbi R package\nTo experiment with its noSQL mode, we create a temporary SQLite database in memory. (For real data, you definitely want to provide a file path as the dbname instead!)\n\nsrc <- nodbi::src_sqlite(dbname = \":memory:\")\n\nRight now, the names of the gene sets are only stored as the names() of the list elements, e.g. not in a field within each sub-list itself. To make sure they are included in each database record, we add them to each sub-list in a new name field.\n\nmh2 <- lapply(names(mh), \\(gs) c(\"name\" = gs, mh[[gs]]))\n\n\n\n\n\n\n\nUnique identifiers\n\n\n\nThe docdb_create() function accepts either a data.frame, a JSON string or a list as its value argument.\nIf you include a field _id in your list, it will be used as the primary key for each element. If no _id field is found, then the _id field is created automatically with a call to the uuid::UUIDgenerate() function.\nIf you provide a data.frames() with row.names, they will be used to populate the _id field.\n\n\nNow we are ready to create a new SQLite table hallmarks and populate it with the 50 gene sets.\n\ndocdb_create(src, key = \"hallmarks\", value = mh2)\n\n[1] 50\n\n\nWe can retrieve the full set of records as a data.frame with the docdb_get() function. (Here we select a subset of the returned columns due to space constraints.) Because each gene set contains multiple geneSymbols, this field is a list-column.\n\ndocdb_get(src, \"hallmarks\")[1:4, c(\"name\", \"geneSymbols\", \"pmid\")]\n\n                          name  geneSymbols     pmid\n1        HALLMARK_ADIPOGENESIS Abca1, A.... 30224793\n2 HALLMARK_ALLOGRAFT_REJECTION Aars, Ab.... 30224793\n3   HALLMARK_ANDROGEN_RESPONSE Abcc4, A.... 30224793\n4        HALLMARK_ANGIOGENESIS Apoh, Ap.... 30224793\n\n\n\n\nQuerying with JSON filters\nMore commonly, users might want to retrieve one or more gene sets by name. The docdb_query() function accepts a query argument specifying the desired filter criteria (as MongoDB JSON ).\n\nresults <- nodbi::docdb_query(\n  src = src, key = \"hallmarks\",\n  query = '{\"name\": \"HALLMARK_ADIPOGENESIS\"}')\nresults[, c(\"name\", \"geneSymbols\", \"pmid\")]\n\n                   name  geneSymbols     pmid\n1 HALLMARK_ADIPOGENESIS Abca1, A.... 30224793\n\n\nThe fields argument allows us to return only specific columns. (Specifying a field as 1 or 0 will include or exclude it, respectively.)\n\nnodbi::docdb_query(\n  src = src, key = \"hallmarks\",\n  query = '{\"name\": \"HALLMARK_ADIPOGENESIS\"}',\n  fields = '{\"name\": 1, \"geneSymbols\": 1}'\n)\n\n                   name  geneSymbols\n1 HALLMARK_ADIPOGENESIS Abca1, A....\n\n\nWe can also identify gene sets containing at least one of the given gene symbols:\n\nresults <- nodbi::docdb_query(\n  src = src, key = \"hallmarks\",\n  query = paste0('{\"$or\":[',\n                 '{\"geneSymbols\": \"Abca1\"},', \n                 '{\"geneSymbols\": \"Gapdh\"}',\n                 ']}'),\n  fields = '{\"name\": 1, \"geneSymbols\": 1}'\n)\n\n\n\n\n\n\n\nUnnesting columns\n\n\n\n\n\nBecause the set contains more than one geneSymbol, we obtain a nested data.frame. We can unnest it e.g. with the tidyr R package\n\ntidyr::unnest(results, cols = c(geneSymbols))\n\n# A tibble: 798 × 2\n   name                  geneSymbols\n   <chr>                 <chr>      \n 1 HALLMARK_ADIPOGENESIS Abca1      \n 2 HALLMARK_ADIPOGENESIS Abcb8      \n 3 HALLMARK_ADIPOGENESIS Acaa2      \n 4 HALLMARK_ADIPOGENESIS Acadl      \n 5 HALLMARK_ADIPOGENESIS Acadm      \n 6 HALLMARK_ADIPOGENESIS Acads      \n 7 HALLMARK_ADIPOGENESIS Acly       \n 8 HALLMARK_ADIPOGENESIS Aco2       \n 9 HALLMARK_ADIPOGENESIS Acox1      \n10 HALLMARK_ADIPOGENESIS Adcy6      \n# … with 788 more rows\n\n\n\n\n\n\n\nQuerying using SQL\nFormulating the queries as JSON strings is tedious, though. Alternatively, SQLite also supports querying JSON columns using SQL (muddying the border between noSQL and SQL). For example, we can use SQLite’s -> and ->> operators and the json_each() SQL function to create a query that returns the names of all gene sets that include e.g. the Abca1 gene:\n\nSELECT hallmarks.json->>'name' as name\nFROM hallmarks, json_each(hallmarks.json, '$.geneSymbols')\nWHERE json_each.value LIKE '%Abca1%'\n\n\n5 records\n\n\nname\n\n\n\n\nHALLMARK_ADIPOGENESIS\n\n\nHALLMARK_BILE_ACID_METABOLISM\n\n\nHALLMARK_INFLAMMATORY_RESPONSE\n\n\nHALLMARK_PROTEIN_SECRETION\n\n\nHALLMARK_TNFA_SIGNALING_VIA_NFKB\n\n\n\n\n\nDepending on comfortable you are reading / writing SQL, this might be a nicer approach.\n\n\n\n\n\n\nLimitations\n\n\n\nSQLite’s JSON operators are somewhat limited, e.g. there is no straightforward way to ask whether a column contains one or more gene identifiers (e.g. the query we performed above using a query JSON string). Indexing a SQLite JSON column also comes with limitations.\nThe Postgres database engine supports JSON and binary JSONB fields) with indexing & additional operators like the @> contains operator.\n\n\n\n\nnoSQL summary\nThis example highlights some of the advantages of a noSQL solution:\n\nRapid ingestion of data without the need for a rigid schema.\nSimple retrieval of individual object identified by their primary key.\n\nBut also some of the disadvantages:\n\nQueries that descend into the (potentially nested) objects must be carefully constructed.\nIncreasing database performance with indices is more complicated than for relational databases (see below.)\n\nNext, we will try another approach: reshaping the gene set collection into a set of tables and modeling the relationship between them.s"
  },
  {
    "objectID": "posts/geneset-sqlite-db/index.html#sql-storing-gene-sets-in-a-relational-database-schema",
    "href": "posts/geneset-sqlite-db/index.html#sql-storing-gene-sets-in-a-relational-database-schema",
    "title": "Experimenting with SQLite: storing gene set collections",
    "section": "SQL: storing gene sets in a relational database schema",
    "text": "SQL: storing gene sets in a relational database schema\nTo take advantage of a relational database, we have perform a little more work up-front. But this effort is repaid by simplifying subsequent queries.\n\nLearning from Bioconductor: BiocSet’s three tables\nThe BiocSet Class from the eponymous Bioconductor package represents a collection of gene sets in three tibbles. Let’s create a simple BiocSet with just a single gene set for illustration:\n\nset_name <- mh2[[1]]$name\ngene_ids <- unlist(mh2[[1]]$geneSymbols, use.names = FALSE)\nes <- BiocSet(setNames(list(gene_ids), set_name))\n\nThe first two tibbles represent genes (called elements) and sets, respectively:\n\nes_element: one row per gene\n\n\nes_element(es)\n\n# A tibble: 200 × 1\n   element\n   <chr>  \n 1 Abca1  \n 2 Abcb8  \n 3 Acaa2  \n 4 Acadl  \n 5 Acadm  \n 6 Acads  \n 7 Acly   \n 8 Aco2   \n 9 Acox1  \n10 Adcy6  \n# … with 190 more rows\n\n\n\nes_set: one row per gene set\n\n\nes_set(es)\n\n# A tibble: 1 × 1\n  set                  \n  <chr>                \n1 HALLMARK_ADIPOGENESIS\n\n\nThe third table establishes the many-to-many relationship between genes and sets.\n\nes_elementset: gene x set combination\n\n\nes_elementset(es)\n\n# A tibble: 200 × 2\n   element set                  \n   <chr>   <chr>                \n 1 Abca1   HALLMARK_ADIPOGENESIS\n 2 Abcb8   HALLMARK_ADIPOGENESIS\n 3 Acaa2   HALLMARK_ADIPOGENESIS\n 4 Acadl   HALLMARK_ADIPOGENESIS\n 5 Acadm   HALLMARK_ADIPOGENESIS\n 6 Acads   HALLMARK_ADIPOGENESIS\n 7 Acly    HALLMARK_ADIPOGENESIS\n 8 Aco2    HALLMARK_ADIPOGENESIS\n 9 Acox1   HALLMARK_ADIPOGENESIS\n10 Adcy6   HALLMARK_ADIPOGENESIS\n# … with 190 more rows\n\n\nEach of these tables can be augmented with additional metadata, e.g. we could add Entrez gene identifiers to the es_element, or a long-form description to es_set tibble.\nThese three tables can easily be represented in a relational database, using the element and set columns as primary keys.\n\n\nCreating a new SQLite database\nLet’s start with a fresh SQLite database.\n\ncon <- dbConnect(RSQLite::SQLite(), \":memory:\")\n\n\n\nSessionInfo\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Los_Angeles\n date     2022-12-31\n pandoc   2.19.2 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package          * version  date (UTC) lib source\n AnnotationDbi      1.60.0   2022-11-01 [1] Bioconductor\n askpass            1.1      2019-01-13 [1] CRAN (R 4.2.0)\n assertthat         0.2.1    2019-03-21 [1] CRAN (R 4.2.0)\n Biobase            2.58.0   2022-11-01 [1] Bioconductor\n BiocGenerics       0.44.0   2022-11-01 [1] Bioconductor\n BiocIO             1.8.0    2022-11-01 [1] Bioconductor\n BiocSet          * 1.12.0   2022-11-01 [1] Bioconductor\n Biostrings         2.66.0   2022-11-01 [1] Bioconductor\n bit                4.0.5    2022-11-15 [1] CRAN (R 4.2.0)\n bit64              4.0.5    2020-08-30 [1] CRAN (R 4.2.0)\n bitops             1.0-7    2021-04-24 [1] CRAN (R 4.2.0)\n blob               1.2.3    2022-04-10 [1] CRAN (R 4.2.0)\n cachem             1.0.6    2021-08-19 [1] CRAN (R 4.2.0)\n cli                3.5.0    2022-12-20 [1] CRAN (R 4.2.0)\n crayon             1.5.2    2022-09-29 [1] CRAN (R 4.2.0)\n credentials        1.3.2    2021-11-29 [1] CRAN (R 4.2.0)\n DBI                1.1.3    2022-06-18 [1] CRAN (R 4.2.0)\n digest             0.6.31   2022-12-11 [1] CRAN (R 4.2.0)\n dplyr            * 1.0.10   2022-09-01 [1] CRAN (R 4.2.0)\n ellipsis           0.3.2    2021-04-29 [1] CRAN (R 4.2.0)\n evaluate           0.19     2022-12-13 [1] CRAN (R 4.2.0)\n fansi              1.0.3    2022-03-24 [1] CRAN (R 4.2.0)\n fastmap            1.1.0    2021-01-25 [1] CRAN (R 4.2.0)\n generics           0.1.3    2022-07-05 [1] CRAN (R 4.2.0)\n GenomeInfoDb       1.34.4   2022-12-01 [1] Bioconductor\n GenomeInfoDbData   1.2.9    2022-12-12 [1] Bioconductor\n glue             * 1.6.2    2022-02-24 [1] CRAN (R 4.2.0)\n here             * 1.0.1    2020-12-13 [1] CRAN (R 4.2.0)\n highr              0.9      2021-04-16 [1] CRAN (R 4.2.0)\n htmltools          0.5.4    2022-12-07 [1] CRAN (R 4.2.0)\n htmlwidgets        1.5.4    2021-09-08 [1] CRAN (R 4.2.2)\n httr               1.4.4    2022-08-17 [1] CRAN (R 4.2.0)\n IRanges            2.32.0   2022-11-01 [1] Bioconductor\n jsonify            1.2.2    2022-11-09 [1] CRAN (R 4.2.0)\n jsonlite         * 1.8.4    2022-12-06 [1] CRAN (R 4.2.0)\n KEGGREST           1.38.0   2022-11-01 [1] Bioconductor\n knitr              1.41     2022-11-18 [1] CRAN (R 4.2.0)\n lifecycle          1.0.3    2022-10-07 [1] CRAN (R 4.2.0)\n magrittr           2.0.3    2022-03-30 [1] CRAN (R 4.2.0)\n memoise            2.0.1    2021-11-26 [1] CRAN (R 4.2.0)\n nodbi            * 0.9.1    2022-11-20 [1] CRAN (R 4.2.0)\n ontologyIndex      2.10     2022-08-24 [1] CRAN (R 4.2.0)\n openssl            2.0.5    2022-12-06 [1] CRAN (R 4.2.0)\n pillar             1.8.1    2022-08-19 [1] CRAN (R 4.2.0)\n pkgconfig          2.0.3    2019-09-22 [1] CRAN (R 4.2.0)\n plyr               1.8.8    2022-11-11 [1] CRAN (R 4.2.0)\n png                0.1-8    2022-11-29 [1] CRAN (R 4.2.0)\n purrr              0.3.5    2022-10-06 [1] CRAN (R 4.2.0)\n R6                 2.5.1    2021-08-19 [1] CRAN (R 4.2.0)\n Rcpp               1.0.9    2022-07-08 [1] CRAN (R 4.2.0)\n RCurl              1.98-1.9 2022-10-03 [1] CRAN (R 4.2.0)\n rlang              1.0.6    2022-09-24 [1] CRAN (R 4.2.0)\n rmarkdown          2.19     2022-12-15 [1] CRAN (R 4.2.0)\n rprojroot          2.0.3    2022-04-02 [1] CRAN (R 4.2.0)\n RSQLite          * 2.2.19   2022-11-24 [1] CRAN (R 4.2.0)\n rstudioapi         0.14     2022-08-22 [1] CRAN (R 4.2.0)\n S4Vectors          0.36.1   2022-12-05 [1] Bioconductor\n sessioninfo        1.2.2    2021-12-06 [1] CRAN (R 4.2.0)\n stringi            1.7.8    2022-07-11 [1] CRAN (R 4.2.0)\n stringr            1.5.0    2022-12-02 [1] CRAN (R 4.2.0)\n sys                3.4.1    2022-10-18 [1] CRAN (R 4.2.0)\n tibble           * 3.1.8    2022-07-22 [1] CRAN (R 4.2.0)\n tidyr            * 1.2.1    2022-09-08 [1] CRAN (R 4.2.0)\n tidyselect         1.2.0    2022-10-10 [1] CRAN (R 4.2.0)\n utf8               1.2.2    2021-07-24 [1] CRAN (R 4.2.0)\n uuid               1.1-0    2022-04-19 [1] CRAN (R 4.2.0)\n vctrs              0.5.1    2022-11-16 [1] CRAN (R 4.2.0)\n withr              2.5.0    2022-03-03 [1] CRAN (R 4.2.0)\n xfun               0.35     2022-11-16 [1] CRAN (R 4.2.0)\n XVector            0.38.0   2022-11-01 [1] Bioconductor\n yaml               2.3.6    2022-10-18 [1] CRAN (R 4.2.0)\n zlibbioc           1.44.0   2022-11-01 [1] Bioconductor\n\n [1] /Users/sandmann/Library/R/x86_64/4.2/library\n [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "posts/geneset-sqlite-db/index.html#sql-storing-gene-sets-in-a-relational-database",
    "href": "posts/geneset-sqlite-db/index.html#sql-storing-gene-sets-in-a-relational-database",
    "title": "SQL and noSQL approaches to creating & querying databases (using R)",
    "section": "SQL: storing gene sets in a relational database",
    "text": "SQL: storing gene sets in a relational database\nR has excellent support for interacting with relational database, e.g. via the foundational ‘Common Database Interface’ (DBI) package and the numerous database-specific packages built on top of it, including the RSQLite, RPostgres and many others.\nTo take advantage of a relational database we have perform a little more work up-front. But this effort is amply repaid by simplifying subsequent queries.\n\nLearning from Bioconductor: BiocSet’s three tables\nThe BiocSet Class from the eponymous Bioconductor package represents a collection of gene sets in three tibbles. Let’s create a simple BiocSet with two gene sets for illustration:\n\nset_names <- purrr::map_chr(mh2[1:2], \"name\")\ngene_ids <- purrr::map(mh2[1:2], \"geneSymbols\")\nes <- BiocSet(setNames(gene_ids, set_names))\n\nThe first two tibbles represent genes (called elements) and sets, respectively:\n\nes_element: one row per gene\n\n\nhead(es_element(es))\n\n# A tibble: 6 × 1\n  element\n  <chr>  \n1 Abca1  \n2 Abcb8  \n3 Acaa2  \n4 Acadl  \n5 Acadm  \n6 Acads  \n\n\n\nes_set: one row per gene set\n\n\nes_set(es)\n\n# A tibble: 2 × 1\n  set                         \n  <chr>                       \n1 HALLMARK_ADIPOGENESIS       \n2 HALLMARK_ALLOGRAFT_REJECTION\n\n\nThe third table establishes the many-to-many relationship between genes and sets, e.g. it tracks which gene is a member of each set.\n\nes_elementset: gene x set combination\n\n\n# we are showing 10 random rows\nset.seed(42)\nes_elementset(es)[sample(nrow(es_elementset(es)), size = 10), ]\n\n# A tibble: 10 × 2\n   element set                         \n   <chr>   <chr>                       \n 1 Coq5    HALLMARK_ADIPOGENESIS       \n 2 Irf7    HALLMARK_ALLOGRAFT_REJECTION\n 3 Qdpr    HALLMARK_ADIPOGENESIS       \n 4 Elovl6  HALLMARK_ADIPOGENESIS       \n 5 Cd28    HALLMARK_ALLOGRAFT_REJECTION\n 6 Ppm1b   HALLMARK_ADIPOGENESIS       \n 7 Mtarc2  HALLMARK_ADIPOGENESIS       \n 8 Zap70   HALLMARK_ALLOGRAFT_REJECTION\n 9 Ndufb7  HALLMARK_ADIPOGENESIS       \n10 Il15    HALLMARK_ALLOGRAFT_REJECTION\n\n\nEach of these tables can be augmented with additional metadata, e.g. we could add Entrez gene identifiers to the es_element (see below), or long-form descriptions for each set to the es_set tibble.\nThese three tables can easily be represented in a relational database, using the element and set columns as primary keys.\n\n\nCreating and populating a relational database\nLet’s start with a fresh SQLite database.\n\ncon <- dbConnect(RSQLite::SQLite(), \":memory:\")\n\nFirst, we create the geneset data.frame that lists all gene sets, and we also include their MSigDb URLs as metadata:\n\ngeneset <- data.frame(\n  geneset = purrr::map_chr(mh2, \"name\"),\n  url = purrr::map_chr(mh2, \"msigdbURL\"))\nhead(geneset)\n\n                       geneset\n1        HALLMARK_ADIPOGENESIS\n2 HALLMARK_ALLOGRAFT_REJECTION\n3   HALLMARK_ANDROGEN_RESPONSE\n4        HALLMARK_ANGIOGENESIS\n5     HALLMARK_APICAL_JUNCTION\n6      HALLMARK_APICAL_SURFACE\n                                                                                 url\n1        https://www.gsea-msigdb.org/gsea/msigdb/mouse/geneset/HALLMARK_ADIPOGENESIS\n2 https://www.gsea-msigdb.org/gsea/msigdb/mouse/geneset/HALLMARK_ALLOGRAFT_REJECTION\n3   https://www.gsea-msigdb.org/gsea/msigdb/mouse/geneset/HALLMARK_ANDROGEN_RESPONSE\n4        https://www.gsea-msigdb.org/gsea/msigdb/mouse/geneset/HALLMARK_ANGIOGENESIS\n5     https://www.gsea-msigdb.org/gsea/msigdb/mouse/geneset/HALLMARK_APICAL_JUNCTION\n6      https://www.gsea-msigdb.org/gsea/msigdb/mouse/geneset/HALLMARK_APICAL_SURFACE\n\n\nNext, we identify all unique gene symbols, annotate them with their Entrez ids (using the org.Mm.eg.db Bioconductor annotation package), and store both identifier types in the element data.frame.\n\ngene_symbols <- unique(unlist(purrr::map(mh2, \"geneSymbols\")))\nelement <- data.frame(\n  element = gene_symbols,\n  entrezid = mapIds(org.Mm.eg.db, keys = gene_symbols, keytype = \"SYMBOL\", \n                    column = \"ENTREZID\")\n  )\nhead(element)\n\n      element entrezid\nAbca1   Abca1    11303\nAbcb8   Abcb8    74610\nAcaa2   Acaa2    52538\nAcadl   Acadl    11363\nAcadm   Acadm    11364\nAcads   Acads    11409\n\n\nFinally, we create the element_set join table, connecting gene sets to their constituent genes:\n\nelementset <- purrr::map_df(mh2, \\(gs) {\n  with(gs, \n       data.frame(\n         element = geneSymbols,\n         geneset = name\n       )\n  )\n})\nhead(elementset)\n\n  element               geneset\n1   Abca1 HALLMARK_ADIPOGENESIS\n2   Abcb8 HALLMARK_ADIPOGENESIS\n3   Acaa2 HALLMARK_ADIPOGENESIS\n4   Acadl HALLMARK_ADIPOGENESIS\n5   Acadm HALLMARK_ADIPOGENESIS\n6   Acads HALLMARK_ADIPOGENESIS\n\n\nNext, we write each data.frame into a separate table in our SQLite database.\n\n\n\n\n\n\nVerifying foreign keys\n\n\n\n\n\nBy default, SQLite does not verify that foreign keys actually exist in the referenced table. To make this a requirement, we can enable checking with the following command:\n\ndbExecute(con, 'PRAGMA foreign_keys = 1;')\n\n[1] 0\n\n\n\n\n\n\ndbExecute(con, \n          \"CREATE TABLE tbl_geneset (geneset TEXT PRIMARY KEY, url TEXT)\")\n\n[1] 0\n\ndbWriteTable(con, name = \"tbl_geneset\", value = geneset, overwrite = TRUE)\n\ndbExecute(con, \n          \"CREATE TABLE tbl_element (element TEXT PRIMARY KEY, entrezid TEXT)\")\n\n[1] 0\n\ndbWriteTable(con, name = \"tbl_element\", value = element, overwrite = TRUE)\n\ndbExecute(con, paste(\n  \"CREATE TABLE tbl_elementset (\",\n  \"element TEXT,\", \n  \"geneset TEXT,\",\n  \"FOREIGN KEY(geneset) REFERENCES tbl_geneset(geneset),\",\n  \"FOREIGN KEY(element) REFERENCES tbl_element(element)\",\n  \")\")\n  )\n\n[1] 0\n\ndbWriteTable(con, name = \"tbl_elementset\", value = elementset, overwrite = TRUE)\n\n\ndbListTables(con)\n\n[1] \"tbl_element\"    \"tbl_elementset\" \"tbl_geneset\"   \n\n\n\n\nPlotting relationships\nAs we create and need to keep track of multiple tables, it is useful to visualize their contents (fields, columns) and relationships in a model diagram. The awesome dm R package, designed to bring an existing relational data model into your R session, can be used to generate diagrams like the one shown below. (dm can identify the keys in postgres and SQL server database engines automatically, but for SQLite we need to specify them ourselves with the dm_add_pk() and dm_add_fk() functions.)\n\ndm_from_con(con, learn_keys = FALSE) %>%\n  dm_add_pk(tbl_element, element) %>%\n  dm_add_pk(tbl_geneset, geneset) %>%\n  dm_add_fk(tbl_elementset, element, tbl_element) %>%\n  dm_add_fk(tbl_elementset, geneset, tbl_geneset) %>%\n  dm_draw(view_type = \"all\")\n\n\n\n\nModel diagram\n\n\n\n\nQuerying the database\nGreat! Now we are ready to query our database. To make our lives easier, we will use the dplyr package to translate our R syntax into SQL. (But we could just as well use plain SQL instead.)\nFirst we define the remote tables by connecting to our brand new database:\n\ntbl_geneset <- tbl(con, \"tbl_geneset\")\ntbl_element <- tbl(con, \"tbl_element\")\ntbl_elementset <- tbl(con, \"tbl_elementset\")\n\nLet’s return the gene symbols and entrez identifiers that make up the HALLMARK_APOPTOSIS gene set and display the first 5 (in alphabetical order of the gene symbols).\n\nresult <- tbl_elementset %>% \n  dplyr::filter(geneset == \"HALLMARK_ADIPOGENESIS\") %>%\n  dplyr::inner_join(tbl_element, by = \"element\") %>%\n  dplyr::slice_min(n = 5, order_by = element)\nresult\n\n# Source:   SQL [5 x 3]\n# Database: sqlite 3.39.4 [:memory:]\n  element geneset               entrezid\n  <chr>   <chr>                 <chr>   \n1 Abca1   HALLMARK_ADIPOGENESIS 11303   \n2 Abcb8   HALLMARK_ADIPOGENESIS 74610   \n3 Acaa2   HALLMARK_ADIPOGENESIS 52538   \n4 Acadl   HALLMARK_ADIPOGENESIS 11363   \n5 Acadm   HALLMARK_ADIPOGENESIS 11364   \n\n\nAnd now let’s add the gene set’s URL as well:\n\nresult %>%\n  dplyr::left_join(tbl_geneset, by = \"geneset\")\n\n# Source:   SQL [5 x 4]\n# Database: sqlite 3.39.4 [:memory:]\n  element geneset               entrezid url                                    \n  <chr>   <chr>                 <chr>    <chr>                                  \n1 Abca1   HALLMARK_ADIPOGENESIS 11303    https://www.gsea-msigdb.org/gsea/msigd…\n2 Abcb8   HALLMARK_ADIPOGENESIS 74610    https://www.gsea-msigdb.org/gsea/msigd…\n3 Acaa2   HALLMARK_ADIPOGENESIS 52538    https://www.gsea-msigdb.org/gsea/msigd…\n4 Acadl   HALLMARK_ADIPOGENESIS 11363    https://www.gsea-msigdb.org/gsea/msigd…\n5 Acadm   HALLMARK_ADIPOGENESIS 11364    https://www.gsea-msigdb.org/gsea/msigd…\n\n\n\n\nPulling data into a BiocSet\nFinally, we can easily pull selected (or even all) gene sets into a Bioconductor BiocSet object for analysis in R. Importantly, the database does not require us to use R: e.g. python users can connect to the same SQLite database (e.g. using sqlalchemy ) and retrieve the information in whatever form is most useful to them.\nFor example, let’s retrieve all gene sets whose name ends in the letter N, store them in a list and create a BiocSet object.\n\ngene_set_list <- with(\n  tbl_elementset %>% \n    dplyr::filter(geneset %like% '%N') %>%\n    collect(), \n  split(element, geneset)\n)\nes <- BiocSet(gene_set_list)\n\nNext, we add gene set metadata to the es_set tibble, by joining it with the (richer) information in the database. This will add the url column.\n\nes <- left_join_set(es, \n  tbl_geneset, by = c(set = \"geneset\"), \n  copy = TRUE\n)\nes_set(es)\n\n# A tibble: 8 × 2\n  set                                        url                                \n  <chr>                                      <chr>                              \n1 HALLMARK_ALLOGRAFT_REJECTION               https://www.gsea-msigdb.org/gsea/m…\n2 HALLMARK_APICAL_JUNCTION                   https://www.gsea-msigdb.org/gsea/m…\n3 HALLMARK_COAGULATION                       https://www.gsea-msigdb.org/gsea/m…\n4 HALLMARK_EPITHELIAL_MESENCHYMAL_TRANSITION https://www.gsea-msigdb.org/gsea/m…\n5 HALLMARK_KRAS_SIGNALING_DN                 https://www.gsea-msigdb.org/gsea/m…\n6 HALLMARK_OXIDATIVE_PHOSPHORYLATION         https://www.gsea-msigdb.org/gsea/m…\n7 HALLMARK_PROTEIN_SECRETION                 https://www.gsea-msigdb.org/gsea/m…\n8 HALLMARK_UV_RESPONSE_DN                    https://www.gsea-msigdb.org/gsea/m…\n\n\nAnd finally, let’s also add the entrezid column from out database to the es_element table:\n\nes <- left_join_element(es, \n  tbl_element, by = \"element\", \n  copy = TRUE\n)\nes_element(es)\n\n# A tibble: 1,233 × 2\n   element entrezid\n   <chr>   <chr>   \n 1 Aars    234734  \n 2 Abce1   24015   \n 3 Abi1    11308   \n 4 Ache    11423   \n 5 Acvr2a  11480   \n 6 Akt1    11651   \n 7 Apbb1   11785   \n 8 B2m     12010   \n 9 Bcat1   12035   \n10 Bcl10   12042   \n# … with 1,223 more rows\n\n\n\n\nSQL summary\n\nFor this example the effort required to transform the dataset into a set of three tables - the starting point for import into a relational database - was minimal.\nGiven the use case, e.g. management of a gene set collections, the number of times that data is added to the database is likely much smaller than the number of times it is queried. That makes it worth the effort to transform it once - and benefit from this upfront cost ever after.\nBecause we knew exactly which properties / annotations we wanted to capture in the database, defining the database tables and their relationships (e.g. the schema ) was not an obstacle, either.\nEnabling users to query the data using simple SQL or via a higher level abstraction like dplyr makes it accessible to a broader audience.\n\n\n\n\n\n\n\nWarn\n\n\n\nDefining a schema is much harder when we deal with datasets that are less standardized, deeply nested, changing over time, etc."
  },
  {
    "objectID": "posts/geneset-sqlite-db/index.html#references",
    "href": "posts/geneset-sqlite-db/index.html#references",
    "title": "SQL and noSQL approaches to creating & querying databases (using R)",
    "section": "References",
    "text": "References\nIf you are new to working with databases, then you might find these two great books useful:\n\nSQL for Data Scientists: A Beginner’s Guide for Building Datasets for Analysis by Renee M. P. Teate is a great starting place to learn SQL. It mainly focusses on accessing existing databases.\nPractical SQL: A Beginner’s Guide to Storytelling with Data by Anthony DeBarros teaches readers how to create & populate a Postgres database, and how to index and search it effectively.\n\n\n\nSessionInfo\n\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.2 (2022-10-31)\n os       macOS Big Sur ... 10.16\n system   x86_64, darwin17.0\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Los_Angeles\n date     2023-01-01\n pandoc   2.19.2 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package          * version  date (UTC) lib source\n AnnotationDbi    * 1.60.0   2022-11-01 [1] Bioconductor\n askpass            1.1      2019-01-13 [1] CRAN (R 4.2.0)\n assertthat         0.2.1    2019-03-21 [1] CRAN (R 4.2.0)\n backports          1.4.1    2021-12-13 [1] CRAN (R 4.2.0)\n Biobase          * 2.58.0   2022-11-01 [1] Bioconductor\n BiocGenerics     * 0.44.0   2022-11-01 [1] Bioconductor\n BiocIO             1.8.0    2022-11-01 [1] Bioconductor\n BiocSet          * 1.12.0   2022-11-01 [1] Bioconductor\n Biostrings         2.66.0   2022-11-01 [1] Bioconductor\n bit                4.0.5    2022-11-15 [1] CRAN (R 4.2.0)\n bit64              4.0.5    2020-08-30 [1] CRAN (R 4.2.0)\n bitops             1.0-7    2021-04-24 [1] CRAN (R 4.2.0)\n blob               1.2.3    2022-04-10 [1] CRAN (R 4.2.0)\n cachem             1.0.6    2021-08-19 [1] CRAN (R 4.2.0)\n cli                3.5.0    2022-12-20 [1] CRAN (R 4.2.0)\n crayon             1.5.2    2022-09-29 [1] CRAN (R 4.2.0)\n credentials        1.3.2    2021-11-29 [1] CRAN (R 4.2.0)\n DBI                1.1.3    2022-06-18 [1] CRAN (R 4.2.0)\n dbplyr             2.2.1    2022-06-27 [1] CRAN (R 4.2.0)\n DiagrammeR         1.0.9    2022-03-05 [1] CRAN (R 4.2.0)\n digest             0.6.31   2022-12-11 [1] CRAN (R 4.2.0)\n dm               * 1.0.3    2022-10-12 [1] CRAN (R 4.2.0)\n dplyr            * 1.0.10   2022-09-01 [1] CRAN (R 4.2.0)\n ellipsis           0.3.2    2021-04-29 [1] CRAN (R 4.2.0)\n evaluate           0.19     2022-12-13 [1] CRAN (R 4.2.0)\n fansi              1.0.3    2022-03-24 [1] CRAN (R 4.2.0)\n fastmap            1.1.0    2021-01-25 [1] CRAN (R 4.2.0)\n generics           0.1.3    2022-07-05 [1] CRAN (R 4.2.0)\n GenomeInfoDb       1.34.4   2022-12-01 [1] Bioconductor\n GenomeInfoDbData   1.2.9    2022-12-12 [1] Bioconductor\n glue               1.6.2    2022-02-24 [1] CRAN (R 4.2.0)\n highr              0.9      2021-04-16 [1] CRAN (R 4.2.0)\n htmltools          0.5.4    2022-12-07 [1] CRAN (R 4.2.0)\n htmlwidgets        1.5.4    2021-09-08 [1] CRAN (R 4.2.2)\n httpuv             1.6.7    2022-12-14 [1] CRAN (R 4.2.0)\n httr               1.4.4    2022-08-17 [1] CRAN (R 4.2.0)\n igraph             1.3.5    2022-09-22 [1] CRAN (R 4.2.0)\n IRanges          * 2.32.0   2022-11-01 [1] Bioconductor\n jsonify            1.2.2    2022-11-09 [1] CRAN (R 4.2.0)\n jsonlite         * 1.8.4    2022-12-06 [1] CRAN (R 4.2.0)\n KEGGREST           1.38.0   2022-11-01 [1] Bioconductor\n knitr              1.41     2022-11-18 [1] CRAN (R 4.2.0)\n later              1.3.0    2021-08-18 [1] CRAN (R 4.2.0)\n lifecycle          1.0.3    2022-10-07 [1] CRAN (R 4.2.0)\n magrittr           2.0.3    2022-03-30 [1] CRAN (R 4.2.0)\n memoise            2.0.1    2021-11-26 [1] CRAN (R 4.2.0)\n mime               0.12     2021-09-28 [1] CRAN (R 4.2.0)\n nodbi            * 0.9.1    2022-11-20 [1] CRAN (R 4.2.0)\n ontologyIndex      2.10     2022-08-24 [1] CRAN (R 4.2.0)\n openssl            2.0.5    2022-12-06 [1] CRAN (R 4.2.0)\n org.Mm.eg.db     * 3.16.0   2022-12-29 [1] Bioconductor\n pillar             1.8.1    2022-08-19 [1] CRAN (R 4.2.0)\n pkgconfig          2.0.3    2019-09-22 [1] CRAN (R 4.2.0)\n plyr               1.8.8    2022-11-11 [1] CRAN (R 4.2.0)\n png                0.1-8    2022-11-29 [1] CRAN (R 4.2.0)\n promises           1.2.0.1  2021-02-11 [1] CRAN (R 4.2.0)\n purrr            * 0.3.5    2022-10-06 [1] CRAN (R 4.2.0)\n R6                 2.5.1    2021-08-19 [1] CRAN (R 4.2.0)\n RColorBrewer       1.1-3    2022-04-03 [1] CRAN (R 4.2.0)\n Rcpp               1.0.9    2022-07-08 [1] CRAN (R 4.2.0)\n RCurl              1.98-1.9 2022-10-03 [1] CRAN (R 4.2.0)\n rlang              1.0.6    2022-09-24 [1] CRAN (R 4.2.0)\n rmarkdown          2.19     2022-12-15 [1] CRAN (R 4.2.0)\n RSQLite          * 2.2.19   2022-11-24 [1] CRAN (R 4.2.0)\n rstudioapi         0.14     2022-08-22 [1] CRAN (R 4.2.0)\n S4Vectors        * 0.36.1   2022-12-05 [1] Bioconductor\n sessioninfo        1.2.2    2021-12-06 [1] CRAN (R 4.2.0)\n shiny              1.7.4    2022-12-15 [1] CRAN (R 4.2.0)\n stringi            1.7.8    2022-07-11 [1] CRAN (R 4.2.0)\n stringr            1.5.0    2022-12-02 [1] CRAN (R 4.2.0)\n sys                3.4.1    2022-10-18 [1] CRAN (R 4.2.0)\n tibble           * 3.1.8    2022-07-22 [1] CRAN (R 4.2.0)\n tidyr            * 1.2.1    2022-09-08 [1] CRAN (R 4.2.0)\n tidyselect         1.2.0    2022-10-10 [1] CRAN (R 4.2.0)\n utf8               1.2.2    2021-07-24 [1] CRAN (R 4.2.0)\n uuid               1.1-0    2022-04-19 [1] CRAN (R 4.2.0)\n vctrs              0.5.1    2022-11-16 [1] CRAN (R 4.2.0)\n visNetwork         2.1.2    2022-09-29 [1] CRAN (R 4.2.0)\n withr              2.5.0    2022-03-03 [1] CRAN (R 4.2.0)\n xfun               0.35     2022-11-16 [1] CRAN (R 4.2.0)\n xtable             1.8-4    2019-04-21 [1] CRAN (R 4.2.0)\n XVector            0.38.0   2022-11-01 [1] Bioconductor\n yaml               2.3.6    2022-10-18 [1] CRAN (R 4.2.0)\n zlibbioc           1.44.0   2022-11-01 [1] Bioconductor\n\n [1] /Users/sandmann/Library/R/x86_64/4.2/library\n [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────"
  }
]