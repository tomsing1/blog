---
title: "Compressing single-cell RNA-seq data with run-length encoding and LZW"
author: "Thomas Sandmann"
date: "2024-12-23"
execute:
  echo: true
  warning: false
  message: false
freeze: true
categories: [R, single-cell, RNA-seq, algorithms, TIL]
editor:
  markdown:
    wrap: 72
format:
  html:
    anchor-sections: true
    toc: true
    toc-depth: 4
    code-tools:
      source: true
      toggle: false
      caption: none
editor_options: 
  chunk_output_type: console
---

```{r}
#| include: false
renv::use(lockfile = file.path(path.expand("~"), "repositories", "blog", 
                               "posts", "lzw", "renv", "profiles", "lzw",
                               "renv.lock"))
```

## tl;dr

- Today I learned how to compress integer vectors using 
[run-length encoding (RLE)](https://en.wikipedia.org/wiki/Run-length_encoding), 
output the runs as character vectors, and create a basic implementation
of the 
[Lempel-Ziv-Welch (LZW)](https://en.wikipedia.org/wiki/Lempel%E2%80%93Ziv%E2%80%93Welch)
compression algorithm.
- Together, these approaches reduce the amount of information that needs to be
stored, e.g. in HTML reports, for interactive visualizations.
- Hat tip to analysis reports generated by 
[Parse Bioscience's analysis pipeline](https://support.parsebiosciences.com/hc/en-us/articles/27066395947412-How-Do-I-Analyze-my-Parse-Biosciences-Data) where I spotted compressed single-cell RNA-seq data for the
first time.

## Motivation

I am always looking for ways to communicate genomics analyses to collaborators
in a way that allows them to drill down into the data themselves. Stand-alone
HTML reports can be opened in any web browser and can support rich 
visualizations, making them my an indespensible tool in my tool kit. 

Yet, some of the data I am working with, e.g. single-cell RNA-seq data,
is pretty large, and the size of my HTML reports - which include the data 
as text - can quickly balloon. Luckily, there are ways to compress numerical 
data without loosing information. 

Here, I am exploring two approaches: 
[run-length encoding (RLE)](https://en.wikipedia.org/wiki/Run-length_encoding) and 
[Lempel-Ziv-Welch (LZW) compression](https://en.wikipedia.org/wiki/Lempel%E2%80%93Ziv%E2%80%93Welch)[^1].

[^1]: Both of these approaches are used e.g. in the summary HTML reports
generated by Parse Bioscience's analysis pipeline, e.g. in this
[example report](https://cdn.parsebiosciences.com/mouse/brain-nuclei/v3/all-sample_analysis_summary.html#).
The HTML file contains transcriptome-wide gene expression scores for > 50,000
cells, and users can visualize the expression of their favorite gene on a 
UMAP projection. The whole HTML file is ~ 60 MB in size.

## Sparse information: single-cell RNA-seq data

Single-cell RNA-seq data are notoriously sparse, e.g. the majority of counts
across genes & cells is zero. For example, 96% of all counts in the PBMC 4k
single-cell experiment shared by 10X Genomics (and available via the 
[TENxPBMCData](https://bioconductor.org/packages/release/data/experiment/html/TENxPBMCData.html)
Bioconductor package) are zero:

```{r}
#| message: false
#| warning: false
library(TENxPBMCData)
tenx_pbmc4k <- suppressMessages(TENxPBMCData(dataset = "pbmc4k"))
mean(counts(tenx_pbmc4k) == 0)
```

Most of the remaining counts are integers smaller than ten, with fewer than
0.2% of values exceeding that range:

```{r}
mean(counts(tenx_pbmc4k) > 10)
```

This leads to very long runs of identical integers (most often zero), which
can efficiently be represented through 
[run-length encoding](https://en.wikipedia.org/wiki/Run-length_encoding)

For example, the expression of the transcription facto _MYC_ gene is highly
skewed towards zero counts:

```{r}
myc <- local({
  ensembl <- row.names(tenx_pbmc4k)[which(rowData(tenx_pbmc4k)$Symbol == "MYC")]
  counts(tenx_pbmc4k)[ensembl, ]
})
hist(myc, breaks = 100, xlab = "MYC (raw counts)")
```
and there are long sequences of zeros and some shorter sequences of ones in
the count vector. (Here, I am only showing counts for the the first 100 of the 
`r ncol(tenx_pbmc4k)` cells.) 

```{r}
head(myc, n = 100)
```

R estimates that the entire vector of `r length(myc)` counts occupies 
`r format(object.size(myc), units = "KiB")` of memory.

## Run length encoding

This information can be communicated more concisely by noting each integer (e.g.
zero) and the number of times it is repeated. The `stats::rle` function
performs this conversion:

```{r}
run_lengths <- rle(myc)
run_lengths
```

and returns two components: 

1. a vector of values:

```{r}
head(run_lengths$values)
```

2. a vector with the number of times each of them is repeated:

```{r}
head(run_lengths$lengths)
```

This allows us to compress the original `r ncol(tenx_pbmc4k)`
integers into `r sum(lengths(run_lengths))` integers 
(`r lengths(run_lengths)[1]` length & value pairs), 
without losing any information.

By combining information about values and run-lengths, we can reconstruct
the original vector, either manually:

```
0 x 3: 0,0,0,
1 x 1: 1,
3 x 1: 3,
0 x 3: 0,0,0,
1 x 1: 1,
0 x 4: 0,0,0,0,
1 x 3: 1,1,1,
...

=> 0,0,0,1,3,0,0,0,1,0,0,0,0,1,1,1,...
```

or via `inverse.rle`:

```{r}
head(inverse.rle(run_lengths), n = 16)
```

To store run-length encoded values e.g. in a text (or HTML) file, we can also
represent them as characters, similar to our manual reconstruction above, e.g.
separating values and lengths with an `x`:

```{r}
myc_rle_separated <- mapply(paste, 
    run_lengths$values, 
    run_lengths$length, 
    MoreArgs = list(sep = "x")) |>
  paste(collapse = ";")
substr(myc_rle_separated, 1, 40)
```

This representation occupies only 
`r format(object.size(myc_rle_separated), units = "KiB")` of memory - but _half_
of the character string is required to encode the `x` and `;` separators. We
can do better!

To avoid including any separators, we can represent one of the
numbers, e.g. the values, as a single character instead. For the _MYC_ gene, the 
largest observed integer count is `r max(myc)`. So let's represent all 
`r max(myc) + 1` values (including 0) with a letter of the alphabet instead:

```{r}
dictionary <- setNames(letters[1:(max(myc) + 1)], 0:max(myc))
dictionary
```

For example, the letter `a` represents `0`, `b` represents `1` and so on.

Now we can omit the `x` and `;` separators, as each run is unambiguously
represented by one character and an integer [^2]:

```{r}
myc_rle_character <- mapply(paste0, 
    dictionary[as.character(run_lengths$values)],  # <1>
    run_lengths$length) |>
  paste(collapse = "")
substr(myc_rle_character, 1, 21)
```

1. It's critical to coerce the run-length values into a _character_ vector here,
otherwise the named vector is subset by _position_ instead of by _name_.

[^2]: Because runs can be very long, the lengths - represented as integers - 
have varying number of decimals.

In this representation, the `r ncol(tenx_pbmc4k)` counts value for the _MYC_ 
gene now occupy only `r format(object.size(myc_rle_character), units = "KiB")` 
of memory instead of the original `r format(object.size(myc), units = "KiB")`.
We can also write the data to a text (or HTML) file in this format, e.g. as a 
single string.

::: {.callout-note}

### Encoding larger numbers of values

In this example, we only needed `r max(myc) + 1` letters to encode all observed
unique counts for the _MYC_ gene. But for other genes, especially those 
expressed at higher levels, we might observe many more possible values - even
more than the `r length(letters)` lower case letters of the English alphabet.

```{r}
gapdh <- local({
  ensembl <- row.names(tenx_pbmc4k)[
    which(rowData(tenx_pbmc4k)$Symbol == "GAPDH")]
  counts(tenx_pbmc4k)[ensembl, ]
})
```

For example, in this dataset we observe `r length(table(gapdh))` distinct
count values for the highly abundant _GAPDH_ gene:

```{r}
table(gapdh)
```

Luckily, we are not restricted to the English alphabet. For example, we can map
to any character in the 
[Unicode Transformation Format – 8-bit (UTF-8)](https://en.wikipedia.org/wiki/UTF-8)
character encoding instead.

To encode e.g. all integers from 1 to 256 (more than enough for _GAPDH_) - but
*avoiding those that represent a space, quote, etc or integers* - 
we can use UTF-8 codes 64 to 319:

```{r}
codes <- 64:319
dictionary <- setNames(intToUtf8(codes, multiple = TRUE), 0:255)
head(dictionary, n = 66)
```

And then use this dictionary to encode the _GAPDH_ counts:

```{r}
head(gapdh, n = 20)
```

```{R}
gapdh_character <- local({
  run_lengths <- rle(gapdh)
  mapply(paste0, 
         dictionary[as.character(run_lengths$values)],
         run_lengths$length) |>
    paste0(collapse = "")
})
substr(gapdh_character, 1, 36)
```

Because there are more (and shorter) runs in the _GAPDH_ count vector than
for _MYC_, the degree of compression we achieve is smaller, from 
`r format(object.size(gapdh), units = "KiB")` for the original count vector to 
`r format(object.size(gapdh_character), units = "KiB")` for the character
representation.

:::

::: {.callout-caution collapse="true"}

In this post, the example dictionaries encode counts up to 256 - but many
single-cell experiments will contain larger integer counts than 256. 

For those, we either need to create a  larger dictionary, or we could opt to
truncate larger values (e.g. represent counts >= 256 with the same character,
losing information in the process).

When visualizing gene expression scores, we often log2 transform the raw or
normalized counts, generating floating point numbers. If it is acceptable to
lose precision, we can round these log2 transformed scores to the nearest
integer and apply run-length encoding to them.

Because 2 to the power of 256 is a very large number (~ 1.16e+77), we would
be able to represent even the highest observed scores But on the flip side,
rounding the log2 transformed scores would obscure some differences between
expression levels.

:::

## LZW compression

At this point, we are representing the original count vectors as character
strings. Some of these string representation contain repeated patterns, which
we can exploit to compress them even further.

::: {.callout-note collapse="true"}

The `Lempel–Ziv–Welch` algorithm was the 
[first widely used universal data compression method](https://en.wikipedia.org/wiki/Lempel%E2%80%93Ziv%E2%80%93Welch)
and is e.g. used in the GIF image format. 

At a high level, the algorithm identifies the longest repeated sequences
("phrases") in a character string and maps them to shorter expressions in a
dictionary. 

:::

There are great tutorials about the LZW algorithm and its implementation
available on the web, e.g. 
[this one](https://eng.libretexts.org/Bookshelves/Electrical_Engineering/Signal_Processing_and_Modeling/Information_and_Entropy_(Penfield)/03%3A_Compression/3.07%3A_Detail-_LZW_Compression/3.7.01%3A_LZW_Algorithm_Example_1). 
Here, I will create a basic implementation in R [^3]. 

[^3]: While this implementation works, it could be improved. For example, it 
doesn't set any limits on the size of the final dictionary.

### LZW encoding

```{r}
compress_lzw <- function(input_string) {
  dictionary <- setNames(intToUtf8(1:256, multiple = TRUE),   # <1>
                         intToUtf8(1:256, multiple = TRUE)
  )
  next_code <- 257
  
  previous_pattern <- character(0)  # <2>
  output <- character(0)  # <3>
  
  for (char in strsplit(input_string, "")[[1]]) {  # <4>
    new_pattern <- paste0(previous_pattern, char)  # <5>
    if (new_pattern %in% names(dictionary)) {  # <6>
      previous_pattern <- new_pattern
    } else {  # <7> 
      output <- paste0(output, dictionary[[previous_pattern]])  # <7>
      dictionary[[new_pattern]] <- as.character(intToUtf8(next_code))
      next_code <- next_code + 1
      previous_pattern <- char
    }
  }
  
  if (nzchar(previous_pattern)) {
    output <- paste0(output, dictionary[[previous_pattern]]) # <8>
  }
  return(output)
}
```

1. We initialize a "dictionary" (e.g. a named character vector) with 256 UTF-8
codes.
2. As we parse the input string, the current sequence will be stored in the 
`previous_pattern` variable. It is initialized as an empty string.
3. The `output` variable will collect the compressed output and is 
eventually returned. It is also initialized as an empty string.
4. The input string is split into individual characters, and we process them
one by one.
5. In the first loop, the `previous_pattern` is still empty. But in subsequent
loops, we extend the previous one with the new character to identify longer
patterns.
6. If the extended pattern is already known, then we don't need to update our
dictionary. We simply replace the `previous_pattern` with the current one.
7. If we encounter a _new_ pattern, then we 
  - Encode the `previous_pattern` and add it to the output
  - Map the new pattern to the next available UTF-8 code
  - Increment the position of the next available UTF-8 code by one
  - Reset the previous pattern to the current character.
8. After the entire string has been processed, we encode the final pattern
and then return the full output.

Let's apply our LZW compression function to the run-length encoded _MYC_
expression we generated above:

```{r}
#| message: false
myc_lzw <- compress_lzw(myc_rle_character)
myc_lzw
```

After LZW compression, R estimates the size of this new character representation
to be `r format(object.size(myc_lzw), units = "KiB")`, down from 
`r format(object.size(myc_rle_character), units = "KiB")` after RLE.

Next, let's implement the corresponding decoding function!

### LZW decoding

```{r}
decompress_lzw <- function(compressed) {
  dictionary <- setNames(intToUtf8(1:256, multiple = TRUE),   # <1>
                         intToUtf8(1:256, multiple = TRUE)
  )
  next_code <- 257
  
  compressed_codes <- strsplit(compressed, "")[[1]]  # <2>
  # read the first character and decode it
  current_code <- compressed_codes[1]  # <3>
  output <- dictionary[[current_code]] 
  previous_string <- output
  
  # read the remaining characters, one by one
  for (code in compressed_codes[-1]) {  # <4>
    if (as.character(code) %in% names(dictionary)) {
      current_string <- dictionary[as.character(code)]  # <5>
      dictionary[[intToUtf8(next_code)]] <- paste0(previous_string, 
                                                   substr(current_string, 1, 1))
      
    } else {
      current_string <- paste0(previous_string, substr(previous_string, 1, 1))
      dictionary[[intToUtf8(next_code)]] <- current_string
      
    }
    output <- paste0(output, current_string)  # <6>
    next_code <- next_code + 1  # <7>
    previous_string <- current_string  # <8>
  }
  return(output)
}
```

1. The decoding function is provided with the same initial dictionary we
included in the encoding function.
2. We process the compressed string one character at a time.
3. The algorithm is initialized with the first character of the encoded string, 
and we decode it using the pre-defined dictionary (which includes all single
characters).
4. We then iterate over the remaining characters in the compressed input.
5. We check if the current code is already in our dictionary
  - If _yes_, then we decode it by looking up its corresponding value in our
    dictionary. We also add an extended pattern to our dictionary, by
    concatenating the previous result with the (first character of) our 
    current one.
  - If _no_, then we decode it by extending the previous result by its (own)
  first character and add it to the dictionary.
  character 
6. We add the newly decoded result to our output string.
7. Increment the running index of our dictionary, because we added a new key.
8. Get ready for the next iteration.

Let's test the function by restoring the RLE-encoded _MYC_ counts we
compressed above:

```{r}
myc_lzw_decompressed <- decompress_lzw(myc_lzw)
head(myc_lzw_decompressed)
```

Are the results of sequention compression & decompression really identical
to the input string?

```{r}
identical(
  decompress_lzw(compress_lzw(myc_rle_character)), 
  myc_rle_character)
```

::: {.callout-note collapse="true"}

#### Compression / decompression example

Because it's hard to visually compare the long vectors we have compressed & 
decompressed above, here is a toy example:

```{r}
original_string <- "MARYHADALITTLELAMBMARYHADALITTLELAMBMARYHAD"
compressed <- compress_lzw(original_string)
decompressed <- decompress_lzw(compressed)
```

```{r}
#| echo: false
cat("Original String: ", original_string, "\n")
```

```{r}
#| echo: false
cat("Compressed: ", compressed, "\n")
```

```{r}
#| echo: false
cat("Decompressed: ", decompressed, "\n")
```

:::

## So what?

We have applied two rounds of compression to our count (or rounded, log2 
transformed counts) single-cell RNA-seq data, achieving considerable reduction
in the size of the objects [^4].

[^4]: Typical file formats used to exchange single-cell RNA-seq count tables
are using more sophisticated ways of compression. For example, applying
[gzip compression](https://en.wikipedia.org/wiki/Gzip) to CSV files with
sparse count data will reduce their sizes tremendously. Other formats, e.g. 
`HDF5` or `Parquet` files also take advantage of compression algorithms.

While I have created examples of RLE and LZW compression using R, the same
approach can be implemented in any programming language. The reports generated
by Parse Bioscience, for example 
[this one](https://cdn.parsebiosciences.com/mouse/brain-nuclei/v3/all-sample_analysis_summary.html#),
include rounded log2 gene expression counts for all assayed genes across all
cells that was compressed in the same way [^5]. To decode the compressed 
strings, the html reports include javascript functions that perform the same
operations established here.

[^5]: The encoding & compression is happening when the report is generated,
but the decoding javascript functions are part of the HTML report.

Combined with interactive plots, users can enter a gene name, triggering the
decoding of its gene expression scores and updating a UMP plot in their
browser - without the need for any central server. (Take a look at 
[the source code of one of their reports](https://cdn.parsebiosciences.com/mouse/brain-nuclei/v3/all-sample_analysis_summary.html#)
to see how this is achieved!)

Now that I have a better understanding of how large amounts of data can be
included in a stand-along HTML document, I am ready to learn more about 
javascript & interactive visualizations [^6]! 

[^6]: Greg Wilson's 
[Javascript for Data Scientists](https://third-bit.com/js4ds/)
course has been on my to-do list for a while.

## Reproducibility

<details>
<summary>
Session Information
</summary>

```{r}
sessionInfo()
```

</details>
